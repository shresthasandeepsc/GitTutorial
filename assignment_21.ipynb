{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment_21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shresthasandeepsc/GitTutorial/blob/master/assignment_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wjif_5FsdOFz"
      },
      "source": [
        "# SIT744 Assignment 2: Efficient Training of Convolutional Neural Network \n",
        "\n",
        "<div class=\"alert-info\">\n",
        "    <p>Due: <strong>11:59pm 21 September 2020</strong>  (Monday)</p>\n",
        "\n",
        "This is an <strong>individual</strong> assignment. It contributes <strong>45%</strong> to your final mark. Read the assignment instruction carefully.\n",
        "\n",
        "<h2> What to submit </h2>\n",
        "\n",
        "<p>\n",
        "This assignment is to be completed individually and submitted to CloudDeakin. <strong>By the due date, you are required to submit the following files to the corresponding Assignment (Dropbox) in CloudDeakin</strong>:\n",
        "\n",
        "<ol>\n",
        "<li>\t<strong>[YourID]_assignment2_solution.ipynp</strong>:  This is your Python notebook solution source file. </li>\n",
        "<li>\t<strong>[YourID]_assingment2_output.html</strong>: This is the output of your Python notebook solution <emph>exported</emph> in HTML format.</li>\n",
        "<li>\tExtra files needed to complete your assignment, if any (e.g., images used in your answers).</li>\n",
        "</ol>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "For example, if your student ID is: 123456, you will then need to submit the following files:\n",
        "<ul>\n",
        "<li> 123456_assignment2_solution.ipynp </li>\n",
        "<li> 123456_assignment2_output.html</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<h2> Warning </h2>\n",
        "\n",
        "Some components of this assignment may involve heavy computation that runs for a long duration. Please start early to avoid missing the assignment due date.\n",
        "\n",
        "<h2> Marking criteria </h2>\n",
        "\n",
        "<p>\n",
        "Your submission will be marked using the following criteria.\n",
        "\n",
        "<ul>\n",
        "<li> Showing good effort through completed tasks.</li>\n",
        "<li> Applying deep learning theory to design suitable deep learning solutions for the tasks.</li>\n",
        "<li> Critically evaluating and reflecting on the pros and cons of various design decisions.</li>\n",
        "<li> Demonstrating creativity and resourcefulness in providing unique individual solutions.</li>\n",
        "<li> Showing attention to details through a good quality assignment report.</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "Indicative weights of various tasks are provided, but the assignment will be marked by the overall quality per the above criteria.\n",
        "</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "twFQbltnm8da"
      },
      "source": [
        "## Assignment objective\n",
        "\n",
        "This assignment is to feedback on your learning in deep learning theory and its application to  data analytics or artificial intelligence problems.  \n",
        "\n",
        "It builds on Assignment 1 but requires a higher level of mastery of deep learning theory and programming/engineering skills. In particular, you will experience training a much deeper network on a large-scale dataset. You will encounter  practical issues that help you consolidate textbook learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ITc1hw_o7qV"
      },
      "source": [
        "## Task 1 Solving Fashion-MNIST with Convolutional Neural Networks\n",
        "\n",
        "*(weight ~18%)*\n",
        "\n",
        "In Assignment 1, you tackled the image classification problem in Fashion-MNIST. There, you used a Densely Connected Neural Network. You should now know that is not an optimal model architecture for the problem. In Assignment 2, you will apply the best practices of deep-learning computer vision to improve the image classification performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zdHwmgwOpEfx"
      },
      "source": [
        "### Task 1.1 Revisit Fashion-MNIST classification with DNN\n",
        "\n",
        "*(weight ~2%)*\n",
        "\n",
        "Review your Assignment 1 solution, and reproduce the experiment here. Try to improve the model without changing the model architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ou1-Hf1Buoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "051ac11f-a923-48c2-a3b9-5e03dab9a101"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR0zqdmTCING",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b1871198-0651-4936-ff3d-d0a9887b7845"
      },
      "source": [
        "# load fashion mnist dataset from keras dataset\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg5Z1b3bCQf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "test_images = test_images.reshape((10000, 28 * 28))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL7HbURqCTYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3CvLW8oCWKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding of labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EORMeMxWCZJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, valid_images) = (train_images[5000:], train_images[:5000])\n",
        "(train_labels, valid_labels) = (train_labels[5000:], train_labels[:5000])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR0RE28DCicD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "dataset_valid = tf.data.Dataset.from_tensor_slices((valid_images, valid_labels))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LZjQwcbCmRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = dataset_train.shuffle(10000).repeat(1500).batch(1280).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "dataset_test = dataset_test.batch(1280).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "dataset_valid = dataset_valid.batch(1280).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMhGzUQ-Cs4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_per_epoch = len(dataset_train)/1280"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuDrtoVVDVOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./logs/assign-1-logs \n",
        "fit_log_dir = \"logs/assign-1-logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=fit_log_dir, histogram_freq=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yzOm0kRC1UV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cd949f9-5470-45da-fff0-f968d60e433e"
      },
      "source": [
        "# Construct a Sequential model with 2 hidden layers\n",
        "fmnist_model = models.Sequential([\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(units=512, input_dim=28 * 28, activation=tf.nn.relu),\n",
        "    layers.Dense(units=128, input_dim=512, activation=tf.nn.relu),\n",
        "    layers.Dense(units=10, input_dim=128,  activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "fmnist_model.compile(optimizer = tf.optimizers.Adam(),\n",
        "                     loss = 'categorical_crossentropy', # as we have already used the one-hot encoding for the training labels\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history = fmnist_model.fit(dataset_train, \n",
        "                           epochs=1100,\n",
        "                           steps_per_epoch= steps_per_epoch,\n",
        "                           validation_data = dataset_valid,\n",
        "                           callbacks = [tensorboard_callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1100\n",
            " 2/50 [>.............................] - ETA: 1s - loss: 2.0611 - accuracy: 0.3398WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_train_batch_end` time: 0.0563s). Check your callbacks.\n",
            "51/50 [==============================] - 0s 8ms/step - loss: 0.7267 - accuracy: 0.7507 - val_loss: 0.4688 - val_accuracy: 0.8392\n",
            "Epoch 2/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.8314 - val_loss: 0.4097 - val_accuracy: 0.8580\n",
            "Epoch 3/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.8464 - val_loss: 0.3724 - val_accuracy: 0.8716\n",
            "Epoch 4/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8609 - val_loss: 0.3653 - val_accuracy: 0.8718\n",
            "Epoch 5/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8626 - val_loss: 0.3465 - val_accuracy: 0.8790\n",
            "Epoch 6/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8689 - val_loss: 0.3359 - val_accuracy: 0.8840\n",
            "Epoch 7/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8722 - val_loss: 0.3175 - val_accuracy: 0.8884\n",
            "Epoch 8/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8787 - val_loss: 0.3134 - val_accuracy: 0.8886\n",
            "Epoch 9/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.8819 - val_loss: 0.3162 - val_accuracy: 0.8888\n",
            "Epoch 10/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8824 - val_loss: 0.3271 - val_accuracy: 0.8832\n",
            "Epoch 11/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.8849 - val_loss: 0.3019 - val_accuracy: 0.8880\n",
            "Epoch 12/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.8891 - val_loss: 0.3019 - val_accuracy: 0.8918\n",
            "Epoch 13/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2939 - accuracy: 0.8918 - val_loss: 0.3020 - val_accuracy: 0.8930\n",
            "Epoch 14/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2879 - accuracy: 0.8947 - val_loss: 0.2899 - val_accuracy: 0.8958\n",
            "Epoch 15/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.8955 - val_loss: 0.2857 - val_accuracy: 0.8978\n",
            "Epoch 16/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2730 - accuracy: 0.8991 - val_loss: 0.2866 - val_accuracy: 0.8968\n",
            "Epoch 17/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.8983 - val_loss: 0.2918 - val_accuracy: 0.8940\n",
            "Epoch 18/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.9018 - val_loss: 0.2800 - val_accuracy: 0.9022\n",
            "Epoch 19/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2639 - accuracy: 0.9009 - val_loss: 0.3071 - val_accuracy: 0.8902\n",
            "Epoch 20/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2588 - accuracy: 0.9036 - val_loss: 0.2749 - val_accuracy: 0.8974\n",
            "Epoch 21/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.9064 - val_loss: 0.2830 - val_accuracy: 0.9002\n",
            "Epoch 22/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2513 - accuracy: 0.9066 - val_loss: 0.2782 - val_accuracy: 0.8994\n",
            "Epoch 23/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2501 - accuracy: 0.9055 - val_loss: 0.2711 - val_accuracy: 0.9032\n",
            "Epoch 24/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9096 - val_loss: 0.2874 - val_accuracy: 0.8958\n",
            "Epoch 25/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2396 - accuracy: 0.9102 - val_loss: 0.2770 - val_accuracy: 0.9006\n",
            "Epoch 26/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2366 - accuracy: 0.9114 - val_loss: 0.2754 - val_accuracy: 0.9014\n",
            "Epoch 27/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2277 - accuracy: 0.9152 - val_loss: 0.2695 - val_accuracy: 0.9030\n",
            "Epoch 28/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2289 - accuracy: 0.9141 - val_loss: 0.2808 - val_accuracy: 0.8994\n",
            "Epoch 29/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2270 - accuracy: 0.9152 - val_loss: 0.2702 - val_accuracy: 0.9016\n",
            "Epoch 30/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9159 - val_loss: 0.2733 - val_accuracy: 0.9016\n",
            "Epoch 31/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9180 - val_loss: 0.2675 - val_accuracy: 0.9038\n",
            "Epoch 32/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2161 - accuracy: 0.9185 - val_loss: 0.2659 - val_accuracy: 0.9058\n",
            "Epoch 33/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9186 - val_loss: 0.2816 - val_accuracy: 0.8994\n",
            "Epoch 34/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2106 - accuracy: 0.9207 - val_loss: 0.2707 - val_accuracy: 0.9068\n",
            "Epoch 35/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2084 - accuracy: 0.9208 - val_loss: 0.2701 - val_accuracy: 0.9034\n",
            "Epoch 36/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.9219 - val_loss: 0.2709 - val_accuracy: 0.9056\n",
            "Epoch 37/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.9222 - val_loss: 0.2680 - val_accuracy: 0.9030\n",
            "Epoch 38/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2014 - accuracy: 0.9241 - val_loss: 0.2653 - val_accuracy: 0.9086\n",
            "Epoch 39/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1999 - accuracy: 0.9246 - val_loss: 0.2858 - val_accuracy: 0.9038\n",
            "Epoch 40/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9252 - val_loss: 0.2689 - val_accuracy: 0.9064\n",
            "Epoch 41/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9259 - val_loss: 0.2798 - val_accuracy: 0.9018\n",
            "Epoch 42/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9260 - val_loss: 0.2745 - val_accuracy: 0.9072\n",
            "Epoch 43/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9280 - val_loss: 0.2757 - val_accuracy: 0.9036\n",
            "Epoch 44/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9290 - val_loss: 0.2772 - val_accuracy: 0.9048\n",
            "Epoch 45/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9301 - val_loss: 0.2733 - val_accuracy: 0.9050\n",
            "Epoch 46/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9295 - val_loss: 0.2689 - val_accuracy: 0.9026\n",
            "Epoch 47/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1860 - accuracy: 0.9296 - val_loss: 0.2705 - val_accuracy: 0.9090\n",
            "Epoch 48/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1825 - accuracy: 0.9307 - val_loss: 0.2781 - val_accuracy: 0.9050\n",
            "Epoch 49/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1848 - accuracy: 0.9298 - val_loss: 0.2727 - val_accuracy: 0.9064\n",
            "Epoch 50/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1791 - accuracy: 0.9312 - val_loss: 0.2733 - val_accuracy: 0.9092\n",
            "Epoch 51/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1781 - accuracy: 0.9313 - val_loss: 0.2700 - val_accuracy: 0.9102\n",
            "Epoch 52/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1744 - accuracy: 0.9329 - val_loss: 0.2765 - val_accuracy: 0.9056\n",
            "Epoch 53/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1763 - accuracy: 0.9331 - val_loss: 0.2764 - val_accuracy: 0.9028\n",
            "Epoch 54/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9335 - val_loss: 0.2702 - val_accuracy: 0.9094\n",
            "Epoch 55/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.9350 - val_loss: 0.2804 - val_accuracy: 0.9046\n",
            "Epoch 56/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1707 - accuracy: 0.9342 - val_loss: 0.2646 - val_accuracy: 0.9104\n",
            "Epoch 57/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1701 - accuracy: 0.9359 - val_loss: 0.2710 - val_accuracy: 0.9120\n",
            "Epoch 58/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.9364 - val_loss: 0.2800 - val_accuracy: 0.9030\n",
            "Epoch 59/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1656 - accuracy: 0.9374 - val_loss: 0.2747 - val_accuracy: 0.9056\n",
            "Epoch 60/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1642 - accuracy: 0.9368 - val_loss: 0.2803 - val_accuracy: 0.9086\n",
            "Epoch 61/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1659 - accuracy: 0.9372 - val_loss: 0.2817 - val_accuracy: 0.9056\n",
            "Epoch 62/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1647 - accuracy: 0.9377 - val_loss: 0.2741 - val_accuracy: 0.9080\n",
            "Epoch 63/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.9400 - val_loss: 0.2867 - val_accuracy: 0.9066\n",
            "Epoch 64/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.9385 - val_loss: 0.2777 - val_accuracy: 0.9070\n",
            "Epoch 65/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9412 - val_loss: 0.2758 - val_accuracy: 0.9078\n",
            "Epoch 66/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1559 - accuracy: 0.9410 - val_loss: 0.2860 - val_accuracy: 0.9068\n",
            "Epoch 67/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1544 - accuracy: 0.9407 - val_loss: 0.2805 - val_accuracy: 0.9080\n",
            "Epoch 68/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9405 - val_loss: 0.2767 - val_accuracy: 0.9086\n",
            "Epoch 69/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9425 - val_loss: 0.2804 - val_accuracy: 0.9088\n",
            "Epoch 70/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1529 - accuracy: 0.9414 - val_loss: 0.2809 - val_accuracy: 0.9102\n",
            "Epoch 71/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9437 - val_loss: 0.2865 - val_accuracy: 0.9044\n",
            "Epoch 72/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.9420 - val_loss: 0.2868 - val_accuracy: 0.9062\n",
            "Epoch 73/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9433 - val_loss: 0.2872 - val_accuracy: 0.9084\n",
            "Epoch 74/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1484 - accuracy: 0.9422 - val_loss: 0.2899 - val_accuracy: 0.9048\n",
            "Epoch 75/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1466 - accuracy: 0.9443 - val_loss: 0.2831 - val_accuracy: 0.9084\n",
            "Epoch 76/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9459 - val_loss: 0.2946 - val_accuracy: 0.9050\n",
            "Epoch 77/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1446 - accuracy: 0.9450 - val_loss: 0.2735 - val_accuracy: 0.9116\n",
            "Epoch 78/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1414 - accuracy: 0.9458 - val_loss: 0.2877 - val_accuracy: 0.9084\n",
            "Epoch 79/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1383 - accuracy: 0.9471 - val_loss: 0.2938 - val_accuracy: 0.9032\n",
            "Epoch 80/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.9470 - val_loss: 0.2858 - val_accuracy: 0.9088\n",
            "Epoch 81/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9471 - val_loss: 0.2898 - val_accuracy: 0.9094\n",
            "Epoch 82/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1408 - accuracy: 0.9452 - val_loss: 0.2844 - val_accuracy: 0.9108\n",
            "Epoch 83/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.9491 - val_loss: 0.2867 - val_accuracy: 0.9098\n",
            "Epoch 84/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.9470 - val_loss: 0.2896 - val_accuracy: 0.9086\n",
            "Epoch 85/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1332 - accuracy: 0.9492 - val_loss: 0.2913 - val_accuracy: 0.9094\n",
            "Epoch 86/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1349 - accuracy: 0.9483 - val_loss: 0.2970 - val_accuracy: 0.9048\n",
            "Epoch 87/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9486 - val_loss: 0.2974 - val_accuracy: 0.9088\n",
            "Epoch 88/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9491 - val_loss: 0.2957 - val_accuracy: 0.9070\n",
            "Epoch 89/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9496 - val_loss: 0.2870 - val_accuracy: 0.9082\n",
            "Epoch 90/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1269 - accuracy: 0.9515 - val_loss: 0.2934 - val_accuracy: 0.9120\n",
            "Epoch 91/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1305 - accuracy: 0.9504 - val_loss: 0.2898 - val_accuracy: 0.9134\n",
            "Epoch 92/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1290 - accuracy: 0.9501 - val_loss: 0.3119 - val_accuracy: 0.9078\n",
            "Epoch 93/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1297 - accuracy: 0.9492 - val_loss: 0.2966 - val_accuracy: 0.9102\n",
            "Epoch 94/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9506 - val_loss: 0.3114 - val_accuracy: 0.9064\n",
            "Epoch 95/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.9498 - val_loss: 0.2953 - val_accuracy: 0.9054\n",
            "Epoch 96/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1252 - accuracy: 0.9520 - val_loss: 0.3036 - val_accuracy: 0.9064\n",
            "Epoch 97/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9517 - val_loss: 0.3124 - val_accuracy: 0.9086\n",
            "Epoch 98/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.9533 - val_loss: 0.2964 - val_accuracy: 0.9110\n",
            "Epoch 99/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9525 - val_loss: 0.3000 - val_accuracy: 0.9124\n",
            "Epoch 100/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1235 - accuracy: 0.9525 - val_loss: 0.3032 - val_accuracy: 0.9066\n",
            "Epoch 101/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1231 - accuracy: 0.9522 - val_loss: 0.3123 - val_accuracy: 0.9062\n",
            "Epoch 102/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1237 - accuracy: 0.9530 - val_loss: 0.3049 - val_accuracy: 0.9102\n",
            "Epoch 103/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.9545 - val_loss: 0.3115 - val_accuracy: 0.9072\n",
            "Epoch 104/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9540 - val_loss: 0.3086 - val_accuracy: 0.9126\n",
            "Epoch 105/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1196 - accuracy: 0.9536 - val_loss: 0.3016 - val_accuracy: 0.9126\n",
            "Epoch 106/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.9548 - val_loss: 0.3072 - val_accuracy: 0.9098\n",
            "Epoch 107/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1200 - accuracy: 0.9541 - val_loss: 0.3223 - val_accuracy: 0.9092\n",
            "Epoch 108/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1166 - accuracy: 0.9551 - val_loss: 0.3185 - val_accuracy: 0.9092\n",
            "Epoch 109/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9564 - val_loss: 0.3085 - val_accuracy: 0.9112\n",
            "Epoch 110/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1132 - accuracy: 0.9570 - val_loss: 0.3090 - val_accuracy: 0.9104\n",
            "Epoch 111/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.9550 - val_loss: 0.3083 - val_accuracy: 0.9108\n",
            "Epoch 112/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.9568 - val_loss: 0.3127 - val_accuracy: 0.9034\n",
            "Epoch 113/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.9558 - val_loss: 0.3200 - val_accuracy: 0.9076\n",
            "Epoch 114/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9565 - val_loss: 0.3275 - val_accuracy: 0.9082\n",
            "Epoch 115/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1137 - accuracy: 0.9559 - val_loss: 0.3154 - val_accuracy: 0.9040\n",
            "Epoch 116/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9572 - val_loss: 0.3170 - val_accuracy: 0.9074\n",
            "Epoch 117/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1127 - accuracy: 0.9566 - val_loss: 0.3091 - val_accuracy: 0.9088\n",
            "Epoch 118/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1115 - accuracy: 0.9566 - val_loss: 0.3269 - val_accuracy: 0.9092\n",
            "Epoch 119/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.9576 - val_loss: 0.3259 - val_accuracy: 0.9122\n",
            "Epoch 120/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9583 - val_loss: 0.3215 - val_accuracy: 0.9080\n",
            "Epoch 121/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1102 - accuracy: 0.9575 - val_loss: 0.3234 - val_accuracy: 0.9066\n",
            "Epoch 122/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9590 - val_loss: 0.3248 - val_accuracy: 0.9100\n",
            "Epoch 123/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1157 - accuracy: 0.9559 - val_loss: 0.3314 - val_accuracy: 0.9034\n",
            "Epoch 124/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9583 - val_loss: 0.3267 - val_accuracy: 0.9074\n",
            "Epoch 125/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1061 - accuracy: 0.9598 - val_loss: 0.3281 - val_accuracy: 0.9094\n",
            "Epoch 126/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1105 - accuracy: 0.9568 - val_loss: 0.3232 - val_accuracy: 0.9108\n",
            "Epoch 127/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1065 - accuracy: 0.9597 - val_loss: 0.3261 - val_accuracy: 0.9094\n",
            "Epoch 128/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1078 - accuracy: 0.9584 - val_loss: 0.3264 - val_accuracy: 0.9070\n",
            "Epoch 129/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9589 - val_loss: 0.3333 - val_accuracy: 0.9068\n",
            "Epoch 130/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9595 - val_loss: 0.3436 - val_accuracy: 0.9070\n",
            "Epoch 131/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1050 - accuracy: 0.9596 - val_loss: 0.3357 - val_accuracy: 0.9066\n",
            "Epoch 132/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.9597 - val_loss: 0.3328 - val_accuracy: 0.9076\n",
            "Epoch 133/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9606 - val_loss: 0.3389 - val_accuracy: 0.9098\n",
            "Epoch 134/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9604 - val_loss: 0.3412 - val_accuracy: 0.9084\n",
            "Epoch 135/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9610 - val_loss: 0.3432 - val_accuracy: 0.9046\n",
            "Epoch 136/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1042 - accuracy: 0.9597 - val_loss: 0.3278 - val_accuracy: 0.9114\n",
            "Epoch 137/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1018 - accuracy: 0.9604 - val_loss: 0.3415 - val_accuracy: 0.9100\n",
            "Epoch 138/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.9595 - val_loss: 0.3325 - val_accuracy: 0.9056\n",
            "Epoch 139/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9615 - val_loss: 0.3594 - val_accuracy: 0.9050\n",
            "Epoch 140/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0995 - accuracy: 0.9616 - val_loss: 0.3375 - val_accuracy: 0.9080\n",
            "Epoch 141/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9615 - val_loss: 0.3272 - val_accuracy: 0.9124\n",
            "Epoch 142/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9601 - val_loss: 0.3365 - val_accuracy: 0.9088\n",
            "Epoch 143/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9620 - val_loss: 0.3333 - val_accuracy: 0.9118\n",
            "Epoch 144/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9608 - val_loss: 0.3462 - val_accuracy: 0.9056\n",
            "Epoch 145/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0970 - accuracy: 0.9628 - val_loss: 0.3586 - val_accuracy: 0.9046\n",
            "Epoch 146/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9638 - val_loss: 0.3435 - val_accuracy: 0.9104\n",
            "Epoch 147/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 0.9641 - val_loss: 0.3380 - val_accuracy: 0.9080\n",
            "Epoch 148/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9621 - val_loss: 0.3497 - val_accuracy: 0.9098\n",
            "Epoch 149/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9623 - val_loss: 0.3485 - val_accuracy: 0.9126\n",
            "Epoch 150/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9628 - val_loss: 0.3454 - val_accuracy: 0.9072\n",
            "Epoch 151/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9645 - val_loss: 0.3497 - val_accuracy: 0.9112\n",
            "Epoch 152/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9636 - val_loss: 0.3480 - val_accuracy: 0.9100\n",
            "Epoch 153/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0937 - accuracy: 0.9637 - val_loss: 0.3526 - val_accuracy: 0.9052\n",
            "Epoch 154/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9650 - val_loss: 0.3543 - val_accuracy: 0.9076\n",
            "Epoch 155/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9640 - val_loss: 0.3554 - val_accuracy: 0.9112\n",
            "Epoch 156/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 0.9642 - val_loss: 0.3476 - val_accuracy: 0.9114\n",
            "Epoch 157/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0936 - accuracy: 0.9638 - val_loss: 0.3637 - val_accuracy: 0.9108\n",
            "Epoch 158/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0910 - accuracy: 0.9654 - val_loss: 0.3550 - val_accuracy: 0.9108\n",
            "Epoch 159/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9649 - val_loss: 0.3545 - val_accuracy: 0.9068\n",
            "Epoch 160/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9642 - val_loss: 0.3568 - val_accuracy: 0.9060\n",
            "Epoch 161/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9655 - val_loss: 0.3658 - val_accuracy: 0.9088\n",
            "Epoch 162/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0901 - accuracy: 0.9657 - val_loss: 0.3908 - val_accuracy: 0.9038\n",
            "Epoch 163/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.9649 - val_loss: 0.3491 - val_accuracy: 0.9082\n",
            "Epoch 164/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9665 - val_loss: 0.3464 - val_accuracy: 0.9100\n",
            "Epoch 165/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9657 - val_loss: 0.3567 - val_accuracy: 0.9062\n",
            "Epoch 166/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9657 - val_loss: 0.3669 - val_accuracy: 0.9026\n",
            "Epoch 167/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.9660 - val_loss: 0.3681 - val_accuracy: 0.9086\n",
            "Epoch 168/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9661 - val_loss: 0.3649 - val_accuracy: 0.9084\n",
            "Epoch 169/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9674 - val_loss: 0.3651 - val_accuracy: 0.9076\n",
            "Epoch 170/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0863 - accuracy: 0.9662 - val_loss: 0.3752 - val_accuracy: 0.9056\n",
            "Epoch 171/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9661 - val_loss: 0.3676 - val_accuracy: 0.9076\n",
            "Epoch 172/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9670 - val_loss: 0.3817 - val_accuracy: 0.9062\n",
            "Epoch 173/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9675 - val_loss: 0.3774 - val_accuracy: 0.9060\n",
            "Epoch 174/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9673 - val_loss: 0.3730 - val_accuracy: 0.9106\n",
            "Epoch 175/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9667 - val_loss: 0.3768 - val_accuracy: 0.9082\n",
            "Epoch 176/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9666 - val_loss: 0.3913 - val_accuracy: 0.9066\n",
            "Epoch 177/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0861 - accuracy: 0.9664 - val_loss: 0.3822 - val_accuracy: 0.9018\n",
            "Epoch 178/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9671 - val_loss: 0.3840 - val_accuracy: 0.9046\n",
            "Epoch 179/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0846 - accuracy: 0.9680 - val_loss: 0.3864 - val_accuracy: 0.9042\n",
            "Epoch 180/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.3740 - val_accuracy: 0.9086\n",
            "Epoch 181/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0860 - accuracy: 0.9666 - val_loss: 0.3794 - val_accuracy: 0.9072\n",
            "Epoch 182/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9674 - val_loss: 0.3711 - val_accuracy: 0.9084\n",
            "Epoch 183/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9672 - val_loss: 0.3962 - val_accuracy: 0.9028\n",
            "Epoch 184/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0831 - accuracy: 0.9680 - val_loss: 0.3908 - val_accuracy: 0.9072\n",
            "Epoch 185/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9674 - val_loss: 0.3820 - val_accuracy: 0.9086\n",
            "Epoch 186/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9683 - val_loss: 0.3839 - val_accuracy: 0.9078\n",
            "Epoch 187/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9680 - val_loss: 0.3873 - val_accuracy: 0.9070\n",
            "Epoch 188/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0821 - accuracy: 0.9691 - val_loss: 0.4002 - val_accuracy: 0.9046\n",
            "Epoch 189/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0795 - accuracy: 0.9693 - val_loss: 0.3905 - val_accuracy: 0.9096\n",
            "Epoch 190/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9693 - val_loss: 0.3798 - val_accuracy: 0.9066\n",
            "Epoch 191/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.9691 - val_loss: 0.3853 - val_accuracy: 0.9036\n",
            "Epoch 192/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9692 - val_loss: 0.3936 - val_accuracy: 0.9060\n",
            "Epoch 193/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9684 - val_loss: 0.3780 - val_accuracy: 0.9070\n",
            "Epoch 194/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9702 - val_loss: 0.3916 - val_accuracy: 0.9090\n",
            "Epoch 195/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9693 - val_loss: 0.3953 - val_accuracy: 0.9056\n",
            "Epoch 196/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9705 - val_loss: 0.3975 - val_accuracy: 0.9052\n",
            "Epoch 197/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9694 - val_loss: 0.3815 - val_accuracy: 0.9078\n",
            "Epoch 198/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0813 - accuracy: 0.9687 - val_loss: 0.3818 - val_accuracy: 0.9058\n",
            "Epoch 199/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.3988 - val_accuracy: 0.9084\n",
            "Epoch 200/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0828 - accuracy: 0.9689 - val_loss: 0.3868 - val_accuracy: 0.9032\n",
            "Epoch 201/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9702 - val_loss: 0.3978 - val_accuracy: 0.9066\n",
            "Epoch 202/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0804 - accuracy: 0.9696 - val_loss: 0.3856 - val_accuracy: 0.9092\n",
            "Epoch 203/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9705 - val_loss: 0.4090 - val_accuracy: 0.9052\n",
            "Epoch 204/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9690 - val_loss: 0.3979 - val_accuracy: 0.9040\n",
            "Epoch 205/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9700 - val_loss: 0.4009 - val_accuracy: 0.9084\n",
            "Epoch 206/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9707 - val_loss: 0.3745 - val_accuracy: 0.9104\n",
            "Epoch 207/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9712 - val_loss: 0.4078 - val_accuracy: 0.9076\n",
            "Epoch 208/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9697 - val_loss: 0.4133 - val_accuracy: 0.9040\n",
            "Epoch 209/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.4005 - val_accuracy: 0.9072\n",
            "Epoch 210/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9696 - val_loss: 0.3866 - val_accuracy: 0.9094\n",
            "Epoch 211/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9717 - val_loss: 0.4023 - val_accuracy: 0.9084\n",
            "Epoch 212/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9711 - val_loss: 0.3892 - val_accuracy: 0.9074\n",
            "Epoch 213/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9716 - val_loss: 0.3999 - val_accuracy: 0.9060\n",
            "Epoch 214/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9718 - val_loss: 0.4042 - val_accuracy: 0.9066\n",
            "Epoch 215/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9713 - val_loss: 0.4234 - val_accuracy: 0.9050\n",
            "Epoch 216/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9721 - val_loss: 0.4180 - val_accuracy: 0.9018\n",
            "Epoch 217/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9709 - val_loss: 0.4005 - val_accuracy: 0.9078\n",
            "Epoch 218/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9722 - val_loss: 0.3974 - val_accuracy: 0.9088\n",
            "Epoch 219/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9722 - val_loss: 0.3956 - val_accuracy: 0.9084\n",
            "Epoch 220/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0729 - accuracy: 0.9725 - val_loss: 0.4090 - val_accuracy: 0.9064\n",
            "Epoch 221/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9726 - val_loss: 0.4149 - val_accuracy: 0.9070\n",
            "Epoch 222/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9733 - val_loss: 0.4101 - val_accuracy: 0.9080\n",
            "Epoch 223/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9725 - val_loss: 0.4152 - val_accuracy: 0.9068\n",
            "Epoch 224/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0740 - accuracy: 0.9716 - val_loss: 0.4208 - val_accuracy: 0.9074\n",
            "Epoch 225/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9726 - val_loss: 0.4227 - val_accuracy: 0.9052\n",
            "Epoch 226/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0726 - accuracy: 0.9729 - val_loss: 0.4199 - val_accuracy: 0.9080\n",
            "Epoch 227/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0727 - accuracy: 0.9721 - val_loss: 0.4072 - val_accuracy: 0.9072\n",
            "Epoch 228/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9730 - val_loss: 0.4070 - val_accuracy: 0.9098\n",
            "Epoch 229/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0723 - accuracy: 0.9723 - val_loss: 0.3945 - val_accuracy: 0.9092\n",
            "Epoch 230/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9722 - val_loss: 0.4207 - val_accuracy: 0.9038\n",
            "Epoch 231/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.4077 - val_accuracy: 0.9066\n",
            "Epoch 232/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9725 - val_loss: 0.4186 - val_accuracy: 0.9088\n",
            "Epoch 233/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9743 - val_loss: 0.4001 - val_accuracy: 0.9090\n",
            "Epoch 234/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9727 - val_loss: 0.3987 - val_accuracy: 0.9098\n",
            "Epoch 235/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0717 - accuracy: 0.9731 - val_loss: 0.4125 - val_accuracy: 0.9052\n",
            "Epoch 236/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9725 - val_loss: 0.4204 - val_accuracy: 0.9044\n",
            "Epoch 237/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9731 - val_loss: 0.4219 - val_accuracy: 0.9096\n",
            "Epoch 238/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9733 - val_loss: 0.4182 - val_accuracy: 0.9036\n",
            "Epoch 239/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9730 - val_loss: 0.4305 - val_accuracy: 0.9048\n",
            "Epoch 240/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9738 - val_loss: 0.4253 - val_accuracy: 0.9090\n",
            "Epoch 241/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9740 - val_loss: 0.4203 - val_accuracy: 0.9044\n",
            "Epoch 242/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9739 - val_loss: 0.4387 - val_accuracy: 0.9068\n",
            "Epoch 243/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9743 - val_loss: 0.4206 - val_accuracy: 0.9066\n",
            "Epoch 244/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9733 - val_loss: 0.4218 - val_accuracy: 0.9068\n",
            "Epoch 245/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9750 - val_loss: 0.4144 - val_accuracy: 0.9068\n",
            "Epoch 246/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9736 - val_loss: 0.4166 - val_accuracy: 0.9064\n",
            "Epoch 247/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9740 - val_loss: 0.4334 - val_accuracy: 0.9028\n",
            "Epoch 248/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9723 - val_loss: 0.4268 - val_accuracy: 0.9034\n",
            "Epoch 249/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9743 - val_loss: 0.4189 - val_accuracy: 0.9068\n",
            "Epoch 250/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9745 - val_loss: 0.4197 - val_accuracy: 0.9118\n",
            "Epoch 251/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9745 - val_loss: 0.4382 - val_accuracy: 0.9088\n",
            "Epoch 252/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9743 - val_loss: 0.4229 - val_accuracy: 0.9034\n",
            "Epoch 253/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9738 - val_loss: 0.4442 - val_accuracy: 0.9100\n",
            "Epoch 254/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9746 - val_loss: 0.4483 - val_accuracy: 0.9034\n",
            "Epoch 255/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9758 - val_loss: 0.4148 - val_accuracy: 0.9080\n",
            "Epoch 256/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9751 - val_loss: 0.4160 - val_accuracy: 0.9086\n",
            "Epoch 257/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9754 - val_loss: 0.4516 - val_accuracy: 0.9052\n",
            "Epoch 258/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0658 - accuracy: 0.9752 - val_loss: 0.4432 - val_accuracy: 0.9094\n",
            "Epoch 259/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9746 - val_loss: 0.4385 - val_accuracy: 0.9032\n",
            "Epoch 260/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9752 - val_loss: 0.4243 - val_accuracy: 0.9054\n",
            "Epoch 261/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9756 - val_loss: 0.4158 - val_accuracy: 0.9088\n",
            "Epoch 262/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9757 - val_loss: 0.4181 - val_accuracy: 0.9090\n",
            "Epoch 263/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0673 - accuracy: 0.9742 - val_loss: 0.4422 - val_accuracy: 0.9032\n",
            "Epoch 264/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9754 - val_loss: 0.4316 - val_accuracy: 0.9048\n",
            "Epoch 265/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9745 - val_loss: 0.4345 - val_accuracy: 0.9062\n",
            "Epoch 266/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0635 - accuracy: 0.9766 - val_loss: 0.4305 - val_accuracy: 0.9096\n",
            "Epoch 267/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9758 - val_loss: 0.4461 - val_accuracy: 0.9032\n",
            "Epoch 268/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9761 - val_loss: 0.4519 - val_accuracy: 0.9060\n",
            "Epoch 269/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0655 - accuracy: 0.9746 - val_loss: 0.4513 - val_accuracy: 0.9070\n",
            "Epoch 270/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9766 - val_loss: 0.4343 - val_accuracy: 0.9066\n",
            "Epoch 271/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9764 - val_loss: 0.4262 - val_accuracy: 0.9038\n",
            "Epoch 272/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9758 - val_loss: 0.4378 - val_accuracy: 0.9030\n",
            "Epoch 273/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9774 - val_loss: 0.4477 - val_accuracy: 0.9082\n",
            "Epoch 274/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9768 - val_loss: 0.4494 - val_accuracy: 0.9080\n",
            "Epoch 275/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9750 - val_loss: 0.4229 - val_accuracy: 0.9078\n",
            "Epoch 276/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0641 - accuracy: 0.9754 - val_loss: 0.4213 - val_accuracy: 0.9086\n",
            "Epoch 277/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9757 - val_loss: 0.4573 - val_accuracy: 0.9066\n",
            "Epoch 278/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0653 - accuracy: 0.9753 - val_loss: 0.4371 - val_accuracy: 0.9044\n",
            "Epoch 279/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9763 - val_loss: 0.4457 - val_accuracy: 0.9026\n",
            "Epoch 280/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0622 - accuracy: 0.9768 - val_loss: 0.4451 - val_accuracy: 0.9066\n",
            "Epoch 281/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9781 - val_loss: 0.4316 - val_accuracy: 0.9084\n",
            "Epoch 282/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9768 - val_loss: 0.4493 - val_accuracy: 0.9030\n",
            "Epoch 283/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9782 - val_loss: 0.4322 - val_accuracy: 0.9050\n",
            "Epoch 284/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0627 - accuracy: 0.9759 - val_loss: 0.4318 - val_accuracy: 0.9028\n",
            "Epoch 285/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0629 - accuracy: 0.9758 - val_loss: 0.4460 - val_accuracy: 0.9034\n",
            "Epoch 286/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9779 - val_loss: 0.4496 - val_accuracy: 0.9060\n",
            "Epoch 287/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9771 - val_loss: 0.4487 - val_accuracy: 0.9074\n",
            "Epoch 288/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9766 - val_loss: 0.4448 - val_accuracy: 0.9078\n",
            "Epoch 289/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9774 - val_loss: 0.4542 - val_accuracy: 0.9056\n",
            "Epoch 290/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9775 - val_loss: 0.4621 - val_accuracy: 0.9040\n",
            "Epoch 291/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0592 - accuracy: 0.9776 - val_loss: 0.4601 - val_accuracy: 0.9058\n",
            "Epoch 292/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9777 - val_loss: 0.4495 - val_accuracy: 0.9116\n",
            "Epoch 293/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9774 - val_loss: 0.4606 - val_accuracy: 0.9004\n",
            "Epoch 294/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0587 - accuracy: 0.9779 - val_loss: 0.4578 - val_accuracy: 0.9056\n",
            "Epoch 295/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9777 - val_loss: 0.4543 - val_accuracy: 0.9038\n",
            "Epoch 296/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9783 - val_loss: 0.4631 - val_accuracy: 0.9050\n",
            "Epoch 297/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9782 - val_loss: 0.4705 - val_accuracy: 0.9054\n",
            "Epoch 298/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9766 - val_loss: 0.4567 - val_accuracy: 0.9036\n",
            "Epoch 299/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9770 - val_loss: 0.4587 - val_accuracy: 0.9030\n",
            "Epoch 300/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9766 - val_loss: 0.4544 - val_accuracy: 0.9072\n",
            "Epoch 301/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9767 - val_loss: 0.4674 - val_accuracy: 0.9062\n",
            "Epoch 302/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9791 - val_loss: 0.4880 - val_accuracy: 0.9038\n",
            "Epoch 303/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9784 - val_loss: 0.4683 - val_accuracy: 0.9046\n",
            "Epoch 304/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9778 - val_loss: 0.4695 - val_accuracy: 0.9024\n",
            "Epoch 305/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9799 - val_loss: 0.4733 - val_accuracy: 0.9052\n",
            "Epoch 306/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9783 - val_loss: 0.4882 - val_accuracy: 0.9068\n",
            "Epoch 307/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9776 - val_loss: 0.4743 - val_accuracy: 0.9032\n",
            "Epoch 308/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9781 - val_loss: 0.4761 - val_accuracy: 0.9040\n",
            "Epoch 309/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9761 - val_loss: 0.4848 - val_accuracy: 0.9040\n",
            "Epoch 310/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9777 - val_loss: 0.4790 - val_accuracy: 0.8994\n",
            "Epoch 311/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9785 - val_loss: 0.4710 - val_accuracy: 0.9052\n",
            "Epoch 312/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9790 - val_loss: 0.4935 - val_accuracy: 0.9064\n",
            "Epoch 313/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9782 - val_loss: 0.4747 - val_accuracy: 0.9080\n",
            "Epoch 314/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0561 - accuracy: 0.9788 - val_loss: 0.4892 - val_accuracy: 0.9016\n",
            "Epoch 315/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9777 - val_loss: 0.4859 - val_accuracy: 0.9066\n",
            "Epoch 316/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9784 - val_loss: 0.4894 - val_accuracy: 0.9054\n",
            "Epoch 317/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9774 - val_loss: 0.4897 - val_accuracy: 0.9020\n",
            "Epoch 318/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9773 - val_loss: 0.4886 - val_accuracy: 0.9020\n",
            "Epoch 319/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0581 - accuracy: 0.9783 - val_loss: 0.4797 - val_accuracy: 0.9054\n",
            "Epoch 320/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9781 - val_loss: 0.4749 - val_accuracy: 0.9072\n",
            "Epoch 321/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9792 - val_loss: 0.4711 - val_accuracy: 0.9054\n",
            "Epoch 322/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9775 - val_loss: 0.4783 - val_accuracy: 0.9064\n",
            "Epoch 323/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9789 - val_loss: 0.4789 - val_accuracy: 0.9046\n",
            "Epoch 324/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9776 - val_loss: 0.4665 - val_accuracy: 0.9064\n",
            "Epoch 325/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0582 - accuracy: 0.9773 - val_loss: 0.4824 - val_accuracy: 0.9038\n",
            "Epoch 326/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9788 - val_loss: 0.4974 - val_accuracy: 0.9044\n",
            "Epoch 327/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9801 - val_loss: 0.4860 - val_accuracy: 0.9024\n",
            "Epoch 328/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9787 - val_loss: 0.4946 - val_accuracy: 0.9040\n",
            "Epoch 329/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9800 - val_loss: 0.4909 - val_accuracy: 0.9062\n",
            "Epoch 330/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9807 - val_loss: 0.4968 - val_accuracy: 0.9032\n",
            "Epoch 331/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9788 - val_loss: 0.4803 - val_accuracy: 0.9010\n",
            "Epoch 332/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9784 - val_loss: 0.4738 - val_accuracy: 0.9074\n",
            "Epoch 333/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9795 - val_loss: 0.4907 - val_accuracy: 0.9066\n",
            "Epoch 334/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9795 - val_loss: 0.5001 - val_accuracy: 0.9034\n",
            "Epoch 335/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9800 - val_loss: 0.4623 - val_accuracy: 0.9066\n",
            "Epoch 336/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9803 - val_loss: 0.4811 - val_accuracy: 0.9056\n",
            "Epoch 337/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 0.4777 - val_accuracy: 0.8994\n",
            "Epoch 338/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9789 - val_loss: 0.4988 - val_accuracy: 0.9050\n",
            "Epoch 339/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9800 - val_loss: 0.4702 - val_accuracy: 0.9054\n",
            "Epoch 340/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9799 - val_loss: 0.5164 - val_accuracy: 0.9054\n",
            "Epoch 341/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9796 - val_loss: 0.4744 - val_accuracy: 0.9038\n",
            "Epoch 342/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0536 - accuracy: 0.9798 - val_loss: 0.4937 - val_accuracy: 0.9068\n",
            "Epoch 343/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9799 - val_loss: 0.4811 - val_accuracy: 0.9024\n",
            "Epoch 344/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9796 - val_loss: 0.5195 - val_accuracy: 0.9024\n",
            "Epoch 345/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9788 - val_loss: 0.4837 - val_accuracy: 0.9042\n",
            "Epoch 346/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9802 - val_loss: 0.4820 - val_accuracy: 0.9068\n",
            "Epoch 347/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9797 - val_loss: 0.5236 - val_accuracy: 0.9050\n",
            "Epoch 348/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9791 - val_loss: 0.4817 - val_accuracy: 0.9058\n",
            "Epoch 349/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9813 - val_loss: 0.4964 - val_accuracy: 0.9076\n",
            "Epoch 350/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9812 - val_loss: 0.4916 - val_accuracy: 0.9058\n",
            "Epoch 351/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9802 - val_loss: 0.4997 - val_accuracy: 0.9044\n",
            "Epoch 352/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9795 - val_loss: 0.4847 - val_accuracy: 0.9036\n",
            "Epoch 353/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0515 - accuracy: 0.9808 - val_loss: 0.4954 - val_accuracy: 0.9044\n",
            "Epoch 354/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 0.9802 - val_loss: 0.5004 - val_accuracy: 0.9084\n",
            "Epoch 355/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9807 - val_loss: 0.5089 - val_accuracy: 0.9070\n",
            "Epoch 356/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9801 - val_loss: 0.4955 - val_accuracy: 0.9098\n",
            "Epoch 357/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9808 - val_loss: 0.4959 - val_accuracy: 0.9058\n",
            "Epoch 358/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.5211 - val_accuracy: 0.9032\n",
            "Epoch 359/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0528 - accuracy: 0.9801 - val_loss: 0.4860 - val_accuracy: 0.9044\n",
            "Epoch 360/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9798 - val_loss: 0.4964 - val_accuracy: 0.9036\n",
            "Epoch 361/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9796 - val_loss: 0.5077 - val_accuracy: 0.9070\n",
            "Epoch 362/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9807 - val_loss: 0.4691 - val_accuracy: 0.9062\n",
            "Epoch 363/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9797 - val_loss: 0.5001 - val_accuracy: 0.9060\n",
            "Epoch 364/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9803 - val_loss: 0.5051 - val_accuracy: 0.9028\n",
            "Epoch 365/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0516 - accuracy: 0.9802 - val_loss: 0.5000 - val_accuracy: 0.9018\n",
            "Epoch 366/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.5122 - val_accuracy: 0.9056\n",
            "Epoch 367/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9799 - val_loss: 0.4902 - val_accuracy: 0.9022\n",
            "Epoch 368/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9814 - val_loss: 0.5112 - val_accuracy: 0.9016\n",
            "Epoch 369/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9809 - val_loss: 0.5128 - val_accuracy: 0.9034\n",
            "Epoch 370/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0510 - accuracy: 0.9810 - val_loss: 0.5165 - val_accuracy: 0.9030\n",
            "Epoch 371/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0495 - accuracy: 0.9813 - val_loss: 0.5305 - val_accuracy: 0.9032\n",
            "Epoch 372/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0497 - accuracy: 0.9813 - val_loss: 0.5047 - val_accuracy: 0.9036\n",
            "Epoch 373/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9816 - val_loss: 0.5134 - val_accuracy: 0.9034\n",
            "Epoch 374/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 0.4997 - val_accuracy: 0.9036\n",
            "Epoch 375/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.5299 - val_accuracy: 0.9056\n",
            "Epoch 376/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9809 - val_loss: 0.5168 - val_accuracy: 0.9056\n",
            "Epoch 377/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9814 - val_loss: 0.5192 - val_accuracy: 0.9010\n",
            "Epoch 378/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9811 - val_loss: 0.5034 - val_accuracy: 0.9040\n",
            "Epoch 379/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9813 - val_loss: 0.4989 - val_accuracy: 0.9044\n",
            "Epoch 380/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9811 - val_loss: 0.4988 - val_accuracy: 0.9058\n",
            "Epoch 381/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9812 - val_loss: 0.5084 - val_accuracy: 0.9096\n",
            "Epoch 382/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0508 - accuracy: 0.9808 - val_loss: 0.5146 - val_accuracy: 0.9046\n",
            "Epoch 383/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9824 - val_loss: 0.5101 - val_accuracy: 0.9090\n",
            "Epoch 384/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 0.5098 - val_accuracy: 0.9068\n",
            "Epoch 385/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9828 - val_loss: 0.5091 - val_accuracy: 0.9056\n",
            "Epoch 386/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0501 - accuracy: 0.9816 - val_loss: 0.5506 - val_accuracy: 0.8978\n",
            "Epoch 387/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9813 - val_loss: 0.5284 - val_accuracy: 0.9016\n",
            "Epoch 388/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0481 - accuracy: 0.9818 - val_loss: 0.5431 - val_accuracy: 0.9034\n",
            "Epoch 389/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9824 - val_loss: 0.5159 - val_accuracy: 0.9072\n",
            "Epoch 390/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9816 - val_loss: 0.5226 - val_accuracy: 0.9052\n",
            "Epoch 391/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9815 - val_loss: 0.5496 - val_accuracy: 0.9006\n",
            "Epoch 392/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9814 - val_loss: 0.5347 - val_accuracy: 0.9078\n",
            "Epoch 393/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9808 - val_loss: 0.4907 - val_accuracy: 0.9068\n",
            "Epoch 394/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9817 - val_loss: 0.5252 - val_accuracy: 0.9068\n",
            "Epoch 395/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9826 - val_loss: 0.5156 - val_accuracy: 0.9054\n",
            "Epoch 396/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9804 - val_loss: 0.5359 - val_accuracy: 0.9028\n",
            "Epoch 397/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9817 - val_loss: 0.5116 - val_accuracy: 0.9060\n",
            "Epoch 398/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9811 - val_loss: 0.5231 - val_accuracy: 0.9056\n",
            "Epoch 399/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9828 - val_loss: 0.5543 - val_accuracy: 0.9036\n",
            "Epoch 400/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9818 - val_loss: 0.5390 - val_accuracy: 0.8998\n",
            "Epoch 401/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9823 - val_loss: 0.5265 - val_accuracy: 0.9028\n",
            "Epoch 402/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0493 - accuracy: 0.9817 - val_loss: 0.5259 - val_accuracy: 0.9010\n",
            "Epoch 403/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9820 - val_loss: 0.5361 - val_accuracy: 0.9034\n",
            "Epoch 404/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9811 - val_loss: 0.5322 - val_accuracy: 0.8988\n",
            "Epoch 405/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9815 - val_loss: 0.5148 - val_accuracy: 0.9044\n",
            "Epoch 406/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9828 - val_loss: 0.5298 - val_accuracy: 0.9028\n",
            "Epoch 407/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9830 - val_loss: 0.5269 - val_accuracy: 0.9054\n",
            "Epoch 408/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.5329 - val_accuracy: 0.9050\n",
            "Epoch 409/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9829 - val_loss: 0.5171 - val_accuracy: 0.9022\n",
            "Epoch 410/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9824 - val_loss: 0.5137 - val_accuracy: 0.9088\n",
            "Epoch 411/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9827 - val_loss: 0.5146 - val_accuracy: 0.9054\n",
            "Epoch 412/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0494 - accuracy: 0.9820 - val_loss: 0.5104 - val_accuracy: 0.9000\n",
            "Epoch 413/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0458 - accuracy: 0.9829 - val_loss: 0.5378 - val_accuracy: 0.9034\n",
            "Epoch 414/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9829 - val_loss: 0.5364 - val_accuracy: 0.9018\n",
            "Epoch 415/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 0.5042 - val_accuracy: 0.9056\n",
            "Epoch 416/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9823 - val_loss: 0.5262 - val_accuracy: 0.9050\n",
            "Epoch 417/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9832 - val_loss: 0.5443 - val_accuracy: 0.9026\n",
            "Epoch 418/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 0.5394 - val_accuracy: 0.9030\n",
            "Epoch 419/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9816 - val_loss: 0.5154 - val_accuracy: 0.9042\n",
            "Epoch 420/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9832 - val_loss: 0.5356 - val_accuracy: 0.9008\n",
            "Epoch 421/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9827 - val_loss: 0.5116 - val_accuracy: 0.9050\n",
            "Epoch 422/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9826 - val_loss: 0.5284 - val_accuracy: 0.9066\n",
            "Epoch 423/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0529 - accuracy: 0.9801 - val_loss: 0.5148 - val_accuracy: 0.9056\n",
            "Epoch 424/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0475 - accuracy: 0.9819 - val_loss: 0.5439 - val_accuracy: 0.9064\n",
            "Epoch 425/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.5302 - val_accuracy: 0.9052\n",
            "Epoch 426/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0447 - accuracy: 0.9835 - val_loss: 0.5416 - val_accuracy: 0.9046\n",
            "Epoch 427/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9837 - val_loss: 0.5130 - val_accuracy: 0.9016\n",
            "Epoch 428/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 0.5442 - val_accuracy: 0.9066\n",
            "Epoch 429/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9820 - val_loss: 0.5411 - val_accuracy: 0.9022\n",
            "Epoch 430/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9829 - val_loss: 0.5322 - val_accuracy: 0.9034\n",
            "Epoch 431/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9833 - val_loss: 0.5360 - val_accuracy: 0.9048\n",
            "Epoch 432/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9837 - val_loss: 0.5337 - val_accuracy: 0.9056\n",
            "Epoch 433/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0460 - accuracy: 0.9829 - val_loss: 0.5360 - val_accuracy: 0.9044\n",
            "Epoch 434/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9824 - val_loss: 0.5344 - val_accuracy: 0.9032\n",
            "Epoch 435/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0497 - accuracy: 0.9818 - val_loss: 0.5414 - val_accuracy: 0.9038\n",
            "Epoch 436/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9828 - val_loss: 0.5286 - val_accuracy: 0.9086\n",
            "Epoch 437/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0505 - accuracy: 0.9811 - val_loss: 0.5328 - val_accuracy: 0.9028\n",
            "Epoch 438/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0451 - accuracy: 0.9828 - val_loss: 0.5278 - val_accuracy: 0.9032\n",
            "Epoch 439/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 0.5179 - val_accuracy: 0.9030\n",
            "Epoch 440/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 0.5630 - val_accuracy: 0.9034\n",
            "Epoch 441/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0449 - accuracy: 0.9830 - val_loss: 0.5558 - val_accuracy: 0.9040\n",
            "Epoch 442/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9840 - val_loss: 0.5266 - val_accuracy: 0.9088\n",
            "Epoch 443/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9837 - val_loss: 0.5184 - val_accuracy: 0.9072\n",
            "Epoch 444/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9831 - val_loss: 0.5540 - val_accuracy: 0.9060\n",
            "Epoch 445/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9834 - val_loss: 0.5485 - val_accuracy: 0.9028\n",
            "Epoch 446/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9823 - val_loss: 0.5361 - val_accuracy: 0.9042\n",
            "Epoch 447/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.5349 - val_accuracy: 0.9052\n",
            "Epoch 448/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9823 - val_loss: 0.5291 - val_accuracy: 0.9036\n",
            "Epoch 449/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0438 - accuracy: 0.9839 - val_loss: 0.5381 - val_accuracy: 0.9032\n",
            "Epoch 450/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9823 - val_loss: 0.5559 - val_accuracy: 0.9006\n",
            "Epoch 451/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9838 - val_loss: 0.5312 - val_accuracy: 0.9008\n",
            "Epoch 452/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9832 - val_loss: 0.5550 - val_accuracy: 0.9038\n",
            "Epoch 453/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0441 - accuracy: 0.9835 - val_loss: 0.5307 - val_accuracy: 0.9032\n",
            "Epoch 454/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9836 - val_loss: 0.5398 - val_accuracy: 0.9058\n",
            "Epoch 455/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9835 - val_loss: 0.5453 - val_accuracy: 0.9034\n",
            "Epoch 456/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9833 - val_loss: 0.5522 - val_accuracy: 0.9032\n",
            "Epoch 457/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9840 - val_loss: 0.5463 - val_accuracy: 0.9050\n",
            "Epoch 458/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9855 - val_loss: 0.5647 - val_accuracy: 0.9048\n",
            "Epoch 459/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9837 - val_loss: 0.5270 - val_accuracy: 0.9014\n",
            "Epoch 460/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.5379 - val_accuracy: 0.9066\n",
            "Epoch 461/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9837 - val_loss: 0.5459 - val_accuracy: 0.9016\n",
            "Epoch 462/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9843 - val_loss: 0.5521 - val_accuracy: 0.9044\n",
            "Epoch 463/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9843 - val_loss: 0.5451 - val_accuracy: 0.9046\n",
            "Epoch 464/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9841 - val_loss: 0.5319 - val_accuracy: 0.9038\n",
            "Epoch 465/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9836 - val_loss: 0.5550 - val_accuracy: 0.9016\n",
            "Epoch 466/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9830 - val_loss: 0.5204 - val_accuracy: 0.9054\n",
            "Epoch 467/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9843 - val_loss: 0.5405 - val_accuracy: 0.9028\n",
            "Epoch 468/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9843 - val_loss: 0.5298 - val_accuracy: 0.9064\n",
            "Epoch 469/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0440 - accuracy: 0.9839 - val_loss: 0.5219 - val_accuracy: 0.9056\n",
            "Epoch 470/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9849 - val_loss: 0.5445 - val_accuracy: 0.9030\n",
            "Epoch 471/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9850 - val_loss: 0.5495 - val_accuracy: 0.9024\n",
            "Epoch 472/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9839 - val_loss: 0.5470 - val_accuracy: 0.9030\n",
            "Epoch 473/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9845 - val_loss: 0.5458 - val_accuracy: 0.9046\n",
            "Epoch 474/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9839 - val_loss: 0.5638 - val_accuracy: 0.9036\n",
            "Epoch 475/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9842 - val_loss: 0.5332 - val_accuracy: 0.9044\n",
            "Epoch 476/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9849 - val_loss: 0.5401 - val_accuracy: 0.9020\n",
            "Epoch 477/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9840 - val_loss: 0.5766 - val_accuracy: 0.9042\n",
            "Epoch 478/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9845 - val_loss: 0.5635 - val_accuracy: 0.9026\n",
            "Epoch 479/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9842 - val_loss: 0.5715 - val_accuracy: 0.9070\n",
            "Epoch 480/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9836 - val_loss: 0.5638 - val_accuracy: 0.9064\n",
            "Epoch 481/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9844 - val_loss: 0.5619 - val_accuracy: 0.9036\n",
            "Epoch 482/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9837 - val_loss: 0.5441 - val_accuracy: 0.9040\n",
            "Epoch 483/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9836 - val_loss: 0.5837 - val_accuracy: 0.9032\n",
            "Epoch 484/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9843 - val_loss: 0.5570 - val_accuracy: 0.9052\n",
            "Epoch 485/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9850 - val_loss: 0.5420 - val_accuracy: 0.9020\n",
            "Epoch 486/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 0.5486 - val_accuracy: 0.9054\n",
            "Epoch 487/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9843 - val_loss: 0.5603 - val_accuracy: 0.9030\n",
            "Epoch 488/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9860 - val_loss: 0.5785 - val_accuracy: 0.9030\n",
            "Epoch 489/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9840 - val_loss: 0.5645 - val_accuracy: 0.9010\n",
            "Epoch 490/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9846 - val_loss: 0.5595 - val_accuracy: 0.9014\n",
            "Epoch 491/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9835 - val_loss: 0.5544 - val_accuracy: 0.9020\n",
            "Epoch 492/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9851 - val_loss: 0.5707 - val_accuracy: 0.9052\n",
            "Epoch 493/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 0.5630 - val_accuracy: 0.9048\n",
            "Epoch 494/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9845 - val_loss: 0.5744 - val_accuracy: 0.9044\n",
            "Epoch 495/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.5835 - val_accuracy: 0.9012\n",
            "Epoch 496/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.5560 - val_accuracy: 0.9008\n",
            "Epoch 497/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0409 - accuracy: 0.9846 - val_loss: 0.5720 - val_accuracy: 0.9040\n",
            "Epoch 498/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0426 - accuracy: 0.9846 - val_loss: 0.5686 - val_accuracy: 0.9028\n",
            "Epoch 499/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9848 - val_loss: 0.5758 - val_accuracy: 0.9032\n",
            "Epoch 500/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0411 - accuracy: 0.9843 - val_loss: 0.5598 - val_accuracy: 0.9042\n",
            "Epoch 501/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.5597 - val_accuracy: 0.9038\n",
            "Epoch 502/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9853 - val_loss: 0.5498 - val_accuracy: 0.9074\n",
            "Epoch 503/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9845 - val_loss: 0.5611 - val_accuracy: 0.9034\n",
            "Epoch 504/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9851 - val_loss: 0.5906 - val_accuracy: 0.9042\n",
            "Epoch 505/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 0.5777 - val_accuracy: 0.9032\n",
            "Epoch 506/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9845 - val_loss: 0.5426 - val_accuracy: 0.9036\n",
            "Epoch 507/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9837 - val_loss: 0.5588 - val_accuracy: 0.9030\n",
            "Epoch 508/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0433 - accuracy: 0.9837 - val_loss: 0.5989 - val_accuracy: 0.9008\n",
            "Epoch 509/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 0.5837 - val_accuracy: 0.9048\n",
            "Epoch 510/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9846 - val_loss: 0.5818 - val_accuracy: 0.9012\n",
            "Epoch 511/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9843 - val_loss: 0.5643 - val_accuracy: 0.9078\n",
            "Epoch 512/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 0.5743 - val_accuracy: 0.9070\n",
            "Epoch 513/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9843 - val_loss: 0.5775 - val_accuracy: 0.9040\n",
            "Epoch 514/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9849 - val_loss: 0.5554 - val_accuracy: 0.9036\n",
            "Epoch 515/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9850 - val_loss: 0.5863 - val_accuracy: 0.9012\n",
            "Epoch 516/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9850 - val_loss: 0.5722 - val_accuracy: 0.9054\n",
            "Epoch 517/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9853 - val_loss: 0.5497 - val_accuracy: 0.9028\n",
            "Epoch 518/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9858 - val_loss: 0.5731 - val_accuracy: 0.9054\n",
            "Epoch 519/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 0.5681 - val_accuracy: 0.9036\n",
            "Epoch 520/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9845 - val_loss: 0.5725 - val_accuracy: 0.9060\n",
            "Epoch 521/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 0.5932 - val_accuracy: 0.9010\n",
            "Epoch 522/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0404 - accuracy: 0.9845 - val_loss: 0.5744 - val_accuracy: 0.9016\n",
            "Epoch 523/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9855 - val_loss: 0.5694 - val_accuracy: 0.9074\n",
            "Epoch 524/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0424 - accuracy: 0.9841 - val_loss: 0.5813 - val_accuracy: 0.9014\n",
            "Epoch 525/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9856 - val_loss: 0.5770 - val_accuracy: 0.9014\n",
            "Epoch 526/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9857 - val_loss: 0.5959 - val_accuracy: 0.9014\n",
            "Epoch 527/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.5958 - val_accuracy: 0.9032\n",
            "Epoch 528/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9854 - val_loss: 0.5908 - val_accuracy: 0.9040\n",
            "Epoch 529/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.5747 - val_accuracy: 0.9040\n",
            "Epoch 530/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.5893 - val_accuracy: 0.9018\n",
            "Epoch 531/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9853 - val_loss: 0.5866 - val_accuracy: 0.9010\n",
            "Epoch 532/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9852 - val_loss: 0.5763 - val_accuracy: 0.9064\n",
            "Epoch 533/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9852 - val_loss: 0.5896 - val_accuracy: 0.9028\n",
            "Epoch 534/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9860 - val_loss: 0.5731 - val_accuracy: 0.9044\n",
            "Epoch 535/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9858 - val_loss: 0.5779 - val_accuracy: 0.9020\n",
            "Epoch 536/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0408 - accuracy: 0.9853 - val_loss: 0.5823 - val_accuracy: 0.9046\n",
            "Epoch 537/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 0.5982 - val_accuracy: 0.9006\n",
            "Epoch 538/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.5676 - val_accuracy: 0.9042\n",
            "Epoch 539/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.5778 - val_accuracy: 0.9036\n",
            "Epoch 540/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9857 - val_loss: 0.5845 - val_accuracy: 0.9044\n",
            "Epoch 541/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.6109 - val_accuracy: 0.9006\n",
            "Epoch 542/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 0.5816 - val_accuracy: 0.9054\n",
            "Epoch 543/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9858 - val_loss: 0.5788 - val_accuracy: 0.9040\n",
            "Epoch 544/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9858 - val_loss: 0.5663 - val_accuracy: 0.9040\n",
            "Epoch 545/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9863 - val_loss: 0.5864 - val_accuracy: 0.8992\n",
            "Epoch 546/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9867 - val_loss: 0.6158 - val_accuracy: 0.8988\n",
            "Epoch 547/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9854 - val_loss: 0.5929 - val_accuracy: 0.8990\n",
            "Epoch 548/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.5789 - val_accuracy: 0.9070\n",
            "Epoch 549/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.5832 - val_accuracy: 0.9058\n",
            "Epoch 550/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 0.5867 - val_accuracy: 0.9012\n",
            "Epoch 551/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9853 - val_loss: 0.5839 - val_accuracy: 0.9058\n",
            "Epoch 552/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9863 - val_loss: 0.6173 - val_accuracy: 0.9024\n",
            "Epoch 553/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9858 - val_loss: 0.6054 - val_accuracy: 0.9030\n",
            "Epoch 554/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0401 - accuracy: 0.9852 - val_loss: 0.5939 - val_accuracy: 0.9036\n",
            "Epoch 555/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9858 - val_loss: 0.5762 - val_accuracy: 0.9046\n",
            "Epoch 556/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9858 - val_loss: 0.5854 - val_accuracy: 0.9026\n",
            "Epoch 557/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9861 - val_loss: 0.6131 - val_accuracy: 0.9024\n",
            "Epoch 558/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9863 - val_loss: 0.6018 - val_accuracy: 0.9028\n",
            "Epoch 559/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9853 - val_loss: 0.5721 - val_accuracy: 0.9046\n",
            "Epoch 560/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9860 - val_loss: 0.5807 - val_accuracy: 0.9046\n",
            "Epoch 561/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9857 - val_loss: 0.5772 - val_accuracy: 0.9032\n",
            "Epoch 562/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9859 - val_loss: 0.5710 - val_accuracy: 0.9020\n",
            "Epoch 563/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9854 - val_loss: 0.5862 - val_accuracy: 0.9026\n",
            "Epoch 564/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9874 - val_loss: 0.6031 - val_accuracy: 0.9052\n",
            "Epoch 565/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0382 - accuracy: 0.9861 - val_loss: 0.5703 - val_accuracy: 0.9064\n",
            "Epoch 566/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0405 - accuracy: 0.9852 - val_loss: 0.5992 - val_accuracy: 0.9016\n",
            "Epoch 567/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 0.6013 - val_accuracy: 0.9046\n",
            "Epoch 568/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9875 - val_loss: 0.5946 - val_accuracy: 0.8994\n",
            "Epoch 569/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9858 - val_loss: 0.6216 - val_accuracy: 0.9028\n",
            "Epoch 570/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.5821 - val_accuracy: 0.9032\n",
            "Epoch 571/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9868 - val_loss: 0.5847 - val_accuracy: 0.9046\n",
            "Epoch 572/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9851 - val_loss: 0.5879 - val_accuracy: 0.9054\n",
            "Epoch 573/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9862 - val_loss: 0.5909 - val_accuracy: 0.9032\n",
            "Epoch 574/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.5972 - val_accuracy: 0.9036\n",
            "Epoch 575/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9854 - val_loss: 0.5948 - val_accuracy: 0.9014\n",
            "Epoch 576/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9856 - val_loss: 0.6108 - val_accuracy: 0.8996\n",
            "Epoch 577/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0348 - accuracy: 0.9868 - val_loss: 0.5990 - val_accuracy: 0.9064\n",
            "Epoch 578/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9864 - val_loss: 0.5839 - val_accuracy: 0.9036\n",
            "Epoch 579/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9865 - val_loss: 0.5849 - val_accuracy: 0.9024\n",
            "Epoch 580/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.6108 - val_accuracy: 0.9008\n",
            "Epoch 581/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 0.6120 - val_accuracy: 0.9030\n",
            "Epoch 582/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9857 - val_loss: 0.6456 - val_accuracy: 0.8978\n",
            "Epoch 583/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9854 - val_loss: 0.6239 - val_accuracy: 0.9034\n",
            "Epoch 584/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9864 - val_loss: 0.5967 - val_accuracy: 0.9050\n",
            "Epoch 585/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9870 - val_loss: 0.6104 - val_accuracy: 0.9022\n",
            "Epoch 586/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9866 - val_loss: 0.6058 - val_accuracy: 0.9036\n",
            "Epoch 587/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.6220 - val_accuracy: 0.9038\n",
            "Epoch 588/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9867 - val_loss: 0.6110 - val_accuracy: 0.9048\n",
            "Epoch 589/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0371 - accuracy: 0.9867 - val_loss: 0.6194 - val_accuracy: 0.9024\n",
            "Epoch 590/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9871 - val_loss: 0.6200 - val_accuracy: 0.9028\n",
            "Epoch 591/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.6201 - val_accuracy: 0.8972\n",
            "Epoch 592/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9863 - val_loss: 0.6049 - val_accuracy: 0.9002\n",
            "Epoch 593/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9868 - val_loss: 0.6004 - val_accuracy: 0.9038\n",
            "Epoch 594/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9857 - val_loss: 0.5913 - val_accuracy: 0.8994\n",
            "Epoch 595/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9861 - val_loss: 0.6183 - val_accuracy: 0.9058\n",
            "Epoch 596/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9870 - val_loss: 0.5991 - val_accuracy: 0.9072\n",
            "Epoch 597/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9865 - val_loss: 0.6071 - val_accuracy: 0.9044\n",
            "Epoch 598/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 0.6015 - val_accuracy: 0.9032\n",
            "Epoch 599/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.6174 - val_accuracy: 0.8988\n",
            "Epoch 600/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9874 - val_loss: 0.6087 - val_accuracy: 0.9034\n",
            "Epoch 601/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9873 - val_loss: 0.5890 - val_accuracy: 0.9002\n",
            "Epoch 602/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9859 - val_loss: 0.5713 - val_accuracy: 0.9032\n",
            "Epoch 603/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9867 - val_loss: 0.5996 - val_accuracy: 0.9012\n",
            "Epoch 604/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 0.6118 - val_accuracy: 0.9018\n",
            "Epoch 605/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.6027 - val_accuracy: 0.8994\n",
            "Epoch 606/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9871 - val_loss: 0.5970 - val_accuracy: 0.9030\n",
            "Epoch 607/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9874 - val_loss: 0.6147 - val_accuracy: 0.9034\n",
            "Epoch 608/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9877 - val_loss: 0.5921 - val_accuracy: 0.9064\n",
            "Epoch 609/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9868 - val_loss: 0.5916 - val_accuracy: 0.8994\n",
            "Epoch 610/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9855 - val_loss: 0.6025 - val_accuracy: 0.9028\n",
            "Epoch 611/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9863 - val_loss: 0.6165 - val_accuracy: 0.9058\n",
            "Epoch 612/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9859 - val_loss: 0.6150 - val_accuracy: 0.9052\n",
            "Epoch 613/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9876 - val_loss: 0.5884 - val_accuracy: 0.9026\n",
            "Epoch 614/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9874 - val_loss: 0.6116 - val_accuracy: 0.9018\n",
            "Epoch 615/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9873 - val_loss: 0.5914 - val_accuracy: 0.9026\n",
            "Epoch 616/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9878 - val_loss: 0.6118 - val_accuracy: 0.9024\n",
            "Epoch 617/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.5913 - val_accuracy: 0.9052\n",
            "Epoch 618/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9869 - val_loss: 0.6050 - val_accuracy: 0.9040\n",
            "Epoch 619/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0365 - accuracy: 0.9869 - val_loss: 0.5883 - val_accuracy: 0.9018\n",
            "Epoch 620/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 0.6304 - val_accuracy: 0.9034\n",
            "Epoch 621/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9867 - val_loss: 0.6046 - val_accuracy: 0.9036\n",
            "Epoch 622/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.6166 - val_accuracy: 0.9018\n",
            "Epoch 623/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9869 - val_loss: 0.5989 - val_accuracy: 0.9040\n",
            "Epoch 624/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.6284 - val_accuracy: 0.9058\n",
            "Epoch 625/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9876 - val_loss: 0.6407 - val_accuracy: 0.9052\n",
            "Epoch 626/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9870 - val_loss: 0.6087 - val_accuracy: 0.9034\n",
            "Epoch 627/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9875 - val_loss: 0.6155 - val_accuracy: 0.9034\n",
            "Epoch 628/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9865 - val_loss: 0.6199 - val_accuracy: 0.9040\n",
            "Epoch 629/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9872 - val_loss: 0.6138 - val_accuracy: 0.9004\n",
            "Epoch 630/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9878 - val_loss: 0.5816 - val_accuracy: 0.9028\n",
            "Epoch 631/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.5928 - val_accuracy: 0.9034\n",
            "Epoch 632/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9873 - val_loss: 0.6054 - val_accuracy: 0.9006\n",
            "Epoch 633/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 0.6297 - val_accuracy: 0.9028\n",
            "Epoch 634/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9876 - val_loss: 0.5916 - val_accuracy: 0.9058\n",
            "Epoch 635/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9867 - val_loss: 0.6041 - val_accuracy: 0.9020\n",
            "Epoch 636/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9867 - val_loss: 0.5913 - val_accuracy: 0.9060\n",
            "Epoch 637/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.6216 - val_accuracy: 0.9002\n",
            "Epoch 638/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9876 - val_loss: 0.6243 - val_accuracy: 0.9026\n",
            "Epoch 639/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 0.6059 - val_accuracy: 0.9018\n",
            "Epoch 640/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9885 - val_loss: 0.5990 - val_accuracy: 0.9074\n",
            "Epoch 641/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9879 - val_loss: 0.6303 - val_accuracy: 0.9048\n",
            "Epoch 642/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9883 - val_loss: 0.6190 - val_accuracy: 0.9066\n",
            "Epoch 643/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.6249 - val_accuracy: 0.9024\n",
            "Epoch 644/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9876 - val_loss: 0.6351 - val_accuracy: 0.9026\n",
            "Epoch 645/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.6423 - val_accuracy: 0.9072\n",
            "Epoch 646/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 0.6288 - val_accuracy: 0.8990\n",
            "Epoch 647/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9863 - val_loss: 0.6189 - val_accuracy: 0.9004\n",
            "Epoch 648/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.6303 - val_accuracy: 0.9026\n",
            "Epoch 649/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9867 - val_loss: 0.6367 - val_accuracy: 0.9022\n",
            "Epoch 650/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 0.6285 - val_accuracy: 0.8992\n",
            "Epoch 651/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9876 - val_loss: 0.6112 - val_accuracy: 0.9032\n",
            "Epoch 652/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9870 - val_loss: 0.6244 - val_accuracy: 0.8996\n",
            "Epoch 653/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0347 - accuracy: 0.9873 - val_loss: 0.6301 - val_accuracy: 0.9014\n",
            "Epoch 654/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.6265 - val_accuracy: 0.9050\n",
            "Epoch 655/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9879 - val_loss: 0.6378 - val_accuracy: 0.8996\n",
            "Epoch 656/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.6182 - val_accuracy: 0.9038\n",
            "Epoch 657/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9871 - val_loss: 0.6167 - val_accuracy: 0.9050\n",
            "Epoch 658/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.6314 - val_accuracy: 0.9016\n",
            "Epoch 659/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.6313 - val_accuracy: 0.9034\n",
            "Epoch 660/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9871 - val_loss: 0.6362 - val_accuracy: 0.9050\n",
            "Epoch 661/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0352 - accuracy: 0.9869 - val_loss: 0.6370 - val_accuracy: 0.9046\n",
            "Epoch 662/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9871 - val_loss: 0.6178 - val_accuracy: 0.9018\n",
            "Epoch 663/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9871 - val_loss: 0.6472 - val_accuracy: 0.8996\n",
            "Epoch 664/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 0.6334 - val_accuracy: 0.9002\n",
            "Epoch 665/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9875 - val_loss: 0.6325 - val_accuracy: 0.9044\n",
            "Epoch 666/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.6184 - val_accuracy: 0.8998\n",
            "Epoch 667/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9873 - val_loss: 0.6296 - val_accuracy: 0.8998\n",
            "Epoch 668/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.6576 - val_accuracy: 0.9016\n",
            "Epoch 669/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 0.6458 - val_accuracy: 0.9038\n",
            "Epoch 670/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9878 - val_loss: 0.6512 - val_accuracy: 0.9014\n",
            "Epoch 671/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.6171 - val_accuracy: 0.9042\n",
            "Epoch 672/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0346 - accuracy: 0.9872 - val_loss: 0.6399 - val_accuracy: 0.9008\n",
            "Epoch 673/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.6215 - val_accuracy: 0.9034\n",
            "Epoch 674/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9877 - val_loss: 0.6369 - val_accuracy: 0.9030\n",
            "Epoch 675/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9882 - val_loss: 0.6545 - val_accuracy: 0.9010\n",
            "Epoch 676/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9888 - val_loss: 0.6433 - val_accuracy: 0.9024\n",
            "Epoch 677/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 0.6392 - val_accuracy: 0.9062\n",
            "Epoch 678/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9878 - val_loss: 0.6696 - val_accuracy: 0.9010\n",
            "Epoch 679/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9875 - val_loss: 0.6427 - val_accuracy: 0.9008\n",
            "Epoch 680/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9878 - val_loss: 0.6586 - val_accuracy: 0.9014\n",
            "Epoch 681/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 0.6585 - val_accuracy: 0.8986\n",
            "Epoch 682/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9880 - val_loss: 0.6603 - val_accuracy: 0.8998\n",
            "Epoch 683/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.6511 - val_accuracy: 0.9012\n",
            "Epoch 684/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9878 - val_loss: 0.6554 - val_accuracy: 0.9026\n",
            "Epoch 685/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9885 - val_loss: 0.6377 - val_accuracy: 0.9020\n",
            "Epoch 686/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9884 - val_loss: 0.6454 - val_accuracy: 0.9024\n",
            "Epoch 687/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9879 - val_loss: 0.6560 - val_accuracy: 0.8988\n",
            "Epoch 688/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9871 - val_loss: 0.6407 - val_accuracy: 0.9034\n",
            "Epoch 689/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.6302 - val_accuracy: 0.9030\n",
            "Epoch 690/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9876 - val_loss: 0.6466 - val_accuracy: 0.9030\n",
            "Epoch 691/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9874 - val_loss: 0.6256 - val_accuracy: 0.9022\n",
            "Epoch 692/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9886 - val_loss: 0.6306 - val_accuracy: 0.9016\n",
            "Epoch 693/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 0.6332 - val_accuracy: 0.9048\n",
            "Epoch 694/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 0.6275 - val_accuracy: 0.9052\n",
            "Epoch 695/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9874 - val_loss: 0.6509 - val_accuracy: 0.9022\n",
            "Epoch 696/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9871 - val_loss: 0.6413 - val_accuracy: 0.9032\n",
            "Epoch 697/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.6493 - val_accuracy: 0.9038\n",
            "Epoch 698/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9885 - val_loss: 0.6485 - val_accuracy: 0.9030\n",
            "Epoch 699/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.6473 - val_accuracy: 0.9012\n",
            "Epoch 700/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.6491 - val_accuracy: 0.9028\n",
            "Epoch 701/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0341 - accuracy: 0.9877 - val_loss: 0.6230 - val_accuracy: 0.9030\n",
            "Epoch 702/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9888 - val_loss: 0.6590 - val_accuracy: 0.8990\n",
            "Epoch 703/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.6307 - val_accuracy: 0.9044\n",
            "Epoch 704/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9885 - val_loss: 0.6582 - val_accuracy: 0.9016\n",
            "Epoch 705/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0305 - accuracy: 0.9889 - val_loss: 0.6343 - val_accuracy: 0.9034\n",
            "Epoch 706/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9876 - val_loss: 0.6317 - val_accuracy: 0.9032\n",
            "Epoch 707/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.6562 - val_accuracy: 0.9020\n",
            "Epoch 708/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.6308 - val_accuracy: 0.9060\n",
            "Epoch 709/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.6680 - val_accuracy: 0.9010\n",
            "Epoch 710/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9879 - val_loss: 0.6480 - val_accuracy: 0.9018\n",
            "Epoch 711/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9888 - val_loss: 0.6420 - val_accuracy: 0.8990\n",
            "Epoch 712/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9888 - val_loss: 0.6384 - val_accuracy: 0.9012\n",
            "Epoch 713/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9892 - val_loss: 0.6382 - val_accuracy: 0.9042\n",
            "Epoch 714/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9883 - val_loss: 0.6271 - val_accuracy: 0.9044\n",
            "Epoch 715/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 0.6432 - val_accuracy: 0.9004\n",
            "Epoch 716/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9876 - val_loss: 0.6378 - val_accuracy: 0.9024\n",
            "Epoch 717/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9883 - val_loss: 0.6249 - val_accuracy: 0.9058\n",
            "Epoch 718/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9884 - val_loss: 0.6414 - val_accuracy: 0.9060\n",
            "Epoch 719/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.6229 - val_accuracy: 0.9024\n",
            "Epoch 720/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.6352 - val_accuracy: 0.9006\n",
            "Epoch 721/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9878 - val_loss: 0.6335 - val_accuracy: 0.9058\n",
            "Epoch 722/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9884 - val_loss: 0.6125 - val_accuracy: 0.9050\n",
            "Epoch 723/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.6292 - val_accuracy: 0.9036\n",
            "Epoch 724/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.6301 - val_accuracy: 0.9036\n",
            "Epoch 725/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9885 - val_loss: 0.6341 - val_accuracy: 0.9048\n",
            "Epoch 726/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9886 - val_loss: 0.6344 - val_accuracy: 0.9014\n",
            "Epoch 727/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9885 - val_loss: 0.6381 - val_accuracy: 0.9028\n",
            "Epoch 728/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9881 - val_loss: 0.6467 - val_accuracy: 0.9040\n",
            "Epoch 729/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9888 - val_loss: 0.6690 - val_accuracy: 0.9056\n",
            "Epoch 730/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9882 - val_loss: 0.6568 - val_accuracy: 0.9026\n",
            "Epoch 731/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9886 - val_loss: 0.6590 - val_accuracy: 0.9026\n",
            "Epoch 732/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9881 - val_loss: 0.6457 - val_accuracy: 0.9074\n",
            "Epoch 733/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9880 - val_loss: 0.6479 - val_accuracy: 0.9030\n",
            "Epoch 734/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9892 - val_loss: 0.6390 - val_accuracy: 0.9032\n",
            "Epoch 735/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9886 - val_loss: 0.6383 - val_accuracy: 0.9068\n",
            "Epoch 736/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9888 - val_loss: 0.6530 - val_accuracy: 0.9050\n",
            "Epoch 737/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.6435 - val_accuracy: 0.9022\n",
            "Epoch 738/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9889 - val_loss: 0.6498 - val_accuracy: 0.9040\n",
            "Epoch 739/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9893 - val_loss: 0.6731 - val_accuracy: 0.9022\n",
            "Epoch 740/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9885 - val_loss: 0.6924 - val_accuracy: 0.9010\n",
            "Epoch 741/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0325 - accuracy: 0.9882 - val_loss: 0.6577 - val_accuracy: 0.9032\n",
            "Epoch 742/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9881 - val_loss: 0.6537 - val_accuracy: 0.9002\n",
            "Epoch 743/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9883 - val_loss: 0.6407 - val_accuracy: 0.9058\n",
            "Epoch 744/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.6520 - val_accuracy: 0.9050\n",
            "Epoch 745/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9878 - val_loss: 0.6707 - val_accuracy: 0.9008\n",
            "Epoch 746/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9889 - val_loss: 0.6462 - val_accuracy: 0.9056\n",
            "Epoch 747/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.6505 - val_accuracy: 0.9028\n",
            "Epoch 748/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9884 - val_loss: 0.6436 - val_accuracy: 0.9040\n",
            "Epoch 749/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9892 - val_loss: 0.6609 - val_accuracy: 0.8994\n",
            "Epoch 750/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9888 - val_loss: 0.6610 - val_accuracy: 0.9034\n",
            "Epoch 751/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.6656 - val_accuracy: 0.9010\n",
            "Epoch 752/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.6453 - val_accuracy: 0.9012\n",
            "Epoch 753/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9892 - val_loss: 0.6762 - val_accuracy: 0.9018\n",
            "Epoch 754/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.6806 - val_accuracy: 0.8998\n",
            "Epoch 755/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9878 - val_loss: 0.6658 - val_accuracy: 0.9032\n",
            "Epoch 756/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.6695 - val_accuracy: 0.9038\n",
            "Epoch 757/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9894 - val_loss: 0.6624 - val_accuracy: 0.8986\n",
            "Epoch 758/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.6683 - val_accuracy: 0.9008\n",
            "Epoch 759/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9888 - val_loss: 0.6488 - val_accuracy: 0.9008\n",
            "Epoch 760/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9889 - val_loss: 0.6695 - val_accuracy: 0.9020\n",
            "Epoch 761/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9897 - val_loss: 0.6757 - val_accuracy: 0.9034\n",
            "Epoch 762/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.6883 - val_accuracy: 0.9000\n",
            "Epoch 763/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.6651 - val_accuracy: 0.8988\n",
            "Epoch 764/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9886 - val_loss: 0.6475 - val_accuracy: 0.9058\n",
            "Epoch 765/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.6680 - val_accuracy: 0.8982\n",
            "Epoch 766/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.6921 - val_accuracy: 0.9010\n",
            "Epoch 767/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9891 - val_loss: 0.6865 - val_accuracy: 0.9016\n",
            "Epoch 768/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.7085 - val_accuracy: 0.8980\n",
            "Epoch 769/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9887 - val_loss: 0.7064 - val_accuracy: 0.9008\n",
            "Epoch 770/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 0.6800 - val_accuracy: 0.9022\n",
            "Epoch 771/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 0.6569 - val_accuracy: 0.9016\n",
            "Epoch 772/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.6772 - val_accuracy: 0.9036\n",
            "Epoch 773/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.6642 - val_accuracy: 0.9008\n",
            "Epoch 774/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9886 - val_loss: 0.6857 - val_accuracy: 0.9010\n",
            "Epoch 775/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.6766 - val_accuracy: 0.9036\n",
            "Epoch 776/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.6459 - val_accuracy: 0.9056\n",
            "Epoch 777/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 0.6752 - val_accuracy: 0.9020\n",
            "Epoch 778/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 0.6884 - val_accuracy: 0.9018\n",
            "Epoch 779/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.6519 - val_accuracy: 0.9016\n",
            "Epoch 780/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.6534 - val_accuracy: 0.9040\n",
            "Epoch 781/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9890 - val_loss: 0.6673 - val_accuracy: 0.8998\n",
            "Epoch 782/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.7023 - val_accuracy: 0.9008\n",
            "Epoch 783/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.6952 - val_accuracy: 0.8990\n",
            "Epoch 784/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9892 - val_loss: 0.6672 - val_accuracy: 0.9028\n",
            "Epoch 785/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.6705 - val_accuracy: 0.9042\n",
            "Epoch 786/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9884 - val_loss: 0.6554 - val_accuracy: 0.9002\n",
            "Epoch 787/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.6580 - val_accuracy: 0.9020\n",
            "Epoch 788/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 0.6663 - val_accuracy: 0.9020\n",
            "Epoch 789/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.6806 - val_accuracy: 0.9014\n",
            "Epoch 790/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.6810 - val_accuracy: 0.9036\n",
            "Epoch 791/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.6894 - val_accuracy: 0.9008\n",
            "Epoch 792/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.6728 - val_accuracy: 0.8964\n",
            "Epoch 793/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.6635 - val_accuracy: 0.9038\n",
            "Epoch 794/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9890 - val_loss: 0.6855 - val_accuracy: 0.9022\n",
            "Epoch 795/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9885 - val_loss: 0.6954 - val_accuracy: 0.9020\n",
            "Epoch 796/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 0.6676 - val_accuracy: 0.9028\n",
            "Epoch 797/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9892 - val_loss: 0.6448 - val_accuracy: 0.9014\n",
            "Epoch 798/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9892 - val_loss: 0.6798 - val_accuracy: 0.9004\n",
            "Epoch 799/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.6739 - val_accuracy: 0.9032\n",
            "Epoch 800/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.6833 - val_accuracy: 0.9030\n",
            "Epoch 801/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.6761 - val_accuracy: 0.9002\n",
            "Epoch 802/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9892 - val_loss: 0.6795 - val_accuracy: 0.9024\n",
            "Epoch 803/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.7024 - val_accuracy: 0.8974\n",
            "Epoch 804/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9886 - val_loss: 0.6860 - val_accuracy: 0.9046\n",
            "Epoch 805/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.6917 - val_accuracy: 0.8986\n",
            "Epoch 806/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9894 - val_loss: 0.6830 - val_accuracy: 0.9002\n",
            "Epoch 807/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.6701 - val_accuracy: 0.9026\n",
            "Epoch 808/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.6998 - val_accuracy: 0.8994\n",
            "Epoch 809/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9894 - val_loss: 0.6983 - val_accuracy: 0.9024\n",
            "Epoch 810/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.6783 - val_accuracy: 0.9030\n",
            "Epoch 811/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.7280 - val_accuracy: 0.8994\n",
            "Epoch 812/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 0.6827 - val_accuracy: 0.9036\n",
            "Epoch 813/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9893 - val_loss: 0.6773 - val_accuracy: 0.9048\n",
            "Epoch 814/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9898 - val_loss: 0.6936 - val_accuracy: 0.9032\n",
            "Epoch 815/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9891 - val_loss: 0.6985 - val_accuracy: 0.9056\n",
            "Epoch 816/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9897 - val_loss: 0.6950 - val_accuracy: 0.9038\n",
            "Epoch 817/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 0.6820 - val_accuracy: 0.9060\n",
            "Epoch 818/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9894 - val_loss: 0.7044 - val_accuracy: 0.8998\n",
            "Epoch 819/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0289 - accuracy: 0.9896 - val_loss: 0.6822 - val_accuracy: 0.9056\n",
            "Epoch 820/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9889 - val_loss: 0.6751 - val_accuracy: 0.9030\n",
            "Epoch 821/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.6875 - val_accuracy: 0.9062\n",
            "Epoch 822/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.6890 - val_accuracy: 0.9010\n",
            "Epoch 823/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9889 - val_loss: 0.6796 - val_accuracy: 0.9036\n",
            "Epoch 824/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.6914 - val_accuracy: 0.8994\n",
            "Epoch 825/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.6667 - val_accuracy: 0.9020\n",
            "Epoch 826/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9894 - val_loss: 0.7004 - val_accuracy: 0.8994\n",
            "Epoch 827/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.6720 - val_accuracy: 0.9042\n",
            "Epoch 828/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.6754 - val_accuracy: 0.8996\n",
            "Epoch 829/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 0.6622 - val_accuracy: 0.9038\n",
            "Epoch 830/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.6853 - val_accuracy: 0.9000\n",
            "Epoch 831/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 0.6818 - val_accuracy: 0.9012\n",
            "Epoch 832/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.6761 - val_accuracy: 0.9038\n",
            "Epoch 833/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.6740 - val_accuracy: 0.9022\n",
            "Epoch 834/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.6867 - val_accuracy: 0.9028\n",
            "Epoch 835/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.6667 - val_accuracy: 0.9024\n",
            "Epoch 836/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 0.6871 - val_accuracy: 0.9038\n",
            "Epoch 837/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0305 - accuracy: 0.9888 - val_loss: 0.6745 - val_accuracy: 0.9010\n",
            "Epoch 838/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9893 - val_loss: 0.6954 - val_accuracy: 0.9016\n",
            "Epoch 839/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 0.6534 - val_accuracy: 0.9050\n",
            "Epoch 840/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 0.6869 - val_accuracy: 0.9006\n",
            "Epoch 841/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9897 - val_loss: 0.7007 - val_accuracy: 0.9008\n",
            "Epoch 842/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9895 - val_loss: 0.6932 - val_accuracy: 0.8994\n",
            "Epoch 843/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9894 - val_loss: 0.6771 - val_accuracy: 0.8990\n",
            "Epoch 844/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.6747 - val_accuracy: 0.9034\n",
            "Epoch 845/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.6817 - val_accuracy: 0.9050\n",
            "Epoch 846/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 0.6638 - val_accuracy: 0.9014\n",
            "Epoch 847/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 0.7027 - val_accuracy: 0.9038\n",
            "Epoch 848/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9904 - val_loss: 0.6878 - val_accuracy: 0.9054\n",
            "Epoch 849/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.6879 - val_accuracy: 0.9006\n",
            "Epoch 850/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 0.6909 - val_accuracy: 0.9044\n",
            "Epoch 851/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9902 - val_loss: 0.6957 - val_accuracy: 0.9032\n",
            "Epoch 852/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.7072 - val_accuracy: 0.9018\n",
            "Epoch 853/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 0.7221 - val_accuracy: 0.9002\n",
            "Epoch 854/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.6836 - val_accuracy: 0.9040\n",
            "Epoch 855/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.7028 - val_accuracy: 0.9002\n",
            "Epoch 856/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9890 - val_loss: 0.7039 - val_accuracy: 0.9002\n",
            "Epoch 857/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9901 - val_loss: 0.6784 - val_accuracy: 0.9036\n",
            "Epoch 858/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9889 - val_loss: 0.6928 - val_accuracy: 0.9034\n",
            "Epoch 859/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.6550 - val_accuracy: 0.9034\n",
            "Epoch 860/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.6699 - val_accuracy: 0.9050\n",
            "Epoch 861/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9905 - val_loss: 0.7059 - val_accuracy: 0.9024\n",
            "Epoch 862/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.7016 - val_accuracy: 0.9002\n",
            "Epoch 863/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9891 - val_loss: 0.6996 - val_accuracy: 0.9044\n",
            "Epoch 864/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9901 - val_loss: 0.6787 - val_accuracy: 0.9034\n",
            "Epoch 865/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.6739 - val_accuracy: 0.9036\n",
            "Epoch 866/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9901 - val_loss: 0.6726 - val_accuracy: 0.9008\n",
            "Epoch 867/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 0.6844 - val_accuracy: 0.9076\n",
            "Epoch 868/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.7006 - val_accuracy: 0.9032\n",
            "Epoch 869/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9893 - val_loss: 0.6908 - val_accuracy: 0.9006\n",
            "Epoch 870/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.7055 - val_accuracy: 0.9054\n",
            "Epoch 871/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.7099 - val_accuracy: 0.9004\n",
            "Epoch 872/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.7035 - val_accuracy: 0.9028\n",
            "Epoch 873/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9894 - val_loss: 0.7133 - val_accuracy: 0.9018\n",
            "Epoch 874/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9901 - val_loss: 0.6905 - val_accuracy: 0.9016\n",
            "Epoch 875/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 0.7049 - val_accuracy: 0.9034\n",
            "Epoch 876/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.6620 - val_accuracy: 0.9056\n",
            "Epoch 877/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.6997 - val_accuracy: 0.9024\n",
            "Epoch 878/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.6888 - val_accuracy: 0.9024\n",
            "Epoch 879/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 0.7072 - val_accuracy: 0.8998\n",
            "Epoch 880/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9899 - val_loss: 0.6892 - val_accuracy: 0.9028\n",
            "Epoch 881/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.7125 - val_accuracy: 0.9044\n",
            "Epoch 882/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9890 - val_loss: 0.6764 - val_accuracy: 0.9018\n",
            "Epoch 883/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9892 - val_loss: 0.6969 - val_accuracy: 0.9064\n",
            "Epoch 884/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 0.6892 - val_accuracy: 0.8990\n",
            "Epoch 885/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 0.6961 - val_accuracy: 0.9006\n",
            "Epoch 886/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 0.7000 - val_accuracy: 0.9062\n",
            "Epoch 887/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.7096 - val_accuracy: 0.9010\n",
            "Epoch 888/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.6994 - val_accuracy: 0.8998\n",
            "Epoch 889/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.6776 - val_accuracy: 0.9008\n",
            "Epoch 890/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.7006 - val_accuracy: 0.8998\n",
            "Epoch 891/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9901 - val_loss: 0.7041 - val_accuracy: 0.9034\n",
            "Epoch 892/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.6903 - val_accuracy: 0.9054\n",
            "Epoch 893/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9900 - val_loss: 0.7221 - val_accuracy: 0.9008\n",
            "Epoch 894/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.7071 - val_accuracy: 0.9042\n",
            "Epoch 895/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.7275 - val_accuracy: 0.9002\n",
            "Epoch 896/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.6917 - val_accuracy: 0.9004\n",
            "Epoch 897/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.6979 - val_accuracy: 0.9076\n",
            "Epoch 898/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.6896 - val_accuracy: 0.9036\n",
            "Epoch 899/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.7179 - val_accuracy: 0.9046\n",
            "Epoch 900/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 0.7111 - val_accuracy: 0.8994\n",
            "Epoch 901/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9901 - val_loss: 0.6791 - val_accuracy: 0.9044\n",
            "Epoch 902/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 0.6927 - val_accuracy: 0.9056\n",
            "Epoch 903/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.7172 - val_accuracy: 0.9044\n",
            "Epoch 904/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 0.7215 - val_accuracy: 0.9044\n",
            "Epoch 905/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.7124 - val_accuracy: 0.9004\n",
            "Epoch 906/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.7222 - val_accuracy: 0.9064\n",
            "Epoch 907/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9903 - val_loss: 0.7000 - val_accuracy: 0.9070\n",
            "Epoch 908/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9903 - val_loss: 0.6909 - val_accuracy: 0.9048\n",
            "Epoch 909/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 0.6987 - val_accuracy: 0.9028\n",
            "Epoch 910/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 0.6887 - val_accuracy: 0.9008\n",
            "Epoch 911/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.6830 - val_accuracy: 0.9050\n",
            "Epoch 912/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9897 - val_loss: 0.6765 - val_accuracy: 0.9034\n",
            "Epoch 913/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.6711 - val_accuracy: 0.9050\n",
            "Epoch 914/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9900 - val_loss: 0.6867 - val_accuracy: 0.9026\n",
            "Epoch 915/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.6846 - val_accuracy: 0.9048\n",
            "Epoch 916/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.6896 - val_accuracy: 0.9026\n",
            "Epoch 917/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9902 - val_loss: 0.6944 - val_accuracy: 0.9026\n",
            "Epoch 918/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9901 - val_loss: 0.7121 - val_accuracy: 0.9012\n",
            "Epoch 919/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.6956 - val_accuracy: 0.9044\n",
            "Epoch 920/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9905 - val_loss: 0.7138 - val_accuracy: 0.9032\n",
            "Epoch 921/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.7124 - val_accuracy: 0.9002\n",
            "Epoch 922/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9903 - val_loss: 0.7140 - val_accuracy: 0.9068\n",
            "Epoch 923/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.7072 - val_accuracy: 0.9042\n",
            "Epoch 924/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9898 - val_loss: 0.6993 - val_accuracy: 0.9018\n",
            "Epoch 925/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.7047 - val_accuracy: 0.9006\n",
            "Epoch 926/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0283 - accuracy: 0.9899 - val_loss: 0.6801 - val_accuracy: 0.9000\n",
            "Epoch 927/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.7100 - val_accuracy: 0.9042\n",
            "Epoch 928/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.7101 - val_accuracy: 0.9024\n",
            "Epoch 929/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9905 - val_loss: 0.7147 - val_accuracy: 0.9028\n",
            "Epoch 930/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9898 - val_loss: 0.7121 - val_accuracy: 0.8996\n",
            "Epoch 931/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.6888 - val_accuracy: 0.9012\n",
            "Epoch 932/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9907 - val_loss: 0.6936 - val_accuracy: 0.9024\n",
            "Epoch 933/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.6890 - val_accuracy: 0.9066\n",
            "Epoch 934/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.6909 - val_accuracy: 0.9050\n",
            "Epoch 935/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9900 - val_loss: 0.6986 - val_accuracy: 0.9050\n",
            "Epoch 936/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.6965 - val_accuracy: 0.9004\n",
            "Epoch 937/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.6997 - val_accuracy: 0.9012\n",
            "Epoch 938/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.7362 - val_accuracy: 0.9032\n",
            "Epoch 939/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.7205 - val_accuracy: 0.8988\n",
            "Epoch 940/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9910 - val_loss: 0.7084 - val_accuracy: 0.9020\n",
            "Epoch 941/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 0.7093 - val_accuracy: 0.9026\n",
            "Epoch 942/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.7109 - val_accuracy: 0.9044\n",
            "Epoch 943/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9900 - val_loss: 0.7119 - val_accuracy: 0.9026\n",
            "Epoch 944/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.7136 - val_accuracy: 0.9058\n",
            "Epoch 945/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.7099 - val_accuracy: 0.9022\n",
            "Epoch 946/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9897 - val_loss: 0.7180 - val_accuracy: 0.8996\n",
            "Epoch 947/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.6924 - val_accuracy: 0.9006\n",
            "Epoch 948/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0290 - accuracy: 0.9900 - val_loss: 0.7035 - val_accuracy: 0.9016\n",
            "Epoch 949/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9903 - val_loss: 0.7034 - val_accuracy: 0.9024\n",
            "Epoch 950/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 0.7125 - val_accuracy: 0.9018\n",
            "Epoch 951/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.7162 - val_accuracy: 0.9028\n",
            "Epoch 952/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.7047 - val_accuracy: 0.9008\n",
            "Epoch 953/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.7161 - val_accuracy: 0.9000\n",
            "Epoch 954/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.7222 - val_accuracy: 0.8996\n",
            "Epoch 955/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.6763 - val_accuracy: 0.9040\n",
            "Epoch 956/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9908 - val_loss: 0.6736 - val_accuracy: 0.9022\n",
            "Epoch 957/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.6774 - val_accuracy: 0.9016\n",
            "Epoch 958/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9899 - val_loss: 0.7114 - val_accuracy: 0.8976\n",
            "Epoch 959/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 0.7060 - val_accuracy: 0.9008\n",
            "Epoch 960/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9901 - val_loss: 0.7004 - val_accuracy: 0.9030\n",
            "Epoch 961/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 0.7054 - val_accuracy: 0.9012\n",
            "Epoch 962/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.7178 - val_accuracy: 0.9010\n",
            "Epoch 963/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.6906 - val_accuracy: 0.9060\n",
            "Epoch 964/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.7261 - val_accuracy: 0.9004\n",
            "Epoch 965/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.6910 - val_accuracy: 0.9036\n",
            "Epoch 966/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0270 - accuracy: 0.9903 - val_loss: 0.6699 - val_accuracy: 0.9038\n",
            "Epoch 967/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9914 - val_loss: 0.6827 - val_accuracy: 0.9026\n",
            "Epoch 968/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.7012 - val_accuracy: 0.9026\n",
            "Epoch 969/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.6959 - val_accuracy: 0.8990\n",
            "Epoch 970/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.7272 - val_accuracy: 0.9028\n",
            "Epoch 971/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9903 - val_loss: 0.6948 - val_accuracy: 0.9024\n",
            "Epoch 972/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.7163 - val_accuracy: 0.9012\n",
            "Epoch 973/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9910 - val_loss: 0.6779 - val_accuracy: 0.9024\n",
            "Epoch 974/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.7207 - val_accuracy: 0.9028\n",
            "Epoch 975/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9906 - val_loss: 0.7141 - val_accuracy: 0.9012\n",
            "Epoch 976/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.6959 - val_accuracy: 0.9020\n",
            "Epoch 977/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9907 - val_loss: 0.7262 - val_accuracy: 0.9008\n",
            "Epoch 978/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.6989 - val_accuracy: 0.9010\n",
            "Epoch 979/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.7001 - val_accuracy: 0.9064\n",
            "Epoch 980/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.7112 - val_accuracy: 0.9014\n",
            "Epoch 981/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9903 - val_loss: 0.7192 - val_accuracy: 0.9058\n",
            "Epoch 982/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9899 - val_loss: 0.7177 - val_accuracy: 0.9008\n",
            "Epoch 983/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.7178 - val_accuracy: 0.8992\n",
            "Epoch 984/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.7270 - val_accuracy: 0.9046\n",
            "Epoch 985/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.7234 - val_accuracy: 0.9008\n",
            "Epoch 986/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9920 - val_loss: 0.7135 - val_accuracy: 0.9068\n",
            "Epoch 987/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9920 - val_loss: 0.7001 - val_accuracy: 0.9032\n",
            "Epoch 988/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.7105 - val_accuracy: 0.9002\n",
            "Epoch 989/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9907 - val_loss: 0.7029 - val_accuracy: 0.9018\n",
            "Epoch 990/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.7079 - val_accuracy: 0.9024\n",
            "Epoch 991/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 0.9912 - val_loss: 0.7051 - val_accuracy: 0.9006\n",
            "Epoch 992/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9901 - val_loss: 0.7051 - val_accuracy: 0.9052\n",
            "Epoch 993/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.7002 - val_accuracy: 0.9014\n",
            "Epoch 994/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.7078 - val_accuracy: 0.9062\n",
            "Epoch 995/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.6831 - val_accuracy: 0.9042\n",
            "Epoch 996/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9914 - val_loss: 0.7028 - val_accuracy: 0.9048\n",
            "Epoch 997/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9914 - val_loss: 0.7136 - val_accuracy: 0.9020\n",
            "Epoch 998/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.7131 - val_accuracy: 0.8990\n",
            "Epoch 999/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 0.6936 - val_accuracy: 0.9066\n",
            "Epoch 1000/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.7038 - val_accuracy: 0.9020\n",
            "Epoch 1001/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9903 - val_loss: 0.7258 - val_accuracy: 0.8974\n",
            "Epoch 1002/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9900 - val_loss: 0.7049 - val_accuracy: 0.9022\n",
            "Epoch 1003/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.7206 - val_accuracy: 0.9044\n",
            "Epoch 1004/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.7132 - val_accuracy: 0.9062\n",
            "Epoch 1005/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.6836 - val_accuracy: 0.9044\n",
            "Epoch 1006/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9906 - val_loss: 0.7095 - val_accuracy: 0.9042\n",
            "Epoch 1007/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 0.7080 - val_accuracy: 0.9040\n",
            "Epoch 1008/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 0.7211 - val_accuracy: 0.9028\n",
            "Epoch 1009/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.7124 - val_accuracy: 0.9026\n",
            "Epoch 1010/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9908 - val_loss: 0.7027 - val_accuracy: 0.9076\n",
            "Epoch 1011/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9908 - val_loss: 0.7192 - val_accuracy: 0.9032\n",
            "Epoch 1012/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 0.7070 - val_accuracy: 0.9004\n",
            "Epoch 1013/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 0.7258 - val_accuracy: 0.9000\n",
            "Epoch 1014/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.7116 - val_accuracy: 0.9036\n",
            "Epoch 1015/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.7412 - val_accuracy: 0.9006\n",
            "Epoch 1016/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.7195 - val_accuracy: 0.8988\n",
            "Epoch 1017/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.7469 - val_accuracy: 0.9020\n",
            "Epoch 1018/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.7314 - val_accuracy: 0.9010\n",
            "Epoch 1019/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.7097 - val_accuracy: 0.9018\n",
            "Epoch 1020/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9918 - val_loss: 0.7296 - val_accuracy: 0.9032\n",
            "Epoch 1021/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9910 - val_loss: 0.7142 - val_accuracy: 0.9020\n",
            "Epoch 1022/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.7280 - val_accuracy: 0.9014\n",
            "Epoch 1023/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9908 - val_loss: 0.7702 - val_accuracy: 0.8954\n",
            "Epoch 1024/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 0.7311 - val_accuracy: 0.9064\n",
            "Epoch 1025/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9908 - val_loss: 0.7631 - val_accuracy: 0.8982\n",
            "Epoch 1026/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 0.7084 - val_accuracy: 0.9032\n",
            "Epoch 1027/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.7072 - val_accuracy: 0.9044\n",
            "Epoch 1028/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9903 - val_loss: 0.7122 - val_accuracy: 0.8982\n",
            "Epoch 1029/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.7362 - val_accuracy: 0.9030\n",
            "Epoch 1030/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.7120 - val_accuracy: 0.9028\n",
            "Epoch 1031/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.7172 - val_accuracy: 0.9050\n",
            "Epoch 1032/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.7134 - val_accuracy: 0.9022\n",
            "Epoch 1033/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9910 - val_loss: 0.7122 - val_accuracy: 0.9048\n",
            "Epoch 1034/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.7316 - val_accuracy: 0.8990\n",
            "Epoch 1035/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9912 - val_loss: 0.7207 - val_accuracy: 0.9050\n",
            "Epoch 1036/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9914 - val_loss: 0.7331 - val_accuracy: 0.9014\n",
            "Epoch 1037/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9910 - val_loss: 0.7273 - val_accuracy: 0.9010\n",
            "Epoch 1038/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.7036 - val_accuracy: 0.9036\n",
            "Epoch 1039/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9911 - val_loss: 0.7517 - val_accuracy: 0.9004\n",
            "Epoch 1040/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.7125 - val_accuracy: 0.9026\n",
            "Epoch 1041/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.7192 - val_accuracy: 0.8990\n",
            "Epoch 1042/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.6989 - val_accuracy: 0.9052\n",
            "Epoch 1043/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9910 - val_loss: 0.7111 - val_accuracy: 0.9018\n",
            "Epoch 1044/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 0.7066 - val_accuracy: 0.8976\n",
            "Epoch 1045/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.7534 - val_accuracy: 0.9000\n",
            "Epoch 1046/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.7148 - val_accuracy: 0.9008\n",
            "Epoch 1047/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.6949 - val_accuracy: 0.9028\n",
            "Epoch 1048/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.7055 - val_accuracy: 0.9014\n",
            "Epoch 1049/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.6874 - val_accuracy: 0.9016\n",
            "Epoch 1050/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9915 - val_loss: 0.7134 - val_accuracy: 0.8992\n",
            "Epoch 1051/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 0.7031 - val_accuracy: 0.9016\n",
            "Epoch 1052/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.7254 - val_accuracy: 0.9034\n",
            "Epoch 1053/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.7010 - val_accuracy: 0.9040\n",
            "Epoch 1054/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.7163 - val_accuracy: 0.8998\n",
            "Epoch 1055/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.7060 - val_accuracy: 0.8998\n",
            "Epoch 1056/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.7163 - val_accuracy: 0.9032\n",
            "Epoch 1057/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9911 - val_loss: 0.7218 - val_accuracy: 0.9044\n",
            "Epoch 1058/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.7205 - val_accuracy: 0.9058\n",
            "Epoch 1059/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9907 - val_loss: 0.7152 - val_accuracy: 0.9002\n",
            "Epoch 1060/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.7438 - val_accuracy: 0.8972\n",
            "Epoch 1061/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.7179 - val_accuracy: 0.8992\n",
            "Epoch 1062/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9910 - val_loss: 0.7109 - val_accuracy: 0.9052\n",
            "Epoch 1063/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.7213 - val_accuracy: 0.8980\n",
            "Epoch 1064/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.6964 - val_accuracy: 0.8960\n",
            "Epoch 1065/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.7197 - val_accuracy: 0.9034\n",
            "Epoch 1066/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.7180 - val_accuracy: 0.8996\n",
            "Epoch 1067/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 0.7125 - val_accuracy: 0.9038\n",
            "Epoch 1068/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.7133 - val_accuracy: 0.9020\n",
            "Epoch 1069/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.7003 - val_accuracy: 0.9024\n",
            "Epoch 1070/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.7030 - val_accuracy: 0.9036\n",
            "Epoch 1071/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.7249 - val_accuracy: 0.9006\n",
            "Epoch 1072/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9918 - val_loss: 0.7372 - val_accuracy: 0.9002\n",
            "Epoch 1073/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9911 - val_loss: 0.7625 - val_accuracy: 0.8984\n",
            "Epoch 1074/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 0.7378 - val_accuracy: 0.9000\n",
            "Epoch 1075/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.7346 - val_accuracy: 0.9024\n",
            "Epoch 1076/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.7637 - val_accuracy: 0.8996\n",
            "Epoch 1077/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 0.7313 - val_accuracy: 0.9024\n",
            "Epoch 1078/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.7493 - val_accuracy: 0.9026\n",
            "Epoch 1079/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.7515 - val_accuracy: 0.8984\n",
            "Epoch 1080/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.7478 - val_accuracy: 0.9026\n",
            "Epoch 1081/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.7292 - val_accuracy: 0.9014\n",
            "Epoch 1082/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.7384 - val_accuracy: 0.8990\n",
            "Epoch 1083/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.7658 - val_accuracy: 0.8986\n",
            "Epoch 1084/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9914 - val_loss: 0.7370 - val_accuracy: 0.9026\n",
            "Epoch 1085/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.7323 - val_accuracy: 0.9050\n",
            "Epoch 1086/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9913 - val_loss: 0.7435 - val_accuracy: 0.9022\n",
            "Epoch 1087/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9917 - val_loss: 0.7440 - val_accuracy: 0.9016\n",
            "Epoch 1088/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.7572 - val_accuracy: 0.9036\n",
            "Epoch 1089/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.7309 - val_accuracy: 0.9018\n",
            "Epoch 1090/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.7141 - val_accuracy: 0.9028\n",
            "Epoch 1091/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.7179 - val_accuracy: 0.9020\n",
            "Epoch 1092/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.7287 - val_accuracy: 0.9016\n",
            "Epoch 1093/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.7325 - val_accuracy: 0.8998\n",
            "Epoch 1094/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.7283 - val_accuracy: 0.9002\n",
            "Epoch 1095/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9914 - val_loss: 0.7275 - val_accuracy: 0.9034\n",
            "Epoch 1096/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9906 - val_loss: 0.7256 - val_accuracy: 0.9024\n",
            "Epoch 1097/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 0.7183 - val_accuracy: 0.9042\n",
            "Epoch 1098/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.7094 - val_accuracy: 0.8998\n",
            "Epoch 1099/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.7138 - val_accuracy: 0.9036\n",
            "Epoch 1100/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9917 - val_loss: 0.7146 - val_accuracy: 0.9036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXNRJ00KDfdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_train_loss():\n",
        "  loss_train = history.history['loss']\n",
        "  loss_val = history.history['val_loss']\n",
        "  epochs = range(1,1101)\n",
        "  plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "  plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7JIVj2RDhkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_train_accuracy():\n",
        "  accuracy_train = history.history['accuracy']\n",
        "  accuracy_val = history.history['val_accuracy']\n",
        "  epochs = range(1,1101)\n",
        "  plt.plot(epochs, accuracy_train, 'g', label='Training accuracy')\n",
        "  plt.plot(epochs, accuracy_val, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLHbpmCvDkJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "e67e1e82-1d9e-4ed2-cd0d-0bfc1ac1d113"
      },
      "source": [
        "# Original from A_1\n",
        "plot_train_loss()\n",
        "plot_train_accuracy()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mwe8tjULuqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "1c8e6605-6c8d-4293-b1ae-7640cc8dafc1"
      },
      "source": [
        "# adding dropout before first hidden layer\n",
        "plot_train_loss()\n",
        "plot_train_accuracy()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kAFTUrOFAt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c800fee6-5bdb-46b9-8bb0-022e0c0f61ba"
      },
      "source": [
        "score = fmnist_model.evaluate(dataset_test, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.8927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHbSSr0qMFA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5039601c-13a5-4735-99af-143780c72aec"
      },
      "source": [
        "fmnist_model = models.Sequential([\n",
        "    layers.Dense(units=512, input_dim=28 * 28, activation=tf.nn.relu),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(units=128, input_dim=512, activation=tf.nn.relu),\n",
        "    layers.Dense(units=10, input_dim=128,  activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "fmnist_model.compile(optimizer = tf.optimizers.Adam(),\n",
        "                     loss = 'categorical_crossentropy', # as we have already used the one-hot encoding for the training labels\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history = fmnist_model.fit(dataset_train, \n",
        "                           epochs=1100,\n",
        "                           steps_per_epoch= steps_per_epoch,\n",
        "                           validation_data = dataset_valid,\n",
        "                           callbacks = [tensorboard_callback])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1100\n",
            " 2/50 [>.............................] - ETA: 1s - loss: 2.2166 - accuracy: 0.2504WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0594s). Check your callbacks.\n",
            "51/50 [==============================] - 0s 8ms/step - loss: 0.7568 - accuracy: 0.7381 - val_loss: 0.4646 - val_accuracy: 0.8338\n",
            "Epoch 2/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.8401 - val_loss: 0.3973 - val_accuracy: 0.8622\n",
            "Epoch 3/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8585 - val_loss: 0.3652 - val_accuracy: 0.8702\n",
            "Epoch 4/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8714 - val_loss: 0.3385 - val_accuracy: 0.8796\n",
            "Epoch 5/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8783 - val_loss: 0.3306 - val_accuracy: 0.8826\n",
            "Epoch 6/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8830 - val_loss: 0.3275 - val_accuracy: 0.8830\n",
            "Epoch 7/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.8866 - val_loss: 0.3180 - val_accuracy: 0.8858\n",
            "Epoch 8/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2974 - accuracy: 0.8908 - val_loss: 0.3071 - val_accuracy: 0.8890\n",
            "Epoch 9/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2823 - accuracy: 0.8977 - val_loss: 0.3064 - val_accuracy: 0.8878\n",
            "Epoch 10/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.8990 - val_loss: 0.2970 - val_accuracy: 0.8946\n",
            "Epoch 11/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2649 - accuracy: 0.9027 - val_loss: 0.2944 - val_accuracy: 0.8902\n",
            "Epoch 12/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2572 - accuracy: 0.9051 - val_loss: 0.2920 - val_accuracy: 0.8948\n",
            "Epoch 13/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.9082 - val_loss: 0.2846 - val_accuracy: 0.8976\n",
            "Epoch 14/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2402 - accuracy: 0.9104 - val_loss: 0.2926 - val_accuracy: 0.8960\n",
            "Epoch 15/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2360 - accuracy: 0.9130 - val_loss: 0.2878 - val_accuracy: 0.8958\n",
            "Epoch 16/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2300 - accuracy: 0.9157 - val_loss: 0.2875 - val_accuracy: 0.8972\n",
            "Epoch 17/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2214 - accuracy: 0.9183 - val_loss: 0.2808 - val_accuracy: 0.8998\n",
            "Epoch 18/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2183 - accuracy: 0.9190 - val_loss: 0.2857 - val_accuracy: 0.8962\n",
            "Epoch 19/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9209 - val_loss: 0.2799 - val_accuracy: 0.8998\n",
            "Epoch 20/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2066 - accuracy: 0.9232 - val_loss: 0.2797 - val_accuracy: 0.9006\n",
            "Epoch 21/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2031 - accuracy: 0.9252 - val_loss: 0.2925 - val_accuracy: 0.8978\n",
            "Epoch 22/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1987 - accuracy: 0.9262 - val_loss: 0.2834 - val_accuracy: 0.8984\n",
            "Epoch 23/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9297 - val_loss: 0.2832 - val_accuracy: 0.9024\n",
            "Epoch 24/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9292 - val_loss: 0.2799 - val_accuracy: 0.9018\n",
            "Epoch 25/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1807 - accuracy: 0.9334 - val_loss: 0.2851 - val_accuracy: 0.9018\n",
            "Epoch 26/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1809 - accuracy: 0.9333 - val_loss: 0.2812 - val_accuracy: 0.9044\n",
            "Epoch 27/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9352 - val_loss: 0.2835 - val_accuracy: 0.9028\n",
            "Epoch 28/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9354 - val_loss: 0.2878 - val_accuracy: 0.9018\n",
            "Epoch 29/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1665 - accuracy: 0.9393 - val_loss: 0.2791 - val_accuracy: 0.9030\n",
            "Epoch 30/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1646 - accuracy: 0.9382 - val_loss: 0.2838 - val_accuracy: 0.9028\n",
            "Epoch 31/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1628 - accuracy: 0.9395 - val_loss: 0.2959 - val_accuracy: 0.9040\n",
            "Epoch 32/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.9398 - val_loss: 0.2850 - val_accuracy: 0.9060\n",
            "Epoch 33/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1532 - accuracy: 0.9434 - val_loss: 0.2961 - val_accuracy: 0.9008\n",
            "Epoch 34/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1508 - accuracy: 0.9443 - val_loss: 0.2955 - val_accuracy: 0.9048\n",
            "Epoch 35/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1470 - accuracy: 0.9458 - val_loss: 0.2955 - val_accuracy: 0.9016\n",
            "Epoch 36/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1439 - accuracy: 0.9469 - val_loss: 0.2954 - val_accuracy: 0.9010\n",
            "Epoch 37/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9482 - val_loss: 0.2982 - val_accuracy: 0.9036\n",
            "Epoch 38/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.9487 - val_loss: 0.3127 - val_accuracy: 0.8994\n",
            "Epoch 39/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.9489 - val_loss: 0.3073 - val_accuracy: 0.9040\n",
            "Epoch 40/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.9475 - val_loss: 0.3022 - val_accuracy: 0.9002\n",
            "Epoch 41/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1346 - accuracy: 0.9492 - val_loss: 0.3082 - val_accuracy: 0.9012\n",
            "Epoch 42/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.9506 - val_loss: 0.3096 - val_accuracy: 0.9040\n",
            "Epoch 43/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1258 - accuracy: 0.9528 - val_loss: 0.3216 - val_accuracy: 0.8978\n",
            "Epoch 44/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9535 - val_loss: 0.3142 - val_accuracy: 0.9036\n",
            "Epoch 45/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1205 - accuracy: 0.9557 - val_loss: 0.3236 - val_accuracy: 0.9046\n",
            "Epoch 46/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.9544 - val_loss: 0.3255 - val_accuracy: 0.9010\n",
            "Epoch 47/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9549 - val_loss: 0.3195 - val_accuracy: 0.9022\n",
            "Epoch 48/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9548 - val_loss: 0.3215 - val_accuracy: 0.9034\n",
            "Epoch 49/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.9552 - val_loss: 0.3530 - val_accuracy: 0.8964\n",
            "Epoch 50/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.9586 - val_loss: 0.3324 - val_accuracy: 0.9038\n",
            "Epoch 51/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.9596 - val_loss: 0.3280 - val_accuracy: 0.9040\n",
            "Epoch 52/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1082 - accuracy: 0.9600 - val_loss: 0.3265 - val_accuracy: 0.9018\n",
            "Epoch 53/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.9608 - val_loss: 0.3455 - val_accuracy: 0.9024\n",
            "Epoch 54/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.9606 - val_loss: 0.3381 - val_accuracy: 0.9034\n",
            "Epoch 55/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9621 - val_loss: 0.3340 - val_accuracy: 0.9026\n",
            "Epoch 56/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1024 - accuracy: 0.9620 - val_loss: 0.3434 - val_accuracy: 0.9012\n",
            "Epoch 57/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.9625 - val_loss: 0.3339 - val_accuracy: 0.9044\n",
            "Epoch 58/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9627 - val_loss: 0.3688 - val_accuracy: 0.8986\n",
            "Epoch 59/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9622 - val_loss: 0.3520 - val_accuracy: 0.9016\n",
            "Epoch 60/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9638 - val_loss: 0.3514 - val_accuracy: 0.9060\n",
            "Epoch 61/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0927 - accuracy: 0.9658 - val_loss: 0.3517 - val_accuracy: 0.9074\n",
            "Epoch 62/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0920 - accuracy: 0.9652 - val_loss: 0.3536 - val_accuracy: 0.9048\n",
            "Epoch 63/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9646 - val_loss: 0.3583 - val_accuracy: 0.9032\n",
            "Epoch 64/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0939 - accuracy: 0.9648 - val_loss: 0.3820 - val_accuracy: 0.9006\n",
            "Epoch 65/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9656 - val_loss: 0.3787 - val_accuracy: 0.9016\n",
            "Epoch 66/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0867 - accuracy: 0.9675 - val_loss: 0.3591 - val_accuracy: 0.9048\n",
            "Epoch 67/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9679 - val_loss: 0.3844 - val_accuracy: 0.9036\n",
            "Epoch 68/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9682 - val_loss: 0.3762 - val_accuracy: 0.8998\n",
            "Epoch 69/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9676 - val_loss: 0.3723 - val_accuracy: 0.9012\n",
            "Epoch 70/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9691 - val_loss: 0.3836 - val_accuracy: 0.9032\n",
            "Epoch 71/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9714 - val_loss: 0.3964 - val_accuracy: 0.9008\n",
            "Epoch 72/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0792 - accuracy: 0.9707 - val_loss: 0.3802 - val_accuracy: 0.9012\n",
            "Epoch 73/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9698 - val_loss: 0.3821 - val_accuracy: 0.9036\n",
            "Epoch 74/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9713 - val_loss: 0.3851 - val_accuracy: 0.9016\n",
            "Epoch 75/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0769 - accuracy: 0.9711 - val_loss: 0.4070 - val_accuracy: 0.9048\n",
            "Epoch 76/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9726 - val_loss: 0.4103 - val_accuracy: 0.9050\n",
            "Epoch 77/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9728 - val_loss: 0.3850 - val_accuracy: 0.9066\n",
            "Epoch 78/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9736 - val_loss: 0.3878 - val_accuracy: 0.9048\n",
            "Epoch 79/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9732 - val_loss: 0.3899 - val_accuracy: 0.9062\n",
            "Epoch 80/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9735 - val_loss: 0.4029 - val_accuracy: 0.9028\n",
            "Epoch 81/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.4147 - val_accuracy: 0.9028\n",
            "Epoch 82/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9727 - val_loss: 0.4015 - val_accuracy: 0.9018\n",
            "Epoch 83/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9733 - val_loss: 0.4011 - val_accuracy: 0.9032\n",
            "Epoch 84/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9752 - val_loss: 0.3966 - val_accuracy: 0.9014\n",
            "Epoch 85/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9748 - val_loss: 0.4075 - val_accuracy: 0.9056\n",
            "Epoch 86/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9743 - val_loss: 0.4151 - val_accuracy: 0.9004\n",
            "Epoch 87/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9747 - val_loss: 0.4203 - val_accuracy: 0.9066\n",
            "Epoch 88/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9758 - val_loss: 0.4328 - val_accuracy: 0.9012\n",
            "Epoch 89/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9750 - val_loss: 0.4172 - val_accuracy: 0.9024\n",
            "Epoch 90/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9737 - val_loss: 0.4111 - val_accuracy: 0.9092\n",
            "Epoch 91/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9749 - val_loss: 0.4459 - val_accuracy: 0.9004\n",
            "Epoch 92/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0630 - accuracy: 0.9765 - val_loss: 0.4548 - val_accuracy: 0.8964\n",
            "Epoch 93/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.4353 - val_accuracy: 0.9032\n",
            "Epoch 94/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9763 - val_loss: 0.4437 - val_accuracy: 0.9020\n",
            "Epoch 95/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9775 - val_loss: 0.4387 - val_accuracy: 0.9052\n",
            "Epoch 96/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9777 - val_loss: 0.4436 - val_accuracy: 0.8998\n",
            "Epoch 97/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9763 - val_loss: 0.4667 - val_accuracy: 0.9004\n",
            "Epoch 98/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0595 - accuracy: 0.9778 - val_loss: 0.4674 - val_accuracy: 0.9012\n",
            "Epoch 99/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0606 - accuracy: 0.9770 - val_loss: 0.4431 - val_accuracy: 0.9042\n",
            "Epoch 100/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9777 - val_loss: 0.4514 - val_accuracy: 0.9026\n",
            "Epoch 101/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9783 - val_loss: 0.4488 - val_accuracy: 0.9028\n",
            "Epoch 102/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9783 - val_loss: 0.4376 - val_accuracy: 0.9028\n",
            "Epoch 103/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0578 - accuracy: 0.9790 - val_loss: 0.4625 - val_accuracy: 0.9014\n",
            "Epoch 104/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9788 - val_loss: 0.4679 - val_accuracy: 0.9052\n",
            "Epoch 105/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9783 - val_loss: 0.4583 - val_accuracy: 0.9016\n",
            "Epoch 106/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9768 - val_loss: 0.4718 - val_accuracy: 0.9004\n",
            "Epoch 107/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9773 - val_loss: 0.4624 - val_accuracy: 0.9002\n",
            "Epoch 108/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9782 - val_loss: 0.4504 - val_accuracy: 0.9052\n",
            "Epoch 109/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9793 - val_loss: 0.4602 - val_accuracy: 0.9034\n",
            "Epoch 110/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9764 - val_loss: 0.4875 - val_accuracy: 0.9000\n",
            "Epoch 111/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9782 - val_loss: 0.4544 - val_accuracy: 0.9050\n",
            "Epoch 112/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0521 - accuracy: 0.9803 - val_loss: 0.4551 - val_accuracy: 0.9046\n",
            "Epoch 113/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0540 - accuracy: 0.9799 - val_loss: 0.4916 - val_accuracy: 0.9036\n",
            "Epoch 114/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0539 - accuracy: 0.9793 - val_loss: 0.4676 - val_accuracy: 0.9040\n",
            "Epoch 115/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9791 - val_loss: 0.4838 - val_accuracy: 0.9028\n",
            "Epoch 116/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9805 - val_loss: 0.4696 - val_accuracy: 0.9052\n",
            "Epoch 117/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.4856 - val_accuracy: 0.9044\n",
            "Epoch 118/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9816 - val_loss: 0.4811 - val_accuracy: 0.9062\n",
            "Epoch 119/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0477 - accuracy: 0.9820 - val_loss: 0.4791 - val_accuracy: 0.9028\n",
            "Epoch 120/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9826 - val_loss: 0.5066 - val_accuracy: 0.9070\n",
            "Epoch 121/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9810 - val_loss: 0.5023 - val_accuracy: 0.9014\n",
            "Epoch 122/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9812 - val_loss: 0.5043 - val_accuracy: 0.9044\n",
            "Epoch 123/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9823 - val_loss: 0.4924 - val_accuracy: 0.9052\n",
            "Epoch 124/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0454 - accuracy: 0.9828 - val_loss: 0.4952 - val_accuracy: 0.9044\n",
            "Epoch 125/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9828 - val_loss: 0.4863 - val_accuracy: 0.9050\n",
            "Epoch 126/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 0.4930 - val_accuracy: 0.9048\n",
            "Epoch 127/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9822 - val_loss: 0.5071 - val_accuracy: 0.9046\n",
            "Epoch 128/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0458 - accuracy: 0.9828 - val_loss: 0.5134 - val_accuracy: 0.9048\n",
            "Epoch 129/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.4969 - val_accuracy: 0.9008\n",
            "Epoch 130/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 0.5069 - val_accuracy: 0.9026\n",
            "Epoch 131/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9849 - val_loss: 0.5178 - val_accuracy: 0.9012\n",
            "Epoch 132/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 0.5150 - val_accuracy: 0.9030\n",
            "Epoch 133/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0461 - accuracy: 0.9828 - val_loss: 0.5094 - val_accuracy: 0.9002\n",
            "Epoch 134/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9845 - val_loss: 0.5164 - val_accuracy: 0.9034\n",
            "Epoch 135/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9843 - val_loss: 0.5201 - val_accuracy: 0.9008\n",
            "Epoch 136/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9840 - val_loss: 0.5112 - val_accuracy: 0.9080\n",
            "Epoch 137/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0478 - accuracy: 0.9824 - val_loss: 0.5012 - val_accuracy: 0.8996\n",
            "Epoch 138/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0451 - accuracy: 0.9832 - val_loss: 0.5062 - val_accuracy: 0.9064\n",
            "Epoch 139/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.5012 - val_accuracy: 0.9086\n",
            "Epoch 140/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9820 - val_loss: 0.5049 - val_accuracy: 0.8994\n",
            "Epoch 141/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9814 - val_loss: 0.5209 - val_accuracy: 0.9026\n",
            "Epoch 142/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0443 - accuracy: 0.9837 - val_loss: 0.5549 - val_accuracy: 0.9034\n",
            "Epoch 143/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0436 - accuracy: 0.9843 - val_loss: 0.5383 - val_accuracy: 0.9020\n",
            "Epoch 144/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0421 - accuracy: 0.9843 - val_loss: 0.5298 - val_accuracy: 0.9076\n",
            "Epoch 145/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9863 - val_loss: 0.5411 - val_accuracy: 0.9014\n",
            "Epoch 146/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9863 - val_loss: 0.5470 - val_accuracy: 0.9026\n",
            "Epoch 147/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9847 - val_loss: 0.5333 - val_accuracy: 0.9026\n",
            "Epoch 148/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0434 - accuracy: 0.9834 - val_loss: 0.5303 - val_accuracy: 0.8992\n",
            "Epoch 149/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9846 - val_loss: 0.5442 - val_accuracy: 0.8990\n",
            "Epoch 150/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9857 - val_loss: 0.5180 - val_accuracy: 0.9038\n",
            "Epoch 151/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9859 - val_loss: 0.5205 - val_accuracy: 0.9048\n",
            "Epoch 152/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9846 - val_loss: 0.5397 - val_accuracy: 0.9032\n",
            "Epoch 153/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.5336 - val_accuracy: 0.9064\n",
            "Epoch 154/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9851 - val_loss: 0.5597 - val_accuracy: 0.9046\n",
            "Epoch 155/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9855 - val_loss: 0.5684 - val_accuracy: 0.9062\n",
            "Epoch 156/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9846 - val_loss: 0.5527 - val_accuracy: 0.9018\n",
            "Epoch 157/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9861 - val_loss: 0.5606 - val_accuracy: 0.9032\n",
            "Epoch 158/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0377 - accuracy: 0.9856 - val_loss: 0.5629 - val_accuracy: 0.9024\n",
            "Epoch 159/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9869 - val_loss: 0.5449 - val_accuracy: 0.9050\n",
            "Epoch 160/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0360 - accuracy: 0.9866 - val_loss: 0.5830 - val_accuracy: 0.9002\n",
            "Epoch 161/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 0.5647 - val_accuracy: 0.9004\n",
            "Epoch 162/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9841 - val_loss: 0.5433 - val_accuracy: 0.9038\n",
            "Epoch 163/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 0.5402 - val_accuracy: 0.9026\n",
            "Epoch 164/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9840 - val_loss: 0.5326 - val_accuracy: 0.9062\n",
            "Epoch 165/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9851 - val_loss: 0.5250 - val_accuracy: 0.8994\n",
            "Epoch 166/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0390 - accuracy: 0.9856 - val_loss: 0.5760 - val_accuracy: 0.9040\n",
            "Epoch 167/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9848 - val_loss: 0.5779 - val_accuracy: 0.9068\n",
            "Epoch 168/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.5752 - val_accuracy: 0.9026\n",
            "Epoch 169/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 0.5663 - val_accuracy: 0.9056\n",
            "Epoch 170/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0366 - accuracy: 0.9860 - val_loss: 0.5836 - val_accuracy: 0.9032\n",
            "Epoch 171/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9846 - val_loss: 0.5558 - val_accuracy: 0.9012\n",
            "Epoch 172/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.5941 - val_accuracy: 0.9028\n",
            "Epoch 173/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9853 - val_loss: 0.5858 - val_accuracy: 0.9020\n",
            "Epoch 174/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9864 - val_loss: 0.5852 - val_accuracy: 0.9032\n",
            "Epoch 175/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9880 - val_loss: 0.5912 - val_accuracy: 0.9052\n",
            "Epoch 176/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9864 - val_loss: 0.6006 - val_accuracy: 0.9010\n",
            "Epoch 177/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 0.5860 - val_accuracy: 0.8988\n",
            "Epoch 178/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9869 - val_loss: 0.5838 - val_accuracy: 0.9054\n",
            "Epoch 179/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 0.5780 - val_accuracy: 0.9038\n",
            "Epoch 180/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 0.5750 - val_accuracy: 0.9006\n",
            "Epoch 181/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9858 - val_loss: 0.6043 - val_accuracy: 0.9014\n",
            "Epoch 182/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9844 - val_loss: 0.5648 - val_accuracy: 0.9028\n",
            "Epoch 183/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0410 - accuracy: 0.9844 - val_loss: 0.5775 - val_accuracy: 0.9034\n",
            "Epoch 184/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0400 - accuracy: 0.9846 - val_loss: 0.5849 - val_accuracy: 0.9034\n",
            "Epoch 185/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0354 - accuracy: 0.9867 - val_loss: 0.5880 - val_accuracy: 0.9038\n",
            "Epoch 186/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9877 - val_loss: 0.5890 - val_accuracy: 0.9020\n",
            "Epoch 187/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0348 - accuracy: 0.9876 - val_loss: 0.6020 - val_accuracy: 0.9046\n",
            "Epoch 188/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0334 - accuracy: 0.9877 - val_loss: 0.6217 - val_accuracy: 0.8984\n",
            "Epoch 189/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9879 - val_loss: 0.6414 - val_accuracy: 0.9038\n",
            "Epoch 190/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9883 - val_loss: 0.5935 - val_accuracy: 0.9038\n",
            "Epoch 191/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0381 - accuracy: 0.9858 - val_loss: 0.5635 - val_accuracy: 0.9030\n",
            "Epoch 192/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.5864 - val_accuracy: 0.9046\n",
            "Epoch 193/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.5717 - val_accuracy: 0.9036\n",
            "Epoch 194/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9879 - val_loss: 0.6181 - val_accuracy: 0.9042\n",
            "Epoch 195/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.6071 - val_accuracy: 0.9028\n",
            "Epoch 196/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 0.6234 - val_accuracy: 0.9060\n",
            "Epoch 197/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9882 - val_loss: 0.6242 - val_accuracy: 0.9012\n",
            "Epoch 198/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9880 - val_loss: 0.6169 - val_accuracy: 0.9054\n",
            "Epoch 199/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9883 - val_loss: 0.6034 - val_accuracy: 0.9056\n",
            "Epoch 200/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 0.5986 - val_accuracy: 0.9044\n",
            "Epoch 201/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.5968 - val_accuracy: 0.9036\n",
            "Epoch 202/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0277 - accuracy: 0.9900 - val_loss: 0.6246 - val_accuracy: 0.9032\n",
            "Epoch 203/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 0.6081 - val_accuracy: 0.9016\n",
            "Epoch 204/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.6058 - val_accuracy: 0.9024\n",
            "Epoch 205/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9893 - val_loss: 0.6125 - val_accuracy: 0.8978\n",
            "Epoch 206/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9893 - val_loss: 0.6421 - val_accuracy: 0.9022\n",
            "Epoch 207/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 0.6598 - val_accuracy: 0.9008\n",
            "Epoch 208/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0351 - accuracy: 0.9871 - val_loss: 0.6087 - val_accuracy: 0.9030\n",
            "Epoch 209/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9883 - val_loss: 0.6176 - val_accuracy: 0.9014\n",
            "Epoch 210/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9886 - val_loss: 0.6408 - val_accuracy: 0.9016\n",
            "Epoch 211/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9891 - val_loss: 0.6344 - val_accuracy: 0.9028\n",
            "Epoch 212/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.6394 - val_accuracy: 0.9066\n",
            "Epoch 213/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0394 - accuracy: 0.9854 - val_loss: 0.6146 - val_accuracy: 0.9008\n",
            "Epoch 214/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0384 - accuracy: 0.9858 - val_loss: 0.6141 - val_accuracy: 0.9012\n",
            "Epoch 215/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0340 - accuracy: 0.9876 - val_loss: 0.6254 - val_accuracy: 0.9038\n",
            "Epoch 216/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9883 - val_loss: 0.6492 - val_accuracy: 0.9012\n",
            "Epoch 217/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9873 - val_loss: 0.6363 - val_accuracy: 0.9070\n",
            "Epoch 218/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 0.6137 - val_accuracy: 0.9058\n",
            "Epoch 219/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9888 - val_loss: 0.6170 - val_accuracy: 0.9036\n",
            "Epoch 220/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.6141 - val_accuracy: 0.9020\n",
            "Epoch 221/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9907 - val_loss: 0.6464 - val_accuracy: 0.9014\n",
            "Epoch 222/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.6343 - val_accuracy: 0.9050\n",
            "Epoch 223/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.6720 - val_accuracy: 0.8996\n",
            "Epoch 224/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0291 - accuracy: 0.9890 - val_loss: 0.6214 - val_accuracy: 0.9046\n",
            "Epoch 225/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0286 - accuracy: 0.9897 - val_loss: 0.6459 - val_accuracy: 0.8998\n",
            "Epoch 226/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0331 - accuracy: 0.9878 - val_loss: 0.6230 - val_accuracy: 0.9044\n",
            "Epoch 227/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.6387 - val_accuracy: 0.9064\n",
            "Epoch 228/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9902 - val_loss: 0.6535 - val_accuracy: 0.9046\n",
            "Epoch 229/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.6828 - val_accuracy: 0.9012\n",
            "Epoch 230/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9918 - val_loss: 0.6540 - val_accuracy: 0.9016\n",
            "Epoch 231/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.6629 - val_accuracy: 0.9010\n",
            "Epoch 232/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.9917 - val_loss: 0.6928 - val_accuracy: 0.9014\n",
            "Epoch 233/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.6443 - val_accuracy: 0.9050\n",
            "Epoch 234/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0280 - accuracy: 0.9894 - val_loss: 0.6622 - val_accuracy: 0.9028\n",
            "Epoch 235/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9883 - val_loss: 0.6304 - val_accuracy: 0.9022\n",
            "Epoch 236/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 0.6366 - val_accuracy: 0.9020\n",
            "Epoch 237/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 0.6769 - val_accuracy: 0.9034\n",
            "Epoch 238/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9901 - val_loss: 0.6670 - val_accuracy: 0.9030\n",
            "Epoch 239/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.6568 - val_accuracy: 0.9014\n",
            "Epoch 240/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9884 - val_loss: 0.6486 - val_accuracy: 0.9026\n",
            "Epoch 241/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 0.6287 - val_accuracy: 0.9030\n",
            "Epoch 242/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9895 - val_loss: 0.6230 - val_accuracy: 0.8988\n",
            "Epoch 243/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.6173 - val_accuracy: 0.9058\n",
            "Epoch 244/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 0.6621 - val_accuracy: 0.9022\n",
            "Epoch 245/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0293 - accuracy: 0.9895 - val_loss: 0.6509 - val_accuracy: 0.9058\n",
            "Epoch 246/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9884 - val_loss: 0.6693 - val_accuracy: 0.9030\n",
            "Epoch 247/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0296 - accuracy: 0.9889 - val_loss: 0.6530 - val_accuracy: 0.9028\n",
            "Epoch 248/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.6758 - val_accuracy: 0.9104\n",
            "Epoch 249/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9909 - val_loss: 0.6835 - val_accuracy: 0.9054\n",
            "Epoch 250/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 0.6887 - val_accuracy: 0.9066\n",
            "Epoch 251/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9908 - val_loss: 0.7025 - val_accuracy: 0.9026\n",
            "Epoch 252/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.6898 - val_accuracy: 0.9038\n",
            "Epoch 253/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9903 - val_loss: 0.6656 - val_accuracy: 0.9016\n",
            "Epoch 254/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0267 - accuracy: 0.9902 - val_loss: 0.6815 - val_accuracy: 0.9042\n",
            "Epoch 255/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0287 - accuracy: 0.9898 - val_loss: 0.6525 - val_accuracy: 0.9050\n",
            "Epoch 256/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.6475 - val_accuracy: 0.9056\n",
            "Epoch 257/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0298 - accuracy: 0.9891 - val_loss: 0.6836 - val_accuracy: 0.9042\n",
            "Epoch 258/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9922 - val_loss: 0.7169 - val_accuracy: 0.9070\n",
            "Epoch 259/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.6616 - val_accuracy: 0.9072\n",
            "Epoch 260/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9912 - val_loss: 0.6470 - val_accuracy: 0.9082\n",
            "Epoch 261/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.6596 - val_accuracy: 0.9050\n",
            "Epoch 262/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.6971 - val_accuracy: 0.9008\n",
            "Epoch 263/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0295 - accuracy: 0.9890 - val_loss: 0.6545 - val_accuracy: 0.9012\n",
            "Epoch 264/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.6917 - val_accuracy: 0.9010\n",
            "Epoch 265/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 0.9905 - val_loss: 0.6972 - val_accuracy: 0.9054\n",
            "Epoch 266/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9898 - val_loss: 0.6804 - val_accuracy: 0.9036\n",
            "Epoch 267/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.6744 - val_accuracy: 0.9018\n",
            "Epoch 268/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.7003 - val_accuracy: 0.9038\n",
            "Epoch 269/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9914 - val_loss: 0.6819 - val_accuracy: 0.9024\n",
            "Epoch 270/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 0.9921 - val_loss: 0.6926 - val_accuracy: 0.9048\n",
            "Epoch 271/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.7169 - val_accuracy: 0.9052\n",
            "Epoch 272/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.6922 - val_accuracy: 0.9048\n",
            "Epoch 273/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 0.6716 - val_accuracy: 0.9054\n",
            "Epoch 274/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9912 - val_loss: 0.6646 - val_accuracy: 0.9078\n",
            "Epoch 275/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.6942 - val_accuracy: 0.9056\n",
            "Epoch 276/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9906 - val_loss: 0.7011 - val_accuracy: 0.9034\n",
            "Epoch 277/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.6802 - val_accuracy: 0.9086\n",
            "Epoch 278/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.6918 - val_accuracy: 0.9078\n",
            "Epoch 279/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.6835 - val_accuracy: 0.9038\n",
            "Epoch 280/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9905 - val_loss: 0.6684 - val_accuracy: 0.9066\n",
            "Epoch 281/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.6980 - val_accuracy: 0.9048\n",
            "Epoch 282/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.6807 - val_accuracy: 0.9038\n",
            "Epoch 283/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.7000 - val_accuracy: 0.9082\n",
            "Epoch 284/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.7319 - val_accuracy: 0.9054\n",
            "Epoch 285/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.7513 - val_accuracy: 0.9042\n",
            "Epoch 286/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9905 - val_loss: 0.7113 - val_accuracy: 0.9072\n",
            "Epoch 287/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0300 - accuracy: 0.9890 - val_loss: 0.6840 - val_accuracy: 0.9008\n",
            "Epoch 288/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 0.9907 - val_loss: 0.7111 - val_accuracy: 0.9054\n",
            "Epoch 289/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.6615 - val_accuracy: 0.9052\n",
            "Epoch 290/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.7160 - val_accuracy: 0.9030\n",
            "Epoch 291/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.7312 - val_accuracy: 0.9052\n",
            "Epoch 292/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.7199 - val_accuracy: 0.9028\n",
            "Epoch 293/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.9897 - val_loss: 0.6791 - val_accuracy: 0.9054\n",
            "Epoch 294/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.7072 - val_accuracy: 0.9086\n",
            "Epoch 295/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 0.6986 - val_accuracy: 0.9028\n",
            "Epoch 296/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0282 - accuracy: 0.9892 - val_loss: 0.7691 - val_accuracy: 0.9002\n",
            "Epoch 297/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9901 - val_loss: 0.7094 - val_accuracy: 0.9024\n",
            "Epoch 298/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9903 - val_loss: 0.7128 - val_accuracy: 0.9048\n",
            "Epoch 299/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 0.9901 - val_loss: 0.7073 - val_accuracy: 0.9034\n",
            "Epoch 300/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0255 - accuracy: 0.9905 - val_loss: 0.7177 - val_accuracy: 0.9034\n",
            "Epoch 301/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 0.7361 - val_accuracy: 0.9050\n",
            "Epoch 302/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9910 - val_loss: 0.7507 - val_accuracy: 0.9034\n",
            "Epoch 303/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.7064 - val_accuracy: 0.9040\n",
            "Epoch 304/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.7485 - val_accuracy: 0.9094\n",
            "Epoch 305/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0262 - accuracy: 0.9909 - val_loss: 0.6680 - val_accuracy: 0.9054\n",
            "Epoch 306/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9917 - val_loss: 0.7126 - val_accuracy: 0.9068\n",
            "Epoch 307/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9920 - val_loss: 0.7128 - val_accuracy: 0.9062\n",
            "Epoch 308/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.7338 - val_accuracy: 0.9072\n",
            "Epoch 309/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.7474 - val_accuracy: 0.9048\n",
            "Epoch 310/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.6821 - val_accuracy: 0.9076\n",
            "Epoch 311/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0194 - accuracy: 0.9930 - val_loss: 0.6882 - val_accuracy: 0.9038\n",
            "Epoch 312/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.7244 - val_accuracy: 0.9054\n",
            "Epoch 313/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 0.7122 - val_accuracy: 0.9012\n",
            "Epoch 314/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.7081 - val_accuracy: 0.9082\n",
            "Epoch 315/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9927 - val_loss: 0.7207 - val_accuracy: 0.9074\n",
            "Epoch 316/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9924 - val_loss: 0.7203 - val_accuracy: 0.9024\n",
            "Epoch 317/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9926 - val_loss: 0.7373 - val_accuracy: 0.9080\n",
            "Epoch 318/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.7139 - val_accuracy: 0.9056\n",
            "Epoch 319/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9917 - val_loss: 0.7348 - val_accuracy: 0.9054\n",
            "Epoch 320/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.7252 - val_accuracy: 0.9014\n",
            "Epoch 321/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.7112 - val_accuracy: 0.9060\n",
            "Epoch 322/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.7223 - val_accuracy: 0.9044\n",
            "Epoch 323/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0248 - accuracy: 0.9912 - val_loss: 0.7396 - val_accuracy: 0.9060\n",
            "Epoch 324/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9920 - val_loss: 0.6973 - val_accuracy: 0.9052\n",
            "Epoch 325/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 0.7336 - val_accuracy: 0.9024\n",
            "Epoch 326/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 0.7270 - val_accuracy: 0.9024\n",
            "Epoch 327/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.7406 - val_accuracy: 0.9014\n",
            "Epoch 328/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.7500 - val_accuracy: 0.9050\n",
            "Epoch 329/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.7358 - val_accuracy: 0.9038\n",
            "Epoch 330/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.7354 - val_accuracy: 0.9022\n",
            "Epoch 331/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9922 - val_loss: 0.7407 - val_accuracy: 0.9024\n",
            "Epoch 332/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.7031 - val_accuracy: 0.9042\n",
            "Epoch 333/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.7500 - val_accuracy: 0.9032\n",
            "Epoch 334/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.7504 - val_accuracy: 0.9044\n",
            "Epoch 335/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.7624 - val_accuracy: 0.9004\n",
            "Epoch 336/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.7508 - val_accuracy: 0.9036\n",
            "Epoch 337/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9924 - val_loss: 0.7553 - val_accuracy: 0.9028\n",
            "Epoch 338/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9934 - val_loss: 0.7859 - val_accuracy: 0.9044\n",
            "Epoch 339/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.7545 - val_accuracy: 0.9060\n",
            "Epoch 340/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 0.7408 - val_accuracy: 0.9048\n",
            "Epoch 341/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.7282 - val_accuracy: 0.9054\n",
            "Epoch 342/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.7226 - val_accuracy: 0.9052\n",
            "Epoch 343/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.7622 - val_accuracy: 0.9042\n",
            "Epoch 344/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9923 - val_loss: 0.7470 - val_accuracy: 0.9054\n",
            "Epoch 345/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0202 - accuracy: 0.9927 - val_loss: 0.7521 - val_accuracy: 0.9088\n",
            "Epoch 346/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.7300 - val_accuracy: 0.9034\n",
            "Epoch 347/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9898 - val_loss: 0.7501 - val_accuracy: 0.9054\n",
            "Epoch 348/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.7258 - val_accuracy: 0.9070\n",
            "Epoch 349/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.7206 - val_accuracy: 0.9052\n",
            "Epoch 350/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.6906 - val_accuracy: 0.9052\n",
            "Epoch 351/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.7101 - val_accuracy: 0.9062\n",
            "Epoch 352/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 0.7298 - val_accuracy: 0.9004\n",
            "Epoch 353/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.7382 - val_accuracy: 0.9080\n",
            "Epoch 354/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9914 - val_loss: 0.7693 - val_accuracy: 0.9050\n",
            "Epoch 355/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.7502 - val_accuracy: 0.9056\n",
            "Epoch 356/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9929 - val_loss: 0.7961 - val_accuracy: 0.9078\n",
            "Epoch 357/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9936 - val_loss: 0.7992 - val_accuracy: 0.9024\n",
            "Epoch 358/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.8067 - val_accuracy: 0.9062\n",
            "Epoch 359/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.7821 - val_accuracy: 0.9040\n",
            "Epoch 360/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.7813 - val_accuracy: 0.9040\n",
            "Epoch 361/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.7926 - val_accuracy: 0.9002\n",
            "Epoch 362/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9931 - val_loss: 0.7996 - val_accuracy: 0.9054\n",
            "Epoch 363/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.8185 - val_accuracy: 0.9038\n",
            "Epoch 364/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.7878 - val_accuracy: 0.9034\n",
            "Epoch 365/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.7862 - val_accuracy: 0.9054\n",
            "Epoch 366/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.7771 - val_accuracy: 0.9076\n",
            "Epoch 367/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.7857 - val_accuracy: 0.9032\n",
            "Epoch 368/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.7906 - val_accuracy: 0.9028\n",
            "Epoch 369/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9917 - val_loss: 0.7662 - val_accuracy: 0.9074\n",
            "Epoch 370/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9926 - val_loss: 0.7835 - val_accuracy: 0.9052\n",
            "Epoch 371/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.7930 - val_accuracy: 0.9046\n",
            "Epoch 372/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.8051 - val_accuracy: 0.9034\n",
            "Epoch 373/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.8129 - val_accuracy: 0.9050\n",
            "Epoch 374/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.7739 - val_accuracy: 0.9074\n",
            "Epoch 375/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.7830 - val_accuracy: 0.9064\n",
            "Epoch 376/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.8071 - val_accuracy: 0.9040\n",
            "Epoch 377/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.7351 - val_accuracy: 0.9050\n",
            "Epoch 378/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0213 - accuracy: 0.9926 - val_loss: 0.7843 - val_accuracy: 0.9076\n",
            "Epoch 379/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 0.7557 - val_accuracy: 0.9026\n",
            "Epoch 380/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.7580 - val_accuracy: 0.9064\n",
            "Epoch 381/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.7465 - val_accuracy: 0.9022\n",
            "Epoch 382/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9926 - val_loss: 0.7784 - val_accuracy: 0.9044\n",
            "Epoch 383/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9937 - val_loss: 0.8138 - val_accuracy: 0.9038\n",
            "Epoch 384/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 0.7808 - val_accuracy: 0.9050\n",
            "Epoch 385/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.7805 - val_accuracy: 0.9036\n",
            "Epoch 386/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.7817 - val_accuracy: 0.9042\n",
            "Epoch 387/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.7951 - val_accuracy: 0.9056\n",
            "Epoch 388/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.7822 - val_accuracy: 0.9038\n",
            "Epoch 389/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.7919 - val_accuracy: 0.9064\n",
            "Epoch 390/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.7733 - val_accuracy: 0.9042\n",
            "Epoch 391/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.8101 - val_accuracy: 0.9036\n",
            "Epoch 392/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9934 - val_loss: 0.7727 - val_accuracy: 0.9064\n",
            "Epoch 393/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.8045 - val_accuracy: 0.9042\n",
            "Epoch 394/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.7915 - val_accuracy: 0.9074\n",
            "Epoch 395/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9932 - val_loss: 0.8062 - val_accuracy: 0.9026\n",
            "Epoch 396/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.7652 - val_accuracy: 0.9056\n",
            "Epoch 397/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.7999 - val_accuracy: 0.9086\n",
            "Epoch 398/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.7876 - val_accuracy: 0.9040\n",
            "Epoch 399/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.8050 - val_accuracy: 0.9052\n",
            "Epoch 400/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.7533 - val_accuracy: 0.9050\n",
            "Epoch 401/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.8044 - val_accuracy: 0.9046\n",
            "Epoch 402/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.8042 - val_accuracy: 0.9062\n",
            "Epoch 403/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9932 - val_loss: 0.7918 - val_accuracy: 0.9032\n",
            "Epoch 404/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9930 - val_loss: 0.7940 - val_accuracy: 0.9032\n",
            "Epoch 405/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.7798 - val_accuracy: 0.9036\n",
            "Epoch 406/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 0.8169 - val_accuracy: 0.9040\n",
            "Epoch 407/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9923 - val_loss: 0.7912 - val_accuracy: 0.9048\n",
            "Epoch 408/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9919 - val_loss: 0.8201 - val_accuracy: 0.9052\n",
            "Epoch 409/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.8047 - val_accuracy: 0.9016\n",
            "Epoch 410/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9919 - val_loss: 0.7800 - val_accuracy: 0.9012\n",
            "Epoch 411/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0218 - accuracy: 0.9921 - val_loss: 0.7917 - val_accuracy: 0.9030\n",
            "Epoch 412/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.7716 - val_accuracy: 0.9046\n",
            "Epoch 413/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.8177 - val_accuracy: 0.9038\n",
            "Epoch 414/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 0.8306 - val_accuracy: 0.9046\n",
            "Epoch 415/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.7688 - val_accuracy: 0.9042\n",
            "Epoch 416/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.8145 - val_accuracy: 0.9048\n",
            "Epoch 417/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.7764 - val_accuracy: 0.9054\n",
            "Epoch 418/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.7859 - val_accuracy: 0.9036\n",
            "Epoch 419/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.7998 - val_accuracy: 0.9014\n",
            "Epoch 420/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.7625 - val_accuracy: 0.9074\n",
            "Epoch 421/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9940 - val_loss: 0.7875 - val_accuracy: 0.9034\n",
            "Epoch 422/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.7988 - val_accuracy: 0.9054\n",
            "Epoch 423/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.8342 - val_accuracy: 0.9062\n",
            "Epoch 424/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.8572 - val_accuracy: 0.9018\n",
            "Epoch 425/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9941 - val_loss: 0.8119 - val_accuracy: 0.9064\n",
            "Epoch 426/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 0.8083 - val_accuracy: 0.9060\n",
            "Epoch 427/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 0.9934 - val_loss: 0.8031 - val_accuracy: 0.9062\n",
            "Epoch 428/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.8548 - val_accuracy: 0.9042\n",
            "Epoch 429/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.8244 - val_accuracy: 0.9088\n",
            "Epoch 430/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.8085 - val_accuracy: 0.9052\n",
            "Epoch 431/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.8291 - val_accuracy: 0.9062\n",
            "Epoch 432/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.8502 - val_accuracy: 0.9038\n",
            "Epoch 433/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.8111 - val_accuracy: 0.9066\n",
            "Epoch 434/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9938 - val_loss: 0.8504 - val_accuracy: 0.9018\n",
            "Epoch 435/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.8427 - val_accuracy: 0.9016\n",
            "Epoch 436/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 0.8547 - val_accuracy: 0.9062\n",
            "Epoch 437/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.8063 - val_accuracy: 0.9058\n",
            "Epoch 438/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.8202 - val_accuracy: 0.9046\n",
            "Epoch 439/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.7965 - val_accuracy: 0.9042\n",
            "Epoch 440/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.8111 - val_accuracy: 0.9028\n",
            "Epoch 441/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0198 - accuracy: 0.9929 - val_loss: 0.8014 - val_accuracy: 0.9066\n",
            "Epoch 442/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 0.8226 - val_accuracy: 0.9050\n",
            "Epoch 443/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9935 - val_loss: 0.8199 - val_accuracy: 0.9060\n",
            "Epoch 444/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9938 - val_loss: 0.8187 - val_accuracy: 0.9044\n",
            "Epoch 445/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.8527 - val_accuracy: 0.9036\n",
            "Epoch 446/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9929 - val_loss: 0.8195 - val_accuracy: 0.9066\n",
            "Epoch 447/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.8257 - val_accuracy: 0.9070\n",
            "Epoch 448/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.8383 - val_accuracy: 0.9050\n",
            "Epoch 449/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.8406 - val_accuracy: 0.9080\n",
            "Epoch 450/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.8381 - val_accuracy: 0.9062\n",
            "Epoch 451/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.8477 - val_accuracy: 0.9018\n",
            "Epoch 452/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.8388 - val_accuracy: 0.9020\n",
            "Epoch 453/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.7915 - val_accuracy: 0.9040\n",
            "Epoch 454/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.7866 - val_accuracy: 0.9060\n",
            "Epoch 455/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.8067 - val_accuracy: 0.9042\n",
            "Epoch 456/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.7969 - val_accuracy: 0.9034\n",
            "Epoch 457/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.7769 - val_accuracy: 0.9040\n",
            "Epoch 458/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.8052 - val_accuracy: 0.9056\n",
            "Epoch 459/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.7925 - val_accuracy: 0.9016\n",
            "Epoch 460/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.8727 - val_accuracy: 0.9008\n",
            "Epoch 461/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.8570 - val_accuracy: 0.9042\n",
            "Epoch 462/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.7972 - val_accuracy: 0.9054\n",
            "Epoch 463/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.8723 - val_accuracy: 0.9056\n",
            "Epoch 464/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.8726 - val_accuracy: 0.9064\n",
            "Epoch 465/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.8436 - val_accuracy: 0.9042\n",
            "Epoch 466/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.8312 - val_accuracy: 0.9010\n",
            "Epoch 467/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.8215 - val_accuracy: 0.9078\n",
            "Epoch 468/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.8569 - val_accuracy: 0.9028\n",
            "Epoch 469/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.8193 - val_accuracy: 0.9038\n",
            "Epoch 470/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9935 - val_loss: 0.7815 - val_accuracy: 0.9058\n",
            "Epoch 471/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9934 - val_loss: 0.8521 - val_accuracy: 0.9046\n",
            "Epoch 472/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.8079 - val_accuracy: 0.9072\n",
            "Epoch 473/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.8251 - val_accuracy: 0.9064\n",
            "Epoch 474/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9943 - val_loss: 0.8428 - val_accuracy: 0.9050\n",
            "Epoch 475/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 0.8456 - val_accuracy: 0.9036\n",
            "Epoch 476/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.8120 - val_accuracy: 0.9082\n",
            "Epoch 477/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.8632 - val_accuracy: 0.9036\n",
            "Epoch 478/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0167 - accuracy: 0.9940 - val_loss: 0.8409 - val_accuracy: 0.9058\n",
            "Epoch 479/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.8521 - val_accuracy: 0.9062\n",
            "Epoch 480/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.8342 - val_accuracy: 0.9066\n",
            "Epoch 481/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.8871 - val_accuracy: 0.9002\n",
            "Epoch 482/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9938 - val_loss: 0.8156 - val_accuracy: 0.9058\n",
            "Epoch 483/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.8231 - val_accuracy: 0.9066\n",
            "Epoch 484/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.8448 - val_accuracy: 0.9070\n",
            "Epoch 485/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.8427 - val_accuracy: 0.9078\n",
            "Epoch 486/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.8334 - val_accuracy: 0.9094\n",
            "Epoch 487/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.8345 - val_accuracy: 0.9100\n",
            "Epoch 488/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.8706 - val_accuracy: 0.9050\n",
            "Epoch 489/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.8304 - val_accuracy: 0.9062\n",
            "Epoch 490/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.7915 - val_accuracy: 0.9064\n",
            "Epoch 491/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.8183 - val_accuracy: 0.9090\n",
            "Epoch 492/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.8506 - val_accuracy: 0.9060\n",
            "Epoch 493/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.7903 - val_accuracy: 0.9074\n",
            "Epoch 494/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.8327 - val_accuracy: 0.9050\n",
            "Epoch 495/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.8547 - val_accuracy: 0.9020\n",
            "Epoch 496/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9946 - val_loss: 0.8136 - val_accuracy: 0.9088\n",
            "Epoch 497/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9945 - val_loss: 0.8154 - val_accuracy: 0.9056\n",
            "Epoch 498/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.8282 - val_accuracy: 0.9074\n",
            "Epoch 499/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.8113 - val_accuracy: 0.9034\n",
            "Epoch 500/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0233 - accuracy: 0.9914 - val_loss: 0.8014 - val_accuracy: 0.9036\n",
            "Epoch 501/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.8353 - val_accuracy: 0.9054\n",
            "Epoch 502/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9924 - val_loss: 0.8393 - val_accuracy: 0.9030\n",
            "Epoch 503/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.8589 - val_accuracy: 0.9056\n",
            "Epoch 504/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9936 - val_loss: 0.8186 - val_accuracy: 0.9072\n",
            "Epoch 505/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9941 - val_loss: 0.8404 - val_accuracy: 0.9014\n",
            "Epoch 506/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.8413 - val_accuracy: 0.9002\n",
            "Epoch 507/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0171 - accuracy: 0.9941 - val_loss: 0.8670 - val_accuracy: 0.9032\n",
            "Epoch 508/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.8384 - val_accuracy: 0.9036\n",
            "Epoch 509/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.9009 - val_accuracy: 0.9070\n",
            "Epoch 510/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.8464 - val_accuracy: 0.9044\n",
            "Epoch 511/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.8808 - val_accuracy: 0.9038\n",
            "Epoch 512/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.8513 - val_accuracy: 0.9050\n",
            "Epoch 513/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.8691 - val_accuracy: 0.9060\n",
            "Epoch 514/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.9048 - val_accuracy: 0.9000\n",
            "Epoch 515/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.8269 - val_accuracy: 0.9038\n",
            "Epoch 516/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.8767 - val_accuracy: 0.9066\n",
            "Epoch 517/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.8934 - val_accuracy: 0.9058\n",
            "Epoch 518/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.8991 - val_accuracy: 0.9090\n",
            "Epoch 519/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.8403 - val_accuracy: 0.9048\n",
            "Epoch 520/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9956 - val_loss: 0.8399 - val_accuracy: 0.9026\n",
            "Epoch 521/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.8972 - val_accuracy: 0.9046\n",
            "Epoch 522/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9946 - val_loss: 0.8353 - val_accuracy: 0.9046\n",
            "Epoch 523/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.7934 - val_accuracy: 0.9082\n",
            "Epoch 524/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.8732 - val_accuracy: 0.9058\n",
            "Epoch 525/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.8680 - val_accuracy: 0.9036\n",
            "Epoch 526/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.8530 - val_accuracy: 0.9036\n",
            "Epoch 527/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.8659 - val_accuracy: 0.9016\n",
            "Epoch 528/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.8587 - val_accuracy: 0.9068\n",
            "Epoch 529/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.8517 - val_accuracy: 0.9112\n",
            "Epoch 530/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.8600 - val_accuracy: 0.9050\n",
            "Epoch 531/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.8631 - val_accuracy: 0.9056\n",
            "Epoch 532/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.8818 - val_accuracy: 0.9046\n",
            "Epoch 533/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.8508 - val_accuracy: 0.9064\n",
            "Epoch 534/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.8787 - val_accuracy: 0.9038\n",
            "Epoch 535/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.7918 - val_accuracy: 0.9074\n",
            "Epoch 536/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.8598 - val_accuracy: 0.9050\n",
            "Epoch 537/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.8521 - val_accuracy: 0.9036\n",
            "Epoch 538/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.8276 - val_accuracy: 0.9042\n",
            "Epoch 539/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.8487 - val_accuracy: 0.9026\n",
            "Epoch 540/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.8724 - val_accuracy: 0.9008\n",
            "Epoch 541/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.8220 - val_accuracy: 0.9018\n",
            "Epoch 542/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.8841 - val_accuracy: 0.9046\n",
            "Epoch 543/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.8931 - val_accuracy: 0.9032\n",
            "Epoch 544/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.8946 - val_accuracy: 0.9024\n",
            "Epoch 545/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.8457 - val_accuracy: 0.9032\n",
            "Epoch 546/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9950 - val_loss: 0.9296 - val_accuracy: 0.9044\n",
            "Epoch 547/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.8689 - val_accuracy: 0.9070\n",
            "Epoch 548/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.8979 - val_accuracy: 0.9070\n",
            "Epoch 549/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.8754 - val_accuracy: 0.9040\n",
            "Epoch 550/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.8811 - val_accuracy: 0.9040\n",
            "Epoch 551/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.8739 - val_accuracy: 0.9040\n",
            "Epoch 552/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 0.8886 - val_accuracy: 0.9054\n",
            "Epoch 553/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.8685 - val_accuracy: 0.9036\n",
            "Epoch 554/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0161 - accuracy: 0.9943 - val_loss: 0.8486 - val_accuracy: 0.9028\n",
            "Epoch 555/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.8655 - val_accuracy: 0.9040\n",
            "Epoch 556/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.8969 - val_accuracy: 0.9026\n",
            "Epoch 557/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.8715 - val_accuracy: 0.9016\n",
            "Epoch 558/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.8593 - val_accuracy: 0.9044\n",
            "Epoch 559/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.8519 - val_accuracy: 0.9030\n",
            "Epoch 560/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.8690 - val_accuracy: 0.8992\n",
            "Epoch 561/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 0.8305 - val_accuracy: 0.9038\n",
            "Epoch 562/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0162 - accuracy: 0.9945 - val_loss: 0.8789 - val_accuracy: 0.9056\n",
            "Epoch 563/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.8863 - val_accuracy: 0.9044\n",
            "Epoch 564/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.8973 - val_accuracy: 0.9054\n",
            "Epoch 565/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.8934 - val_accuracy: 0.9038\n",
            "Epoch 566/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.8744 - val_accuracy: 0.9050\n",
            "Epoch 567/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.8924 - val_accuracy: 0.9040\n",
            "Epoch 568/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.8983 - val_accuracy: 0.9090\n",
            "Epoch 569/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.8882 - val_accuracy: 0.9058\n",
            "Epoch 570/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.8379 - val_accuracy: 0.9076\n",
            "Epoch 571/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.8860 - val_accuracy: 0.9072\n",
            "Epoch 572/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.8512 - val_accuracy: 0.9076\n",
            "Epoch 573/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.8758 - val_accuracy: 0.9068\n",
            "Epoch 574/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.8903 - val_accuracy: 0.9040\n",
            "Epoch 575/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.8946 - val_accuracy: 0.9072\n",
            "Epoch 576/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.8735 - val_accuracy: 0.9054\n",
            "Epoch 577/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.8913 - val_accuracy: 0.9054\n",
            "Epoch 578/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.8812 - val_accuracy: 0.9008\n",
            "Epoch 579/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.9085 - val_accuracy: 0.9004\n",
            "Epoch 580/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.8704 - val_accuracy: 0.9040\n",
            "Epoch 581/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.8900 - val_accuracy: 0.9044\n",
            "Epoch 582/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.8834 - val_accuracy: 0.9028\n",
            "Epoch 583/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.9153 - val_accuracy: 0.9020\n",
            "Epoch 584/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.9031 - val_accuracy: 0.9048\n",
            "Epoch 585/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9950 - val_loss: 0.8635 - val_accuracy: 0.9044\n",
            "Epoch 586/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.8905 - val_accuracy: 0.9056\n",
            "Epoch 587/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.8953 - val_accuracy: 0.9054\n",
            "Epoch 588/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.8951 - val_accuracy: 0.9058\n",
            "Epoch 589/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.8548 - val_accuracy: 0.9050\n",
            "Epoch 590/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.8987 - val_accuracy: 0.9036\n",
            "Epoch 591/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.8939 - val_accuracy: 0.9058\n",
            "Epoch 592/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.8722 - val_accuracy: 0.9052\n",
            "Epoch 593/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.8913 - val_accuracy: 0.9060\n",
            "Epoch 594/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.9071 - val_accuracy: 0.9078\n",
            "Epoch 595/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.9425 - val_accuracy: 0.9032\n",
            "Epoch 596/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.8992 - val_accuracy: 0.9048\n",
            "Epoch 597/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.9046 - val_accuracy: 0.9046\n",
            "Epoch 598/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.9226 - val_accuracy: 0.9046\n",
            "Epoch 599/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.8929 - val_accuracy: 0.9062\n",
            "Epoch 600/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.8838 - val_accuracy: 0.9040\n",
            "Epoch 601/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.8959 - val_accuracy: 0.9044\n",
            "Epoch 602/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.8995 - val_accuracy: 0.9080\n",
            "Epoch 603/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.8829 - val_accuracy: 0.9058\n",
            "Epoch 604/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.8751 - val_accuracy: 0.9056\n",
            "Epoch 605/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.9340 - val_accuracy: 0.9048\n",
            "Epoch 606/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.9345 - val_accuracy: 0.9046\n",
            "Epoch 607/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.9743 - val_accuracy: 0.9056\n",
            "Epoch 608/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.9575 - val_accuracy: 0.9062\n",
            "Epoch 609/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.9372 - val_accuracy: 0.9022\n",
            "Epoch 610/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.9198 - val_accuracy: 0.9042\n",
            "Epoch 611/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.9057 - val_accuracy: 0.9048\n",
            "Epoch 612/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.8795 - val_accuracy: 0.9022\n",
            "Epoch 613/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.9301 - val_accuracy: 0.9078\n",
            "Epoch 614/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.9006 - val_accuracy: 0.9028\n",
            "Epoch 615/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.9116 - val_accuracy: 0.9030\n",
            "Epoch 616/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.9618 - val_accuracy: 0.9026\n",
            "Epoch 617/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.9199 - val_accuracy: 0.9054\n",
            "Epoch 618/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.9496 - val_accuracy: 0.9048\n",
            "Epoch 619/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.8795 - val_accuracy: 0.9080\n",
            "Epoch 620/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.9206 - val_accuracy: 0.9054\n",
            "Epoch 621/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.8964 - val_accuracy: 0.9074\n",
            "Epoch 622/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9949 - val_loss: 0.8939 - val_accuracy: 0.9084\n",
            "Epoch 623/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.9002 - val_accuracy: 0.9048\n",
            "Epoch 624/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9938 - val_loss: 0.9111 - val_accuracy: 0.9060\n",
            "Epoch 625/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.8860 - val_accuracy: 0.9050\n",
            "Epoch 626/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.8897 - val_accuracy: 0.9082\n",
            "Epoch 627/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.8907 - val_accuracy: 0.9050\n",
            "Epoch 628/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.8928 - val_accuracy: 0.9072\n",
            "Epoch 629/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.8982 - val_accuracy: 0.9056\n",
            "Epoch 630/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.8842 - val_accuracy: 0.9074\n",
            "Epoch 631/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.9212 - val_accuracy: 0.9070\n",
            "Epoch 632/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.8861 - val_accuracy: 0.9064\n",
            "Epoch 633/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.9486 - val_accuracy: 0.9040\n",
            "Epoch 634/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.9238 - val_accuracy: 0.9046\n",
            "Epoch 635/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.9114 - val_accuracy: 0.9038\n",
            "Epoch 636/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.9143 - val_accuracy: 0.9062\n",
            "Epoch 637/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.9450 - val_accuracy: 0.9078\n",
            "Epoch 638/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.9431 - val_accuracy: 0.9064\n",
            "Epoch 639/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.9391 - val_accuracy: 0.9052\n",
            "Epoch 640/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.9250 - val_accuracy: 0.9056\n",
            "Epoch 641/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.9303 - val_accuracy: 0.9042\n",
            "Epoch 642/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.9419 - val_accuracy: 0.9060\n",
            "Epoch 643/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.9374 - val_accuracy: 0.9016\n",
            "Epoch 644/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.9345 - val_accuracy: 0.9012\n",
            "Epoch 645/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.9240 - val_accuracy: 0.9036\n",
            "Epoch 646/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9957 - val_loss: 0.9125 - val_accuracy: 0.9034\n",
            "Epoch 647/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.8970 - val_accuracy: 0.9052\n",
            "Epoch 648/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.8845 - val_accuracy: 0.9088\n",
            "Epoch 649/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.9543 - val_accuracy: 0.9018\n",
            "Epoch 650/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 0.9486 - val_accuracy: 0.9046\n",
            "Epoch 651/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.9378 - val_accuracy: 0.9046\n",
            "Epoch 652/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.9012 - val_accuracy: 0.9050\n",
            "Epoch 653/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.9176 - val_accuracy: 0.9042\n",
            "Epoch 654/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.9127 - val_accuracy: 0.9084\n",
            "Epoch 655/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.9037 - val_accuracy: 0.9078\n",
            "Epoch 656/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.9836 - val_accuracy: 0.9070\n",
            "Epoch 657/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.9055 - val_accuracy: 0.9038\n",
            "Epoch 658/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.9454 - val_accuracy: 0.9014\n",
            "Epoch 659/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.8985 - val_accuracy: 0.9060\n",
            "Epoch 660/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.9180 - val_accuracy: 0.9084\n",
            "Epoch 661/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.8708 - val_accuracy: 0.9074\n",
            "Epoch 662/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.9448 - val_accuracy: 0.9028\n",
            "Epoch 663/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.9055 - val_accuracy: 0.9044\n",
            "Epoch 664/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.9575 - val_accuracy: 0.9032\n",
            "Epoch 665/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.9389 - val_accuracy: 0.9042\n",
            "Epoch 666/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.8991 - val_accuracy: 0.9080\n",
            "Epoch 667/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.8668 - val_accuracy: 0.9076\n",
            "Epoch 668/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.9383 - val_accuracy: 0.9070\n",
            "Epoch 669/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.9083 - val_accuracy: 0.9036\n",
            "Epoch 670/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.8963 - val_accuracy: 0.9074\n",
            "Epoch 671/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.9197 - val_accuracy: 0.9070\n",
            "Epoch 672/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.9363 - val_accuracy: 0.9062\n",
            "Epoch 673/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.9335 - val_accuracy: 0.9034\n",
            "Epoch 674/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.8785 - val_accuracy: 0.9036\n",
            "Epoch 675/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.9180 - val_accuracy: 0.9044\n",
            "Epoch 676/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.9295 - val_accuracy: 0.9070\n",
            "Epoch 677/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.8756 - val_accuracy: 0.9052\n",
            "Epoch 678/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.9419 - val_accuracy: 0.9054\n",
            "Epoch 679/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.9132 - val_accuracy: 0.9066\n",
            "Epoch 680/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.9218 - val_accuracy: 0.9044\n",
            "Epoch 681/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.9756 - val_accuracy: 0.9078\n",
            "Epoch 682/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.9229 - val_accuracy: 0.9060\n",
            "Epoch 683/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.9452 - val_accuracy: 0.9110\n",
            "Epoch 684/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.9430 - val_accuracy: 0.9056\n",
            "Epoch 685/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.9577 - val_accuracy: 0.9070\n",
            "Epoch 686/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.9481 - val_accuracy: 0.9080\n",
            "Epoch 687/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.9477 - val_accuracy: 0.9070\n",
            "Epoch 688/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.9278 - val_accuracy: 0.9054\n",
            "Epoch 689/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.9389 - val_accuracy: 0.9070\n",
            "Epoch 690/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9953 - val_loss: 0.8958 - val_accuracy: 0.9074\n",
            "Epoch 691/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.9424 - val_accuracy: 0.9076\n",
            "Epoch 692/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.9602 - val_accuracy: 0.9058\n",
            "Epoch 693/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.9765 - val_accuracy: 0.9050\n",
            "Epoch 694/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.9676 - val_accuracy: 0.9084\n",
            "Epoch 695/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.9757 - val_accuracy: 0.9058\n",
            "Epoch 696/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.9763 - val_accuracy: 0.9052\n",
            "Epoch 697/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.9804 - val_accuracy: 0.9068\n",
            "Epoch 698/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.9270 - val_accuracy: 0.9054\n",
            "Epoch 699/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 0.9202 - val_accuracy: 0.9098\n",
            "Epoch 700/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.8961 - val_accuracy: 0.9034\n",
            "Epoch 701/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.9126 - val_accuracy: 0.9052\n",
            "Epoch 702/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 0.9954 - val_loss: 0.8950 - val_accuracy: 0.9052\n",
            "Epoch 703/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.8924 - val_accuracy: 0.9062\n",
            "Epoch 704/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.9294 - val_accuracy: 0.9040\n",
            "Epoch 705/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.9164 - val_accuracy: 0.9052\n",
            "Epoch 706/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.9004 - val_accuracy: 0.9086\n",
            "Epoch 707/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.9520 - val_accuracy: 0.9068\n",
            "Epoch 708/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 0.9936 - val_accuracy: 0.9034\n",
            "Epoch 709/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.9427 - val_accuracy: 0.9072\n",
            "Epoch 710/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.9744 - val_accuracy: 0.9048\n",
            "Epoch 711/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.9052 - val_accuracy: 0.9068\n",
            "Epoch 712/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.9135 - val_accuracy: 0.9116\n",
            "Epoch 713/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.9493 - val_accuracy: 0.9084\n",
            "Epoch 714/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0130 - accuracy: 0.9953 - val_loss: 0.9521 - val_accuracy: 0.9046\n",
            "Epoch 715/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.9130 - val_accuracy: 0.9052\n",
            "Epoch 716/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.9788 - val_accuracy: 0.9072\n",
            "Epoch 717/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.9593 - val_accuracy: 0.9058\n",
            "Epoch 718/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.9286 - val_accuracy: 0.9080\n",
            "Epoch 719/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.9738 - val_accuracy: 0.9046\n",
            "Epoch 720/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.9268 - val_accuracy: 0.9044\n",
            "Epoch 721/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.9368 - val_accuracy: 0.9062\n",
            "Epoch 722/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.9242 - val_accuracy: 0.9064\n",
            "Epoch 723/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.9165 - val_accuracy: 0.9080\n",
            "Epoch 724/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.9031 - val_accuracy: 0.9072\n",
            "Epoch 725/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9961 - val_loss: 0.9066 - val_accuracy: 0.9086\n",
            "Epoch 726/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.9059 - val_accuracy: 0.9102\n",
            "Epoch 727/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.9475 - val_accuracy: 0.9056\n",
            "Epoch 728/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.9481 - val_accuracy: 0.9042\n",
            "Epoch 729/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.9656 - val_accuracy: 0.9030\n",
            "Epoch 730/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.9871 - val_accuracy: 0.9020\n",
            "Epoch 731/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.9882 - val_accuracy: 0.9054\n",
            "Epoch 732/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9964 - val_loss: 0.9845 - val_accuracy: 0.9032\n",
            "Epoch 733/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 1.0131 - val_accuracy: 0.9046\n",
            "Epoch 734/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.9289 - val_accuracy: 0.9078\n",
            "Epoch 735/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.9587 - val_accuracy: 0.9044\n",
            "Epoch 736/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.9836 - val_accuracy: 0.9050\n",
            "Epoch 737/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.9634 - val_accuracy: 0.9072\n",
            "Epoch 738/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.9906 - val_accuracy: 0.9054\n",
            "Epoch 739/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.9291 - val_accuracy: 0.9068\n",
            "Epoch 740/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.9546 - val_accuracy: 0.9074\n",
            "Epoch 741/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.9795 - val_accuracy: 0.9024\n",
            "Epoch 742/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.9573 - val_accuracy: 0.9046\n",
            "Epoch 743/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.9441 - val_accuracy: 0.9032\n",
            "Epoch 744/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.9402 - val_accuracy: 0.9036\n",
            "Epoch 745/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.9702 - val_accuracy: 0.9038\n",
            "Epoch 746/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.9769 - val_accuracy: 0.9056\n",
            "Epoch 747/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.9134 - val_accuracy: 0.9036\n",
            "Epoch 748/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.9174 - val_accuracy: 0.9062\n",
            "Epoch 749/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.9377 - val_accuracy: 0.9060\n",
            "Epoch 750/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.9698 - val_accuracy: 0.9018\n",
            "Epoch 751/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.9229 - val_accuracy: 0.9048\n",
            "Epoch 752/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.9601 - val_accuracy: 0.9074\n",
            "Epoch 753/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.9469 - val_accuracy: 0.9030\n",
            "Epoch 754/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.9847 - val_accuracy: 0.9056\n",
            "Epoch 755/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.9477 - val_accuracy: 0.9092\n",
            "Epoch 756/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.9510 - val_accuracy: 0.9048\n",
            "Epoch 757/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.9783 - val_accuracy: 0.9038\n",
            "Epoch 758/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.9976 - val_accuracy: 0.9068\n",
            "Epoch 759/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.9664 - val_accuracy: 0.9026\n",
            "Epoch 760/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.9610 - val_accuracy: 0.9082\n",
            "Epoch 761/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.9808 - val_accuracy: 0.9050\n",
            "Epoch 762/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.9858 - val_accuracy: 0.9062\n",
            "Epoch 763/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.9039 - val_accuracy: 0.9052\n",
            "Epoch 764/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.9582 - val_accuracy: 0.9050\n",
            "Epoch 765/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.9952 - val_accuracy: 0.9054\n",
            "Epoch 766/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.9667 - val_accuracy: 0.9078\n",
            "Epoch 767/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.9486 - val_accuracy: 0.9070\n",
            "Epoch 768/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.9242 - val_accuracy: 0.9036\n",
            "Epoch 769/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.9431 - val_accuracy: 0.9052\n",
            "Epoch 770/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.9329 - val_accuracy: 0.9046\n",
            "Epoch 771/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.9067 - val_accuracy: 0.9036\n",
            "Epoch 772/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.9986 - val_accuracy: 0.9054\n",
            "Epoch 773/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.9535 - val_accuracy: 0.9062\n",
            "Epoch 774/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.0079 - val_accuracy: 0.9048\n",
            "Epoch 775/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.9270 - val_accuracy: 0.9038\n",
            "Epoch 776/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.9876 - val_accuracy: 0.9026\n",
            "Epoch 777/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.9194 - val_accuracy: 0.9078\n",
            "Epoch 778/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.9542 - val_accuracy: 0.9042\n",
            "Epoch 779/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.9784 - val_accuracy: 0.9020\n",
            "Epoch 780/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.9482 - val_accuracy: 0.9038\n",
            "Epoch 781/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.9776 - val_accuracy: 0.9042\n",
            "Epoch 782/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.9501 - val_accuracy: 0.9044\n",
            "Epoch 783/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.9885 - val_accuracy: 0.9058\n",
            "Epoch 784/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.9585 - val_accuracy: 0.9038\n",
            "Epoch 785/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 0.9688 - val_accuracy: 0.9038\n",
            "Epoch 786/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.9464 - val_accuracy: 0.9048\n",
            "Epoch 787/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.9276 - val_accuracy: 0.9052\n",
            "Epoch 788/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.9648 - val_accuracy: 0.9012\n",
            "Epoch 789/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9969 - val_loss: 1.0001 - val_accuracy: 0.9072\n",
            "Epoch 790/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 1.0286 - val_accuracy: 0.9004\n",
            "Epoch 791/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.9950 - val_accuracy: 0.9038\n",
            "Epoch 792/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 1.0118 - val_accuracy: 0.9054\n",
            "Epoch 793/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 1.0322 - val_accuracy: 0.9044\n",
            "Epoch 794/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.9978 - val_accuracy: 0.9036\n",
            "Epoch 795/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.9904 - val_accuracy: 0.9034\n",
            "Epoch 796/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.9981 - val_accuracy: 0.9046\n",
            "Epoch 797/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.9420 - val_accuracy: 0.9040\n",
            "Epoch 798/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 1.0271 - val_accuracy: 0.9028\n",
            "Epoch 799/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.0132 - val_accuracy: 0.9076\n",
            "Epoch 800/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.0244 - val_accuracy: 0.9046\n",
            "Epoch 801/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.9635 - val_accuracy: 0.9056\n",
            "Epoch 802/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.9865 - val_accuracy: 0.9018\n",
            "Epoch 803/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.9846 - val_accuracy: 0.9062\n",
            "Epoch 804/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9958 - val_loss: 0.9627 - val_accuracy: 0.9070\n",
            "Epoch 805/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9971 - val_loss: 1.0066 - val_accuracy: 0.9048\n",
            "Epoch 806/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.9771 - val_accuracy: 0.9024\n",
            "Epoch 807/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.9617 - val_accuracy: 0.9034\n",
            "Epoch 808/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.0120 - val_accuracy: 0.9072\n",
            "Epoch 809/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.9953 - val_accuracy: 0.9062\n",
            "Epoch 810/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.9822 - val_accuracy: 0.9056\n",
            "Epoch 811/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.9632 - val_accuracy: 0.9046\n",
            "Epoch 812/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.9615 - val_accuracy: 0.9068\n",
            "Epoch 813/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.9914 - val_accuracy: 0.9040\n",
            "Epoch 814/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.9814 - val_accuracy: 0.9050\n",
            "Epoch 815/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 0.9968 - val_accuracy: 0.9014\n",
            "Epoch 816/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.9837 - val_accuracy: 0.9058\n",
            "Epoch 817/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.9696 - val_accuracy: 0.9038\n",
            "Epoch 818/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.0168 - val_accuracy: 0.9066\n",
            "Epoch 819/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9969 - val_loss: 1.0067 - val_accuracy: 0.9050\n",
            "Epoch 820/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.9921 - val_accuracy: 0.9064\n",
            "Epoch 821/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 1.0321 - val_accuracy: 0.9072\n",
            "Epoch 822/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.9790 - val_accuracy: 0.9074\n",
            "Epoch 823/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.0147 - val_accuracy: 0.9086\n",
            "Epoch 824/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.9918 - val_accuracy: 0.9066\n",
            "Epoch 825/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.0425 - val_accuracy: 0.9048\n",
            "Epoch 826/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.0451 - val_accuracy: 0.9058\n",
            "Epoch 827/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 1.0126 - val_accuracy: 0.9038\n",
            "Epoch 828/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.0342 - val_accuracy: 0.9054\n",
            "Epoch 829/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 1.0110 - val_accuracy: 0.9004\n",
            "Epoch 830/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 1.0432 - val_accuracy: 0.9040\n",
            "Epoch 831/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.1147 - val_accuracy: 0.9014\n",
            "Epoch 832/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.0351 - val_accuracy: 0.9018\n",
            "Epoch 833/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.9633 - val_accuracy: 0.9056\n",
            "Epoch 834/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.9504 - val_accuracy: 0.9036\n",
            "Epoch 835/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.9240 - val_accuracy: 0.9052\n",
            "Epoch 836/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.9668 - val_accuracy: 0.9042\n",
            "Epoch 837/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.9626 - val_accuracy: 0.9040\n",
            "Epoch 838/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.0058 - val_accuracy: 0.9036\n",
            "Epoch 839/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.9779 - val_accuracy: 0.9032\n",
            "Epoch 840/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.9835 - val_accuracy: 0.9048\n",
            "Epoch 841/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.9904 - val_accuracy: 0.9076\n",
            "Epoch 842/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.0206 - val_accuracy: 0.9064\n",
            "Epoch 843/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.9945 - val_accuracy: 0.8984\n",
            "Epoch 844/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.9859 - val_accuracy: 0.9024\n",
            "Epoch 845/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.0048 - val_accuracy: 0.9036\n",
            "Epoch 846/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.9727 - val_accuracy: 0.9042\n",
            "Epoch 847/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.9854 - val_accuracy: 0.9008\n",
            "Epoch 848/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.9893 - val_accuracy: 0.9038\n",
            "Epoch 849/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.9870 - val_accuracy: 0.9040\n",
            "Epoch 850/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.9748 - val_accuracy: 0.9032\n",
            "Epoch 851/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.9818 - val_accuracy: 0.9048\n",
            "Epoch 852/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.9865 - val_accuracy: 0.9072\n",
            "Epoch 853/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.9695 - val_accuracy: 0.9038\n",
            "Epoch 854/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 1.0057 - val_accuracy: 0.9062\n",
            "Epoch 855/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 1.0218 - val_accuracy: 0.9072\n",
            "Epoch 856/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.0101 - val_accuracy: 0.9040\n",
            "Epoch 857/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.9449 - val_accuracy: 0.9070\n",
            "Epoch 858/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.9901 - val_accuracy: 0.9044\n",
            "Epoch 859/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 1.0193 - val_accuracy: 0.9066\n",
            "Epoch 860/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.0144 - val_accuracy: 0.9082\n",
            "Epoch 861/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.9921 - val_accuracy: 0.9060\n",
            "Epoch 862/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 1.0077 - val_accuracy: 0.9018\n",
            "Epoch 863/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.0017 - val_accuracy: 0.9030\n",
            "Epoch 864/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.0186 - val_accuracy: 0.9034\n",
            "Epoch 865/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.9637 - val_accuracy: 0.9048\n",
            "Epoch 866/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.9828 - val_accuracy: 0.9044\n",
            "Epoch 867/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.0308 - val_accuracy: 0.9042\n",
            "Epoch 868/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 1.0367 - val_accuracy: 0.9078\n",
            "Epoch 869/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.0267 - val_accuracy: 0.9056\n",
            "Epoch 870/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 1.0081 - val_accuracy: 0.9074\n",
            "Epoch 871/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 1.0679 - val_accuracy: 0.9026\n",
            "Epoch 872/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.9916 - val_accuracy: 0.9032\n",
            "Epoch 873/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.0020 - val_accuracy: 0.9064\n",
            "Epoch 874/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.0205 - val_accuracy: 0.9046\n",
            "Epoch 875/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 1.0305 - val_accuracy: 0.9010\n",
            "Epoch 876/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.0066 - val_accuracy: 0.9070\n",
            "Epoch 877/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.0105 - val_accuracy: 0.9076\n",
            "Epoch 878/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.9995 - val_accuracy: 0.9036\n",
            "Epoch 879/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 1.0125 - val_accuracy: 0.9062\n",
            "Epoch 880/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 1.0254 - val_accuracy: 0.9058\n",
            "Epoch 881/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 0.9806 - val_accuracy: 0.9066\n",
            "Epoch 882/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 1.0808 - val_accuracy: 0.9014\n",
            "Epoch 883/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 1.0405 - val_accuracy: 0.9048\n",
            "Epoch 884/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.9950 - val_accuracy: 0.9048\n",
            "Epoch 885/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 1.0306 - val_accuracy: 0.9048\n",
            "Epoch 886/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 1.0193 - val_accuracy: 0.9028\n",
            "Epoch 887/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.9883 - val_accuracy: 0.9014\n",
            "Epoch 888/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 1.0002 - val_accuracy: 0.9034\n",
            "Epoch 889/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.9889 - val_accuracy: 0.9052\n",
            "Epoch 890/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.0162 - val_accuracy: 0.9026\n",
            "Epoch 891/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.0074 - val_accuracy: 0.9038\n",
            "Epoch 892/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.0088 - val_accuracy: 0.9026\n",
            "Epoch 893/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.0174 - val_accuracy: 0.9012\n",
            "Epoch 894/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.0283 - val_accuracy: 0.9046\n",
            "Epoch 895/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 1.0112 - val_accuracy: 0.9006\n",
            "Epoch 896/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 1.0039 - val_accuracy: 0.9056\n",
            "Epoch 897/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.9964 - val_accuracy: 0.9074\n",
            "Epoch 898/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.9847 - val_accuracy: 0.9050\n",
            "Epoch 899/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 1.0003 - val_accuracy: 0.9062\n",
            "Epoch 900/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.9967 - val_accuracy: 0.9054\n",
            "Epoch 901/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 1.0168 - val_accuracy: 0.9036\n",
            "Epoch 902/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.9953 - val_accuracy: 0.9056\n",
            "Epoch 903/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 1.0237 - val_accuracy: 0.9072\n",
            "Epoch 904/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 1.0031 - val_accuracy: 0.9054\n",
            "Epoch 905/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.0184 - val_accuracy: 0.9062\n",
            "Epoch 906/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.9886 - val_accuracy: 0.9046\n",
            "Epoch 907/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.9741 - val_accuracy: 0.9078\n",
            "Epoch 908/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.9675 - val_accuracy: 0.9068\n",
            "Epoch 909/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.0171 - val_accuracy: 0.9068\n",
            "Epoch 910/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.9955 - val_accuracy: 0.9026\n",
            "Epoch 911/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.0123 - val_accuracy: 0.9044\n",
            "Epoch 912/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.9499 - val_accuracy: 0.9056\n",
            "Epoch 913/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.9846 - val_accuracy: 0.9048\n",
            "Epoch 914/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 1.0338 - val_accuracy: 0.9056\n",
            "Epoch 915/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.0147 - val_accuracy: 0.9034\n",
            "Epoch 916/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.9828 - val_accuracy: 0.9050\n",
            "Epoch 917/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 1.0209 - val_accuracy: 0.9070\n",
            "Epoch 918/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.9799 - val_accuracy: 0.9040\n",
            "Epoch 919/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 1.0223 - val_accuracy: 0.9056\n",
            "Epoch 920/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 1.0022 - val_accuracy: 0.9060\n",
            "Epoch 921/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 1.0576 - val_accuracy: 0.9044\n",
            "Epoch 922/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 1.0355 - val_accuracy: 0.9014\n",
            "Epoch 923/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.0093 - val_accuracy: 0.9032\n",
            "Epoch 924/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 1.0485 - val_accuracy: 0.9058\n",
            "Epoch 925/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.0002 - val_accuracy: 0.9038\n",
            "Epoch 926/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 1.0157 - val_accuracy: 0.9064\n",
            "Epoch 927/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 1.0300 - val_accuracy: 0.9050\n",
            "Epoch 928/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 1.0459 - val_accuracy: 0.9004\n",
            "Epoch 929/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.0632 - val_accuracy: 0.9026\n",
            "Epoch 930/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.9877 - val_accuracy: 0.9052\n",
            "Epoch 931/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.0084 - val_accuracy: 0.9020\n",
            "Epoch 932/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 1.0579 - val_accuracy: 0.9050\n",
            "Epoch 933/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 1.0083 - val_accuracy: 0.9018\n",
            "Epoch 934/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 1.0360 - val_accuracy: 0.9020\n",
            "Epoch 935/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 1.0191 - val_accuracy: 0.9028\n",
            "Epoch 936/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.9956 - val_accuracy: 0.9066\n",
            "Epoch 937/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 1.0076 - val_accuracy: 0.9062\n",
            "Epoch 938/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.0686 - val_accuracy: 0.9032\n",
            "Epoch 939/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.0361 - val_accuracy: 0.9086\n",
            "Epoch 940/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 1.0213 - val_accuracy: 0.9050\n",
            "Epoch 941/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 1.1014 - val_accuracy: 0.9082\n",
            "Epoch 942/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 1.0284 - val_accuracy: 0.9034\n",
            "Epoch 943/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 1.0540 - val_accuracy: 0.9072\n",
            "Epoch 944/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.0802 - val_accuracy: 0.9060\n",
            "Epoch 945/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 1.0006 - val_accuracy: 0.9054\n",
            "Epoch 946/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 1.0411 - val_accuracy: 0.9036\n",
            "Epoch 947/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.0470 - val_accuracy: 0.9008\n",
            "Epoch 948/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.0073 - val_accuracy: 0.9076\n",
            "Epoch 949/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 1.0360 - val_accuracy: 0.9070\n",
            "Epoch 950/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 1.0327 - val_accuracy: 0.9070\n",
            "Epoch 951/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 1.0573 - val_accuracy: 0.9038\n",
            "Epoch 952/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 1.0622 - val_accuracy: 0.9032\n",
            "Epoch 953/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9952 - val_loss: 1.0209 - val_accuracy: 0.9060\n",
            "Epoch 954/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.9964 - val_accuracy: 0.9048\n",
            "Epoch 955/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 1.0419 - val_accuracy: 0.9040\n",
            "Epoch 956/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.9675 - val_accuracy: 0.9078\n",
            "Epoch 957/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.0120 - val_accuracy: 0.9088\n",
            "Epoch 958/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.0207 - val_accuracy: 0.9032\n",
            "Epoch 959/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.0405 - val_accuracy: 0.9084\n",
            "Epoch 960/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 1.0229 - val_accuracy: 0.9042\n",
            "Epoch 961/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 1.0212 - val_accuracy: 0.9054\n",
            "Epoch 962/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 1.0462 - val_accuracy: 0.9080\n",
            "Epoch 963/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 1.0068 - val_accuracy: 0.9072\n",
            "Epoch 964/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 1.0125 - val_accuracy: 0.9044\n",
            "Epoch 965/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 1.0208 - val_accuracy: 0.9048\n",
            "Epoch 966/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 1.0600 - val_accuracy: 0.9064\n",
            "Epoch 967/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 1.0631 - val_accuracy: 0.9048\n",
            "Epoch 968/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.0692 - val_accuracy: 0.9048\n",
            "Epoch 969/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 1.0510 - val_accuracy: 0.9036\n",
            "Epoch 970/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.9971 - val_accuracy: 0.9048\n",
            "Epoch 971/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 1.0163 - val_accuracy: 0.9012\n",
            "Epoch 972/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 1.0400 - val_accuracy: 0.9046\n",
            "Epoch 973/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 1.0411 - val_accuracy: 0.9050\n",
            "Epoch 974/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 1.0252 - val_accuracy: 0.9056\n",
            "Epoch 975/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 1.0685 - val_accuracy: 0.9046\n",
            "Epoch 976/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 1.0625 - val_accuracy: 0.9036\n",
            "Epoch 977/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.0989 - val_accuracy: 0.9046\n",
            "Epoch 978/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 1.0535 - val_accuracy: 0.9056\n",
            "Epoch 979/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 1.0726 - val_accuracy: 0.9062\n",
            "Epoch 980/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 1.0312 - val_accuracy: 0.9028\n",
            "Epoch 981/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 1.0422 - val_accuracy: 0.9062\n",
            "Epoch 982/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.9918 - val_accuracy: 0.9070\n",
            "Epoch 983/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.0362 - val_accuracy: 0.9094\n",
            "Epoch 984/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 1.0552 - val_accuracy: 0.9056\n",
            "Epoch 985/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.9932 - val_accuracy: 0.9036\n",
            "Epoch 986/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 1.0496 - val_accuracy: 0.9046\n",
            "Epoch 987/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.0427 - val_accuracy: 0.9072\n",
            "Epoch 988/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.0072 - val_accuracy: 0.9056\n",
            "Epoch 989/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.0032 - val_accuracy: 0.9040\n",
            "Epoch 990/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 1.0049 - val_accuracy: 0.9018\n",
            "Epoch 991/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 1.0098 - val_accuracy: 0.9070\n",
            "Epoch 992/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 1.0298 - val_accuracy: 0.9036\n",
            "Epoch 993/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.9695 - val_accuracy: 0.9098\n",
            "Epoch 994/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 1.0335 - val_accuracy: 0.9046\n",
            "Epoch 995/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 1.0314 - val_accuracy: 0.9024\n",
            "Epoch 996/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 1.0373 - val_accuracy: 0.9034\n",
            "Epoch 997/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.0637 - val_accuracy: 0.9066\n",
            "Epoch 998/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.0580 - val_accuracy: 0.9072\n",
            "Epoch 999/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.0462 - val_accuracy: 0.9060\n",
            "Epoch 1000/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.0594 - val_accuracy: 0.9032\n",
            "Epoch 1001/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 1.0897 - val_accuracy: 0.9032\n",
            "Epoch 1002/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 1.0216 - val_accuracy: 0.9072\n",
            "Epoch 1003/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.0684 - val_accuracy: 0.9046\n",
            "Epoch 1004/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 1.0848 - val_accuracy: 0.9050\n",
            "Epoch 1005/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 1.0389 - val_accuracy: 0.9076\n",
            "Epoch 1006/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.0690 - val_accuracy: 0.9054\n",
            "Epoch 1007/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.0171 - val_accuracy: 0.9080\n",
            "Epoch 1008/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 1.0800 - val_accuracy: 0.9022\n",
            "Epoch 1009/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.0192 - val_accuracy: 0.9048\n",
            "Epoch 1010/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 1.0631 - val_accuracy: 0.9070\n",
            "Epoch 1011/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 1.0793 - val_accuracy: 0.9024\n",
            "Epoch 1012/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 1.0822 - val_accuracy: 0.9062\n",
            "Epoch 1013/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 1.0727 - val_accuracy: 0.9024\n",
            "Epoch 1014/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 1.0802 - val_accuracy: 0.9076\n",
            "Epoch 1015/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.0077 - val_accuracy: 0.9016\n",
            "Epoch 1016/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 1.0295 - val_accuracy: 0.9066\n",
            "Epoch 1017/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 1.0479 - val_accuracy: 0.9026\n",
            "Epoch 1018/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 1.0156 - val_accuracy: 0.9058\n",
            "Epoch 1019/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.9944 - val_accuracy: 0.9020\n",
            "Epoch 1020/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 1.0355 - val_accuracy: 0.9038\n",
            "Epoch 1021/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 1.0141 - val_accuracy: 0.9040\n",
            "Epoch 1022/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 1.0040 - val_accuracy: 0.9064\n",
            "Epoch 1023/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 1.0278 - val_accuracy: 0.9046\n",
            "Epoch 1024/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.1089 - val_accuracy: 0.9094\n",
            "Epoch 1025/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.9901 - val_accuracy: 0.9088\n",
            "Epoch 1026/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 1.0938 - val_accuracy: 0.9074\n",
            "Epoch 1027/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 1.0208 - val_accuracy: 0.9072\n",
            "Epoch 1028/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 1.0723 - val_accuracy: 0.9064\n",
            "Epoch 1029/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.0700 - val_accuracy: 0.9066\n",
            "Epoch 1030/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 1.0525 - val_accuracy: 0.9048\n",
            "Epoch 1031/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 1.0368 - val_accuracy: 0.9058\n",
            "Epoch 1032/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 1.0555 - val_accuracy: 0.9090\n",
            "Epoch 1033/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 1.0617 - val_accuracy: 0.9072\n",
            "Epoch 1034/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 1.1192 - val_accuracy: 0.9038\n",
            "Epoch 1035/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.0666 - val_accuracy: 0.9054\n",
            "Epoch 1036/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 1.0091 - val_accuracy: 0.9064\n",
            "Epoch 1037/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.0681 - val_accuracy: 0.9058\n",
            "Epoch 1038/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 1.0127 - val_accuracy: 0.9034\n",
            "Epoch 1039/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 1.0173 - val_accuracy: 0.9030\n",
            "Epoch 1040/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 1.0633 - val_accuracy: 0.9066\n",
            "Epoch 1041/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.9716 - val_accuracy: 0.9090\n",
            "Epoch 1042/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 1.0461 - val_accuracy: 0.9030\n",
            "Epoch 1043/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.0578 - val_accuracy: 0.9074\n",
            "Epoch 1044/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 1.0778 - val_accuracy: 0.9058\n",
            "Epoch 1045/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 1.0234 - val_accuracy: 0.9070\n",
            "Epoch 1046/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 1.1028 - val_accuracy: 0.9036\n",
            "Epoch 1047/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.9970 - val_loss: 1.0672 - val_accuracy: 0.9030\n",
            "Epoch 1048/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 1.0362 - val_accuracy: 0.9066\n",
            "Epoch 1049/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 1.0312 - val_accuracy: 0.9060\n",
            "Epoch 1050/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.0548 - val_accuracy: 0.9046\n",
            "Epoch 1051/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 1.1052 - val_accuracy: 0.9022\n",
            "Epoch 1052/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 1.0898 - val_accuracy: 0.9004\n",
            "Epoch 1053/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.1011 - val_accuracy: 0.9040\n",
            "Epoch 1054/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 1.0553 - val_accuracy: 0.9050\n",
            "Epoch 1055/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.0324 - val_accuracy: 0.9020\n",
            "Epoch 1056/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 1.0573 - val_accuracy: 0.9050\n",
            "Epoch 1057/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.0445 - val_accuracy: 0.9032\n",
            "Epoch 1058/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 1.0657 - val_accuracy: 0.9030\n",
            "Epoch 1059/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.0569 - val_accuracy: 0.9032\n",
            "Epoch 1060/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.0714 - val_accuracy: 0.9074\n",
            "Epoch 1061/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 1.0475 - val_accuracy: 0.9042\n",
            "Epoch 1062/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.0537 - val_accuracy: 0.9052\n",
            "Epoch 1063/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 1.0502 - val_accuracy: 0.9038\n",
            "Epoch 1064/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 1.0242 - val_accuracy: 0.9040\n",
            "Epoch 1065/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 0.9967 - val_loss: 1.0576 - val_accuracy: 0.9042\n",
            "Epoch 1066/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 1.0632 - val_accuracy: 0.9048\n",
            "Epoch 1067/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 1.0260 - val_accuracy: 0.9030\n",
            "Epoch 1068/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 1.0335 - val_accuracy: 0.9056\n",
            "Epoch 1069/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.0547 - val_accuracy: 0.9026\n",
            "Epoch 1070/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.0358 - val_accuracy: 0.9100\n",
            "Epoch 1071/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 1.0832 - val_accuracy: 0.9062\n",
            "Epoch 1072/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 1.0713 - val_accuracy: 0.9034\n",
            "Epoch 1073/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 1.0460 - val_accuracy: 0.9042\n",
            "Epoch 1074/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.0999 - val_accuracy: 0.9038\n",
            "Epoch 1075/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 1.0889 - val_accuracy: 0.9026\n",
            "Epoch 1076/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 1.0179 - val_accuracy: 0.9060\n",
            "Epoch 1077/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 1.0512 - val_accuracy: 0.9078\n",
            "Epoch 1078/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 1.0061 - val_accuracy: 0.9042\n",
            "Epoch 1079/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 1.0299 - val_accuracy: 0.9022\n",
            "Epoch 1080/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.9510 - val_accuracy: 0.9068\n",
            "Epoch 1081/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.9892 - val_accuracy: 0.9064\n",
            "Epoch 1082/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 1.0289 - val_accuracy: 0.9058\n",
            "Epoch 1083/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 1.0462 - val_accuracy: 0.9048\n",
            "Epoch 1084/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.0151 - val_accuracy: 0.9088\n",
            "Epoch 1085/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.0120 - val_accuracy: 0.9096\n",
            "Epoch 1086/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 1.0521 - val_accuracy: 0.9094\n",
            "Epoch 1087/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 1.0350 - val_accuracy: 0.9052\n",
            "Epoch 1088/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.0388 - val_accuracy: 0.9042\n",
            "Epoch 1089/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 1.0126 - val_accuracy: 0.9064\n",
            "Epoch 1090/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 1.0499 - val_accuracy: 0.9066\n",
            "Epoch 1091/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 1.0740 - val_accuracy: 0.9064\n",
            "Epoch 1092/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 1.0630 - val_accuracy: 0.9076\n",
            "Epoch 1093/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 1.0880 - val_accuracy: 0.9058\n",
            "Epoch 1094/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.0282 - val_accuracy: 0.9048\n",
            "Epoch 1095/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.0055 - val_accuracy: 0.9052\n",
            "Epoch 1096/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 1.0658 - val_accuracy: 0.9022\n",
            "Epoch 1097/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 1.0970 - val_accuracy: 0.9032\n",
            "Epoch 1098/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 1.0332 - val_accuracy: 0.9082\n",
            "Epoch 1099/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.0361 - val_accuracy: 0.9068\n",
            "Epoch 1100/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 1.0530 - val_accuracy: 0.9062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K2aK8FwNkVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de50b7c3-fd2b-4164-95bd-2c85165ce11e"
      },
      "source": [
        "score = fmnist_model.evaluate(dataset_test, verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0931 - accuracy: 0.9023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CcfXGOkNApS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "1663e391-f91e-4e8b-e436-3cdf8e6018e8"
      },
      "source": [
        "# adding dropout after first hidden layer\n",
        "plot_train_loss()\n",
        "plot_train_accuracy()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErlXwQyNOfDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "021506e3-b23d-441f-aaac-ce990bac4fbc"
      },
      "source": [
        "fmnist_model = models.Sequential([\n",
        "    layers.Dense(units=512, input_dim=28 * 28, activation=tf.nn.relu),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(units=128, input_dim=512, activation=tf.nn.relu),\n",
        "    layers.Dense(units=10, input_dim=128,  activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=1e-5,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "fmnist_model.compile(optimizer = tf.optimizers.Adam(learning_rate=lr_schedule),\n",
        "                     loss = 'categorical_crossentropy', # as we have already used the one-hot encoding for the training labels\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "history = fmnist_model.fit(dataset_train, \n",
        "                           epochs=1100,\n",
        "                           steps_per_epoch= steps_per_epoch,\n",
        "                           validation_data = dataset_valid,\n",
        "                           callbacks = [tensorboard_callback])\n",
        "\n",
        "score = fmnist_model.evaluate(dataset_test, verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1100\n",
            " 2/50 [>.............................] - ETA: 1s - loss: 2.5218 - accuracy: 0.1004WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0617s). Check your callbacks.\n",
            "51/50 [==============================] - 0s 8ms/step - loss: 2.3519 - accuracy: 0.1367 - val_loss: 2.1583 - val_accuracy: 0.2552\n",
            "Epoch 2/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 2.0531 - accuracy: 0.2990 - val_loss: 1.8760 - val_accuracy: 0.4392\n",
            "Epoch 3/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 1.7968 - accuracy: 0.4710 - val_loss: 1.6197 - val_accuracy: 0.6282\n",
            "Epoch 4/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 1.5692 - accuracy: 0.5889 - val_loss: 1.3994 - val_accuracy: 0.6842\n",
            "Epoch 5/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 1.3765 - accuracy: 0.6452 - val_loss: 1.2245 - val_accuracy: 0.6994\n",
            "Epoch 6/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 1.2235 - accuracy: 0.6727 - val_loss: 1.0894 - val_accuracy: 0.7128\n",
            "Epoch 7/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 1.1068 - accuracy: 0.6892 - val_loss: 0.9889 - val_accuracy: 0.7228\n",
            "Epoch 8/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 1.0196 - accuracy: 0.7036 - val_loss: 0.9141 - val_accuracy: 0.7360\n",
            "Epoch 9/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.9495 - accuracy: 0.7165 - val_loss: 0.8570 - val_accuracy: 0.7452\n",
            "Epoch 10/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.8967 - accuracy: 0.7249 - val_loss: 0.8116 - val_accuracy: 0.7526\n",
            "Epoch 11/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.8522 - accuracy: 0.7364 - val_loss: 0.7742 - val_accuracy: 0.7614\n",
            "Epoch 12/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.8205 - accuracy: 0.7435 - val_loss: 0.7429 - val_accuracy: 0.7678\n",
            "Epoch 13/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.7875 - accuracy: 0.7512 - val_loss: 0.7172 - val_accuracy: 0.7748\n",
            "Epoch 14/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.7629 - accuracy: 0.7551 - val_loss: 0.6953 - val_accuracy: 0.7800\n",
            "Epoch 15/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.7388 - accuracy: 0.7627 - val_loss: 0.6766 - val_accuracy: 0.7848\n",
            "Epoch 16/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.7245 - accuracy: 0.7661 - val_loss: 0.6605 - val_accuracy: 0.7870\n",
            "Epoch 17/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.7077 - accuracy: 0.7708 - val_loss: 0.6447 - val_accuracy: 0.7898\n",
            "Epoch 18/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6918 - accuracy: 0.7760 - val_loss: 0.6296 - val_accuracy: 0.7972\n",
            "Epoch 19/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.7811 - val_loss: 0.6172 - val_accuracy: 0.7990\n",
            "Epoch 20/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6631 - accuracy: 0.7844 - val_loss: 0.6066 - val_accuracy: 0.8018\n",
            "Epoch 21/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.7895 - val_loss: 0.5954 - val_accuracy: 0.8062\n",
            "Epoch 22/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6406 - accuracy: 0.7913 - val_loss: 0.5855 - val_accuracy: 0.8082\n",
            "Epoch 23/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.7947 - val_loss: 0.5749 - val_accuracy: 0.8116\n",
            "Epoch 24/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6197 - accuracy: 0.7980 - val_loss: 0.5654 - val_accuracy: 0.8156\n",
            "Epoch 25/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6117 - accuracy: 0.7993 - val_loss: 0.5592 - val_accuracy: 0.8182\n",
            "Epoch 26/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.6022 - accuracy: 0.8011 - val_loss: 0.5523 - val_accuracy: 0.8188\n",
            "Epoch 27/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.8040 - val_loss: 0.5448 - val_accuracy: 0.8206\n",
            "Epoch 28/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.8049 - val_loss: 0.5364 - val_accuracy: 0.8240\n",
            "Epoch 29/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.8065 - val_loss: 0.5307 - val_accuracy: 0.8262\n",
            "Epoch 30/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.8117 - val_loss: 0.5246 - val_accuracy: 0.8280\n",
            "Epoch 31/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.8119 - val_loss: 0.5206 - val_accuracy: 0.8294\n",
            "Epoch 32/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.8132 - val_loss: 0.5155 - val_accuracy: 0.8310\n",
            "Epoch 33/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.8150 - val_loss: 0.5094 - val_accuracy: 0.8322\n",
            "Epoch 34/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5533 - accuracy: 0.8158 - val_loss: 0.5038 - val_accuracy: 0.8352\n",
            "Epoch 35/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5419 - accuracy: 0.8194 - val_loss: 0.5002 - val_accuracy: 0.8344\n",
            "Epoch 36/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.8190 - val_loss: 0.4963 - val_accuracy: 0.8360\n",
            "Epoch 37/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.8218 - val_loss: 0.4923 - val_accuracy: 0.8382\n",
            "Epoch 38/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.8211 - val_loss: 0.4885 - val_accuracy: 0.8388\n",
            "Epoch 39/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.8237 - val_loss: 0.4834 - val_accuracy: 0.8422\n",
            "Epoch 40/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.8246 - val_loss: 0.4798 - val_accuracy: 0.8440\n",
            "Epoch 41/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5187 - accuracy: 0.8255 - val_loss: 0.4784 - val_accuracy: 0.8424\n",
            "Epoch 42/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.8261 - val_loss: 0.4737 - val_accuracy: 0.8440\n",
            "Epoch 43/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.8270 - val_loss: 0.4712 - val_accuracy: 0.8462\n",
            "Epoch 44/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5066 - accuracy: 0.8303 - val_loss: 0.4678 - val_accuracy: 0.8472\n",
            "Epoch 45/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.8292 - val_loss: 0.4639 - val_accuracy: 0.8474\n",
            "Epoch 46/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.5010 - accuracy: 0.8309 - val_loss: 0.4624 - val_accuracy: 0.8476\n",
            "Epoch 47/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4980 - accuracy: 0.8311 - val_loss: 0.4593 - val_accuracy: 0.8488\n",
            "Epoch 48/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.8329 - val_loss: 0.4569 - val_accuracy: 0.8492\n",
            "Epoch 49/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.8328 - val_loss: 0.4535 - val_accuracy: 0.8494\n",
            "Epoch 50/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4898 - accuracy: 0.8335 - val_loss: 0.4509 - val_accuracy: 0.8496\n",
            "Epoch 51/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.8348 - val_loss: 0.4491 - val_accuracy: 0.8504\n",
            "Epoch 52/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.8376 - val_loss: 0.4477 - val_accuracy: 0.8506\n",
            "Epoch 53/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.8352 - val_loss: 0.4457 - val_accuracy: 0.8512\n",
            "Epoch 54/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.8366 - val_loss: 0.4423 - val_accuracy: 0.8534\n",
            "Epoch 55/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.8369 - val_loss: 0.4398 - val_accuracy: 0.8536\n",
            "Epoch 56/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4743 - accuracy: 0.8388 - val_loss: 0.4379 - val_accuracy: 0.8534\n",
            "Epoch 57/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.8408 - val_loss: 0.4369 - val_accuracy: 0.8548\n",
            "Epoch 58/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.8417 - val_loss: 0.4344 - val_accuracy: 0.8544\n",
            "Epoch 59/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.8410 - val_loss: 0.4323 - val_accuracy: 0.8560\n",
            "Epoch 60/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.8425 - val_loss: 0.4302 - val_accuracy: 0.8570\n",
            "Epoch 61/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.8421 - val_loss: 0.4281 - val_accuracy: 0.8590\n",
            "Epoch 62/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.8441 - val_loss: 0.4278 - val_accuracy: 0.8580\n",
            "Epoch 63/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.8424 - val_loss: 0.4262 - val_accuracy: 0.8580\n",
            "Epoch 64/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8440 - val_loss: 0.4244 - val_accuracy: 0.8588\n",
            "Epoch 65/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.8451 - val_loss: 0.4218 - val_accuracy: 0.8604\n",
            "Epoch 66/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.8447 - val_loss: 0.4200 - val_accuracy: 0.8614\n",
            "Epoch 67/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.8460 - val_loss: 0.4192 - val_accuracy: 0.8620\n",
            "Epoch 68/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.8488 - val_loss: 0.4179 - val_accuracy: 0.8626\n",
            "Epoch 69/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.8473 - val_loss: 0.4165 - val_accuracy: 0.8618\n",
            "Epoch 70/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8470 - val_loss: 0.4143 - val_accuracy: 0.8624\n",
            "Epoch 71/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.8473 - val_loss: 0.4132 - val_accuracy: 0.8638\n",
            "Epoch 72/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.8491 - val_loss: 0.4120 - val_accuracy: 0.8628\n",
            "Epoch 73/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.8506 - val_loss: 0.4112 - val_accuracy: 0.8642\n",
            "Epoch 74/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8512 - val_loss: 0.4110 - val_accuracy: 0.8638\n",
            "Epoch 75/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8491 - val_loss: 0.4082 - val_accuracy: 0.8656\n",
            "Epoch 76/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8501 - val_loss: 0.4069 - val_accuracy: 0.8668\n",
            "Epoch 77/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8531 - val_loss: 0.4053 - val_accuracy: 0.8666\n",
            "Epoch 78/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.8510 - val_loss: 0.4052 - val_accuracy: 0.8668\n",
            "Epoch 79/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.8530 - val_loss: 0.4040 - val_accuracy: 0.8662\n",
            "Epoch 80/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8538 - val_loss: 0.4026 - val_accuracy: 0.8672\n",
            "Epoch 81/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8534 - val_loss: 0.4011 - val_accuracy: 0.8684\n",
            "Epoch 82/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8534 - val_loss: 0.3991 - val_accuracy: 0.8674\n",
            "Epoch 83/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8559 - val_loss: 0.3986 - val_accuracy: 0.8682\n",
            "Epoch 84/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8547 - val_loss: 0.3984 - val_accuracy: 0.8684\n",
            "Epoch 85/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.8551 - val_loss: 0.3966 - val_accuracy: 0.8694\n",
            "Epoch 86/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.8563 - val_loss: 0.3953 - val_accuracy: 0.8688\n",
            "Epoch 87/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4162 - accuracy: 0.8563 - val_loss: 0.3938 - val_accuracy: 0.8672\n",
            "Epoch 88/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.8558 - val_loss: 0.3930 - val_accuracy: 0.8676\n",
            "Epoch 89/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.8557 - val_loss: 0.3929 - val_accuracy: 0.8684\n",
            "Epoch 90/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8578 - val_loss: 0.3922 - val_accuracy: 0.8702\n",
            "Epoch 91/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8586 - val_loss: 0.3906 - val_accuracy: 0.8708\n",
            "Epoch 92/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8576 - val_loss: 0.3890 - val_accuracy: 0.8698\n",
            "Epoch 93/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8579 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
            "Epoch 94/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8595 - val_loss: 0.3877 - val_accuracy: 0.8710\n",
            "Epoch 95/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8594 - val_loss: 0.3868 - val_accuracy: 0.8720\n",
            "Epoch 96/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8597 - val_loss: 0.3857 - val_accuracy: 0.8704\n",
            "Epoch 97/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8592 - val_loss: 0.3843 - val_accuracy: 0.8712\n",
            "Epoch 98/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8601 - val_loss: 0.3833 - val_accuracy: 0.8708\n",
            "Epoch 99/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.4022 - accuracy: 0.8609 - val_loss: 0.3828 - val_accuracy: 0.8714\n",
            "Epoch 100/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8621 - val_loss: 0.3838 - val_accuracy: 0.8728\n",
            "Epoch 101/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8602 - val_loss: 0.3811 - val_accuracy: 0.8718\n",
            "Epoch 102/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8631 - val_loss: 0.3809 - val_accuracy: 0.8720\n",
            "Epoch 103/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8621 - val_loss: 0.3790 - val_accuracy: 0.8704\n",
            "Epoch 104/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8634 - val_loss: 0.3786 - val_accuracy: 0.8716\n",
            "Epoch 105/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8633 - val_loss: 0.3785 - val_accuracy: 0.8720\n",
            "Epoch 106/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8637 - val_loss: 0.3783 - val_accuracy: 0.8720\n",
            "Epoch 107/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8630 - val_loss: 0.3774 - val_accuracy: 0.8724\n",
            "Epoch 108/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8655 - val_loss: 0.3754 - val_accuracy: 0.8718\n",
            "Epoch 109/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3892 - accuracy: 0.8655 - val_loss: 0.3747 - val_accuracy: 0.8716\n",
            "Epoch 110/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8651 - val_loss: 0.3746 - val_accuracy: 0.8728\n",
            "Epoch 111/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8649 - val_loss: 0.3754 - val_accuracy: 0.8740\n",
            "Epoch 112/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8649 - val_loss: 0.3732 - val_accuracy: 0.8732\n",
            "Epoch 113/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8662 - val_loss: 0.3723 - val_accuracy: 0.8730\n",
            "Epoch 114/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8656 - val_loss: 0.3708 - val_accuracy: 0.8722\n",
            "Epoch 115/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8660 - val_loss: 0.3707 - val_accuracy: 0.8732\n",
            "Epoch 116/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8670 - val_loss: 0.3711 - val_accuracy: 0.8732\n",
            "Epoch 117/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8661 - val_loss: 0.3699 - val_accuracy: 0.8738\n",
            "Epoch 118/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8672 - val_loss: 0.3683 - val_accuracy: 0.8730\n",
            "Epoch 119/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8674 - val_loss: 0.3675 - val_accuracy: 0.8728\n",
            "Epoch 120/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3799 - accuracy: 0.8681 - val_loss: 0.3675 - val_accuracy: 0.8730\n",
            "Epoch 121/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8687 - val_loss: 0.3673 - val_accuracy: 0.8736\n",
            "Epoch 122/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8685 - val_loss: 0.3669 - val_accuracy: 0.8742\n",
            "Epoch 123/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8686 - val_loss: 0.3659 - val_accuracy: 0.8746\n",
            "Epoch 124/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8688 - val_loss: 0.3645 - val_accuracy: 0.8740\n",
            "Epoch 125/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8698 - val_loss: 0.3641 - val_accuracy: 0.8734\n",
            "Epoch 126/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3742 - accuracy: 0.8691 - val_loss: 0.3636 - val_accuracy: 0.8736\n",
            "Epoch 127/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8692 - val_loss: 0.3635 - val_accuracy: 0.8738\n",
            "Epoch 128/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8699 - val_loss: 0.3633 - val_accuracy: 0.8740\n",
            "Epoch 129/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8696 - val_loss: 0.3623 - val_accuracy: 0.8736\n",
            "Epoch 130/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8712 - val_loss: 0.3614 - val_accuracy: 0.8732\n",
            "Epoch 131/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8706 - val_loss: 0.3604 - val_accuracy: 0.8748\n",
            "Epoch 132/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8711 - val_loss: 0.3606 - val_accuracy: 0.8740\n",
            "Epoch 133/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8712 - val_loss: 0.3602 - val_accuracy: 0.8748\n",
            "Epoch 134/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8708 - val_loss: 0.3593 - val_accuracy: 0.8744\n",
            "Epoch 135/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8708 - val_loss: 0.3583 - val_accuracy: 0.8734\n",
            "Epoch 136/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8718 - val_loss: 0.3578 - val_accuracy: 0.8746\n",
            "Epoch 137/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8717 - val_loss: 0.3580 - val_accuracy: 0.8752\n",
            "Epoch 138/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8731 - val_loss: 0.3577 - val_accuracy: 0.8750\n",
            "Epoch 139/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8731 - val_loss: 0.3566 - val_accuracy: 0.8746\n",
            "Epoch 140/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8725 - val_loss: 0.3557 - val_accuracy: 0.8738\n",
            "Epoch 141/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8731 - val_loss: 0.3553 - val_accuracy: 0.8742\n",
            "Epoch 142/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3606 - accuracy: 0.8740 - val_loss: 0.3553 - val_accuracy: 0.8754\n",
            "Epoch 143/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8745 - val_loss: 0.3551 - val_accuracy: 0.8756\n",
            "Epoch 144/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8740 - val_loss: 0.3541 - val_accuracy: 0.8748\n",
            "Epoch 145/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8745 - val_loss: 0.3531 - val_accuracy: 0.8754\n",
            "Epoch 146/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8739 - val_loss: 0.3524 - val_accuracy: 0.8740\n",
            "Epoch 147/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8756 - val_loss: 0.3523 - val_accuracy: 0.8746\n",
            "Epoch 148/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8751 - val_loss: 0.3522 - val_accuracy: 0.8754\n",
            "Epoch 149/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3562 - accuracy: 0.8755 - val_loss: 0.3519 - val_accuracy: 0.8760\n",
            "Epoch 150/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8751 - val_loss: 0.3511 - val_accuracy: 0.8764\n",
            "Epoch 151/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8759 - val_loss: 0.3501 - val_accuracy: 0.8758\n",
            "Epoch 152/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3561 - accuracy: 0.8759 - val_loss: 0.3496 - val_accuracy: 0.8758\n",
            "Epoch 153/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8760 - val_loss: 0.3498 - val_accuracy: 0.8766\n",
            "Epoch 154/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8764 - val_loss: 0.3497 - val_accuracy: 0.8766\n",
            "Epoch 155/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8762 - val_loss: 0.3493 - val_accuracy: 0.8768\n",
            "Epoch 156/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3533 - accuracy: 0.8762 - val_loss: 0.3479 - val_accuracy: 0.8762\n",
            "Epoch 157/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3522 - accuracy: 0.8778 - val_loss: 0.3472 - val_accuracy: 0.8760\n",
            "Epoch 158/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3525 - accuracy: 0.8761 - val_loss: 0.3472 - val_accuracy: 0.8770\n",
            "Epoch 159/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8780 - val_loss: 0.3468 - val_accuracy: 0.8764\n",
            "Epoch 160/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3509 - accuracy: 0.8771 - val_loss: 0.3469 - val_accuracy: 0.8764\n",
            "Epoch 161/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8778 - val_loss: 0.3460 - val_accuracy: 0.8766\n",
            "Epoch 162/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.8783 - val_loss: 0.3449 - val_accuracy: 0.8768\n",
            "Epoch 163/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3482 - accuracy: 0.8772 - val_loss: 0.3451 - val_accuracy: 0.8778\n",
            "Epoch 164/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.3474 - accuracy: 0.8775 - val_loss: 0.3453 - val_accuracy: 0.8770\n",
            "Epoch 165/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8788 - val_loss: 0.3451 - val_accuracy: 0.8772\n",
            "Epoch 166/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8786 - val_loss: 0.3444 - val_accuracy: 0.8778\n",
            "Epoch 167/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8785 - val_loss: 0.3430 - val_accuracy: 0.8766\n",
            "Epoch 168/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8792 - val_loss: 0.3423 - val_accuracy: 0.8766\n",
            "Epoch 169/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8798 - val_loss: 0.3432 - val_accuracy: 0.8790\n",
            "Epoch 170/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8796 - val_loss: 0.3425 - val_accuracy: 0.8772\n",
            "Epoch 171/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8815 - val_loss: 0.3417 - val_accuracy: 0.8768\n",
            "Epoch 172/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8800 - val_loss: 0.3413 - val_accuracy: 0.8778\n",
            "Epoch 173/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8803 - val_loss: 0.3405 - val_accuracy: 0.8778\n",
            "Epoch 174/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8801 - val_loss: 0.3408 - val_accuracy: 0.8782\n",
            "Epoch 175/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8805 - val_loss: 0.3406 - val_accuracy: 0.8784\n",
            "Epoch 176/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8799 - val_loss: 0.3402 - val_accuracy: 0.8786\n",
            "Epoch 177/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8797 - val_loss: 0.3394 - val_accuracy: 0.8776\n",
            "Epoch 178/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8820 - val_loss: 0.3386 - val_accuracy: 0.8788\n",
            "Epoch 179/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8808 - val_loss: 0.3384 - val_accuracy: 0.8786\n",
            "Epoch 180/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8808 - val_loss: 0.3384 - val_accuracy: 0.8794\n",
            "Epoch 181/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8814 - val_loss: 0.3384 - val_accuracy: 0.8788\n",
            "Epoch 182/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8821 - val_loss: 0.3377 - val_accuracy: 0.8794\n",
            "Epoch 183/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8806 - val_loss: 0.3367 - val_accuracy: 0.8794\n",
            "Epoch 184/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8820 - val_loss: 0.3364 - val_accuracy: 0.8792\n",
            "Epoch 185/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8813 - val_loss: 0.3369 - val_accuracy: 0.8810\n",
            "Epoch 186/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8828 - val_loss: 0.3368 - val_accuracy: 0.8800\n",
            "Epoch 187/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8821 - val_loss: 0.3359 - val_accuracy: 0.8790\n",
            "Epoch 188/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8821 - val_loss: 0.3359 - val_accuracy: 0.8796\n",
            "Epoch 189/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8836 - val_loss: 0.3350 - val_accuracy: 0.8800\n",
            "Epoch 190/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8848 - val_loss: 0.3347 - val_accuracy: 0.8806\n",
            "Epoch 191/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8820 - val_loss: 0.3347 - val_accuracy: 0.8810\n",
            "Epoch 192/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8826 - val_loss: 0.3345 - val_accuracy: 0.8812\n",
            "Epoch 193/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8839 - val_loss: 0.3342 - val_accuracy: 0.8818\n",
            "Epoch 194/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8831 - val_loss: 0.3332 - val_accuracy: 0.8802\n",
            "Epoch 195/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8826 - val_loss: 0.3330 - val_accuracy: 0.8816\n",
            "Epoch 196/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8852 - val_loss: 0.3337 - val_accuracy: 0.8822\n",
            "Epoch 197/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8850 - val_loss: 0.3333 - val_accuracy: 0.8818\n",
            "Epoch 198/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8835 - val_loss: 0.3322 - val_accuracy: 0.8818\n",
            "Epoch 199/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8831 - val_loss: 0.3316 - val_accuracy: 0.8826\n",
            "Epoch 200/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3253 - accuracy: 0.8861 - val_loss: 0.3314 - val_accuracy: 0.8820\n",
            "Epoch 201/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8839 - val_loss: 0.3312 - val_accuracy: 0.8824\n",
            "Epoch 202/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8861 - val_loss: 0.3314 - val_accuracy: 0.8818\n",
            "Epoch 203/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8850 - val_loss: 0.3308 - val_accuracy: 0.8828\n",
            "Epoch 204/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3238 - accuracy: 0.8848 - val_loss: 0.3299 - val_accuracy: 0.8828\n",
            "Epoch 205/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3254 - accuracy: 0.8853 - val_loss: 0.3302 - val_accuracy: 0.8832\n",
            "Epoch 206/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8861 - val_loss: 0.3301 - val_accuracy: 0.8832\n",
            "Epoch 207/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8861 - val_loss: 0.3299 - val_accuracy: 0.8828\n",
            "Epoch 208/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3239 - accuracy: 0.8862 - val_loss: 0.3292 - val_accuracy: 0.8852\n",
            "Epoch 209/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3251 - accuracy: 0.8848 - val_loss: 0.3289 - val_accuracy: 0.8836\n",
            "Epoch 210/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8862 - val_loss: 0.3277 - val_accuracy: 0.8834\n",
            "Epoch 211/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3217 - accuracy: 0.8869 - val_loss: 0.3279 - val_accuracy: 0.8836\n",
            "Epoch 212/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3225 - accuracy: 0.8873 - val_loss: 0.3283 - val_accuracy: 0.8850\n",
            "Epoch 213/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8862 - val_loss: 0.3283 - val_accuracy: 0.8836\n",
            "Epoch 214/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8876 - val_loss: 0.3274 - val_accuracy: 0.8848\n",
            "Epoch 215/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3204 - accuracy: 0.8862 - val_loss: 0.3269 - val_accuracy: 0.8846\n",
            "Epoch 216/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3232 - accuracy: 0.8867 - val_loss: 0.3269 - val_accuracy: 0.8846\n",
            "Epoch 217/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3180 - accuracy: 0.8884 - val_loss: 0.3269 - val_accuracy: 0.8842\n",
            "Epoch 218/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3186 - accuracy: 0.8881 - val_loss: 0.3271 - val_accuracy: 0.8840\n",
            "Epoch 219/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8862 - val_loss: 0.3268 - val_accuracy: 0.8844\n",
            "Epoch 220/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8883 - val_loss: 0.3257 - val_accuracy: 0.8852\n",
            "Epoch 221/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.8878 - val_loss: 0.3252 - val_accuracy: 0.8834\n",
            "Epoch 222/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3181 - accuracy: 0.8876 - val_loss: 0.3254 - val_accuracy: 0.8856\n",
            "Epoch 223/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8888 - val_loss: 0.3251 - val_accuracy: 0.8858\n",
            "Epoch 224/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8880 - val_loss: 0.3254 - val_accuracy: 0.8848\n",
            "Epoch 225/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3166 - accuracy: 0.8881 - val_loss: 0.3244 - val_accuracy: 0.8864\n",
            "Epoch 226/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.8886 - val_loss: 0.3236 - val_accuracy: 0.8852\n",
            "Epoch 227/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3167 - accuracy: 0.8876 - val_loss: 0.3241 - val_accuracy: 0.8858\n",
            "Epoch 228/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8882 - val_loss: 0.3239 - val_accuracy: 0.8858\n",
            "Epoch 229/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.8888 - val_loss: 0.3243 - val_accuracy: 0.8846\n",
            "Epoch 230/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3155 - accuracy: 0.8892 - val_loss: 0.3235 - val_accuracy: 0.8862\n",
            "Epoch 231/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3150 - accuracy: 0.8891 - val_loss: 0.3228 - val_accuracy: 0.8862\n",
            "Epoch 232/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8902 - val_loss: 0.3223 - val_accuracy: 0.8850\n",
            "Epoch 233/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3139 - accuracy: 0.8904 - val_loss: 0.3226 - val_accuracy: 0.8864\n",
            "Epoch 234/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3127 - accuracy: 0.8902 - val_loss: 0.3231 - val_accuracy: 0.8854\n",
            "Epoch 235/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8894 - val_loss: 0.3226 - val_accuracy: 0.8860\n",
            "Epoch 236/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.8900 - val_loss: 0.3216 - val_accuracy: 0.8870\n",
            "Epoch 237/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8884 - val_loss: 0.3208 - val_accuracy: 0.8856\n",
            "Epoch 238/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8882 - val_loss: 0.3210 - val_accuracy: 0.8862\n",
            "Epoch 239/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3104 - accuracy: 0.8899 - val_loss: 0.3219 - val_accuracy: 0.8864\n",
            "Epoch 240/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8911 - val_loss: 0.3211 - val_accuracy: 0.8868\n",
            "Epoch 241/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3103 - accuracy: 0.8906 - val_loss: 0.3205 - val_accuracy: 0.8868\n",
            "Epoch 242/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.8905 - val_loss: 0.3198 - val_accuracy: 0.8852\n",
            "Epoch 243/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3090 - accuracy: 0.8912 - val_loss: 0.3204 - val_accuracy: 0.8866\n",
            "Epoch 244/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8913 - val_loss: 0.3195 - val_accuracy: 0.8872\n",
            "Epoch 245/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8900 - val_loss: 0.3205 - val_accuracy: 0.8870\n",
            "Epoch 246/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3092 - accuracy: 0.8913 - val_loss: 0.3199 - val_accuracy: 0.8880\n",
            "Epoch 247/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8908 - val_loss: 0.3190 - val_accuracy: 0.8882\n",
            "Epoch 248/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3059 - accuracy: 0.8926 - val_loss: 0.3189 - val_accuracy: 0.8876\n",
            "Epoch 249/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8915 - val_loss: 0.3189 - val_accuracy: 0.8870\n",
            "Epoch 250/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3071 - accuracy: 0.8906 - val_loss: 0.3185 - val_accuracy: 0.8874\n",
            "Epoch 251/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3076 - accuracy: 0.8919 - val_loss: 0.3193 - val_accuracy: 0.8872\n",
            "Epoch 252/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.8917 - val_loss: 0.3178 - val_accuracy: 0.8878\n",
            "Epoch 253/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3054 - accuracy: 0.8925 - val_loss: 0.3174 - val_accuracy: 0.8874\n",
            "Epoch 254/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3030 - accuracy: 0.8927 - val_loss: 0.3174 - val_accuracy: 0.8866\n",
            "Epoch 255/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.8919 - val_loss: 0.3176 - val_accuracy: 0.8892\n",
            "Epoch 256/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3063 - accuracy: 0.8919 - val_loss: 0.3176 - val_accuracy: 0.8876\n",
            "Epoch 257/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3039 - accuracy: 0.8925 - val_loss: 0.3170 - val_accuracy: 0.8892\n",
            "Epoch 258/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8931 - val_loss: 0.3163 - val_accuracy: 0.8888\n",
            "Epoch 259/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.8925 - val_loss: 0.3161 - val_accuracy: 0.8884\n",
            "Epoch 260/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3021 - accuracy: 0.8932 - val_loss: 0.3165 - val_accuracy: 0.8880\n",
            "Epoch 261/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.8938 - val_loss: 0.3164 - val_accuracy: 0.8888\n",
            "Epoch 262/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3040 - accuracy: 0.8912 - val_loss: 0.3159 - val_accuracy: 0.8888\n",
            "Epoch 263/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3006 - accuracy: 0.8941 - val_loss: 0.3151 - val_accuracy: 0.8886\n",
            "Epoch 264/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8933 - val_loss: 0.3154 - val_accuracy: 0.8898\n",
            "Epoch 265/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2999 - accuracy: 0.8943 - val_loss: 0.3154 - val_accuracy: 0.8878\n",
            "Epoch 266/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3017 - accuracy: 0.8936 - val_loss: 0.3152 - val_accuracy: 0.8892\n",
            "Epoch 267/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.8943 - val_loss: 0.3155 - val_accuracy: 0.8884\n",
            "Epoch 268/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8924 - val_loss: 0.3144 - val_accuracy: 0.8892\n",
            "Epoch 269/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8947 - val_loss: 0.3140 - val_accuracy: 0.8886\n",
            "Epoch 270/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.3001 - accuracy: 0.8934 - val_loss: 0.3140 - val_accuracy: 0.8894\n",
            "Epoch 271/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.8955 - val_loss: 0.3144 - val_accuracy: 0.8888\n",
            "Epoch 272/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2989 - accuracy: 0.8941 - val_loss: 0.3140 - val_accuracy: 0.8900\n",
            "Epoch 273/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2983 - accuracy: 0.8949 - val_loss: 0.3137 - val_accuracy: 0.8902\n",
            "Epoch 274/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2998 - accuracy: 0.8936 - val_loss: 0.3132 - val_accuracy: 0.8890\n",
            "Epoch 275/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8946 - val_loss: 0.3132 - val_accuracy: 0.8896\n",
            "Epoch 276/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8952 - val_loss: 0.3136 - val_accuracy: 0.8900\n",
            "Epoch 277/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8955 - val_loss: 0.3131 - val_accuracy: 0.8888\n",
            "Epoch 278/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2984 - accuracy: 0.8953 - val_loss: 0.3137 - val_accuracy: 0.8906\n",
            "Epoch 279/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2956 - accuracy: 0.8953 - val_loss: 0.3126 - val_accuracy: 0.8900\n",
            "Epoch 280/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2952 - accuracy: 0.8957 - val_loss: 0.3121 - val_accuracy: 0.8894\n",
            "Epoch 281/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2961 - accuracy: 0.8958 - val_loss: 0.3119 - val_accuracy: 0.8890\n",
            "Epoch 282/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.8959 - val_loss: 0.3126 - val_accuracy: 0.8894\n",
            "Epoch 283/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2971 - accuracy: 0.8944 - val_loss: 0.3123 - val_accuracy: 0.8898\n",
            "Epoch 284/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2929 - accuracy: 0.8958 - val_loss: 0.3112 - val_accuracy: 0.8894\n",
            "Epoch 285/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.8966 - val_loss: 0.3114 - val_accuracy: 0.8908\n",
            "Epoch 286/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.8945 - val_loss: 0.3112 - val_accuracy: 0.8894\n",
            "Epoch 287/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8959 - val_loss: 0.3115 - val_accuracy: 0.8908\n",
            "Epoch 288/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2954 - accuracy: 0.8953 - val_loss: 0.3108 - val_accuracy: 0.8912\n",
            "Epoch 289/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2916 - accuracy: 0.8958 - val_loss: 0.3108 - val_accuracy: 0.8914\n",
            "Epoch 290/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2936 - accuracy: 0.8957 - val_loss: 0.3101 - val_accuracy: 0.8906\n",
            "Epoch 291/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2898 - accuracy: 0.8966 - val_loss: 0.3100 - val_accuracy: 0.8906\n",
            "Epoch 292/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.8953 - val_loss: 0.3102 - val_accuracy: 0.8900\n",
            "Epoch 293/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.8975 - val_loss: 0.3103 - val_accuracy: 0.8900\n",
            "Epoch 294/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2927 - accuracy: 0.8958 - val_loss: 0.3105 - val_accuracy: 0.8890\n",
            "Epoch 295/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2912 - accuracy: 0.8960 - val_loss: 0.3096 - val_accuracy: 0.8906\n",
            "Epoch 296/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.8958 - val_loss: 0.3095 - val_accuracy: 0.8904\n",
            "Epoch 297/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8980 - val_loss: 0.3096 - val_accuracy: 0.8908\n",
            "Epoch 298/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.8960 - val_loss: 0.3099 - val_accuracy: 0.8908\n",
            "Epoch 299/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.8960 - val_loss: 0.3091 - val_accuracy: 0.8912\n",
            "Epoch 300/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2881 - accuracy: 0.8980 - val_loss: 0.3091 - val_accuracy: 0.8914\n",
            "Epoch 301/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2903 - accuracy: 0.8976 - val_loss: 0.3083 - val_accuracy: 0.8910\n",
            "Epoch 302/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2893 - accuracy: 0.8973 - val_loss: 0.3084 - val_accuracy: 0.8912\n",
            "Epoch 303/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2888 - accuracy: 0.8973 - val_loss: 0.3086 - val_accuracy: 0.8910\n",
            "Epoch 304/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.8968 - val_loss: 0.3087 - val_accuracy: 0.8900\n",
            "Epoch 305/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.8986 - val_loss: 0.3085 - val_accuracy: 0.8920\n",
            "Epoch 306/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8977 - val_loss: 0.3077 - val_accuracy: 0.8906\n",
            "Epoch 307/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.8978 - val_loss: 0.3075 - val_accuracy: 0.8910\n",
            "Epoch 308/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.8992 - val_loss: 0.3078 - val_accuracy: 0.8912\n",
            "Epoch 309/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2874 - accuracy: 0.8986 - val_loss: 0.3079 - val_accuracy: 0.8918\n",
            "Epoch 310/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2868 - accuracy: 0.8980 - val_loss: 0.3073 - val_accuracy: 0.8910\n",
            "Epoch 311/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2869 - accuracy: 0.8975 - val_loss: 0.3072 - val_accuracy: 0.8918\n",
            "Epoch 312/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.8993 - val_loss: 0.3064 - val_accuracy: 0.8910\n",
            "Epoch 313/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8976 - val_loss: 0.3073 - val_accuracy: 0.8916\n",
            "Epoch 314/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8990 - val_loss: 0.3071 - val_accuracy: 0.8910\n",
            "Epoch 315/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.8993 - val_loss: 0.3071 - val_accuracy: 0.8928\n",
            "Epoch 316/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2845 - accuracy: 0.8992 - val_loss: 0.3069 - val_accuracy: 0.8930\n",
            "Epoch 317/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2843 - accuracy: 0.8984 - val_loss: 0.3060 - val_accuracy: 0.8910\n",
            "Epoch 318/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.8985 - val_loss: 0.3060 - val_accuracy: 0.8910\n",
            "Epoch 319/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.8988 - val_loss: 0.3062 - val_accuracy: 0.8910\n",
            "Epoch 320/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.8991 - val_loss: 0.3063 - val_accuracy: 0.8922\n",
            "Epoch 321/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.8992 - val_loss: 0.3053 - val_accuracy: 0.8920\n",
            "Epoch 322/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2839 - accuracy: 0.8991 - val_loss: 0.3054 - val_accuracy: 0.8920\n",
            "Epoch 323/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2820 - accuracy: 0.9001 - val_loss: 0.3051 - val_accuracy: 0.8914\n",
            "Epoch 324/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.9007 - val_loss: 0.3051 - val_accuracy: 0.8912\n",
            "Epoch 325/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8992 - val_loss: 0.3052 - val_accuracy: 0.8918\n",
            "Epoch 326/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.8992 - val_loss: 0.3048 - val_accuracy: 0.8922\n",
            "Epoch 327/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.8994 - val_loss: 0.3048 - val_accuracy: 0.8924\n",
            "Epoch 328/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.9003 - val_loss: 0.3046 - val_accuracy: 0.8918\n",
            "Epoch 329/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2808 - accuracy: 0.9001 - val_loss: 0.3047 - val_accuracy: 0.8918\n",
            "Epoch 330/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2820 - accuracy: 0.9001 - val_loss: 0.3047 - val_accuracy: 0.8920\n",
            "Epoch 331/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2790 - accuracy: 0.9011 - val_loss: 0.3048 - val_accuracy: 0.8918\n",
            "Epoch 332/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2818 - accuracy: 0.8992 - val_loss: 0.3044 - val_accuracy: 0.8926\n",
            "Epoch 333/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.9005 - val_loss: 0.3037 - val_accuracy: 0.8922\n",
            "Epoch 334/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2810 - accuracy: 0.8996 - val_loss: 0.3037 - val_accuracy: 0.8914\n",
            "Epoch 335/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.9008 - val_loss: 0.3038 - val_accuracy: 0.8912\n",
            "Epoch 336/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.9009 - val_loss: 0.3037 - val_accuracy: 0.8920\n",
            "Epoch 337/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2787 - accuracy: 0.9016 - val_loss: 0.3038 - val_accuracy: 0.8922\n",
            "Epoch 338/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2776 - accuracy: 0.9010 - val_loss: 0.3031 - val_accuracy: 0.8918\n",
            "Epoch 339/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2793 - accuracy: 0.9008 - val_loss: 0.3029 - val_accuracy: 0.8928\n",
            "Epoch 340/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2789 - accuracy: 0.9004 - val_loss: 0.3034 - val_accuracy: 0.8920\n",
            "Epoch 341/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2771 - accuracy: 0.9023 - val_loss: 0.3038 - val_accuracy: 0.8928\n",
            "Epoch 342/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.9008 - val_loss: 0.3031 - val_accuracy: 0.8926\n",
            "Epoch 343/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.9013 - val_loss: 0.3030 - val_accuracy: 0.8924\n",
            "Epoch 344/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2769 - accuracy: 0.9015 - val_loss: 0.3019 - val_accuracy: 0.8922\n",
            "Epoch 345/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.9009 - val_loss: 0.3025 - val_accuracy: 0.8926\n",
            "Epoch 346/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.9021 - val_loss: 0.3025 - val_accuracy: 0.8916\n",
            "Epoch 347/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.9020 - val_loss: 0.3026 - val_accuracy: 0.8934\n",
            "Epoch 348/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2755 - accuracy: 0.9016 - val_loss: 0.3021 - val_accuracy: 0.8922\n",
            "Epoch 349/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.9014 - val_loss: 0.3013 - val_accuracy: 0.8918\n",
            "Epoch 350/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2748 - accuracy: 0.9026 - val_loss: 0.3014 - val_accuracy: 0.8920\n",
            "Epoch 351/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2740 - accuracy: 0.9025 - val_loss: 0.3019 - val_accuracy: 0.8922\n",
            "Epoch 352/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2745 - accuracy: 0.9018 - val_loss: 0.3018 - val_accuracy: 0.8932\n",
            "Epoch 353/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2742 - accuracy: 0.9024 - val_loss: 0.3012 - val_accuracy: 0.8928\n",
            "Epoch 354/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2742 - accuracy: 0.9020 - val_loss: 0.3009 - val_accuracy: 0.8934\n",
            "Epoch 355/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2739 - accuracy: 0.9017 - val_loss: 0.3008 - val_accuracy: 0.8914\n",
            "Epoch 356/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2748 - accuracy: 0.9016 - val_loss: 0.3010 - val_accuracy: 0.8926\n",
            "Epoch 357/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2737 - accuracy: 0.9027 - val_loss: 0.3012 - val_accuracy: 0.8926\n",
            "Epoch 358/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2752 - accuracy: 0.9034 - val_loss: 0.3009 - val_accuracy: 0.8936\n",
            "Epoch 359/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9030 - val_loss: 0.3006 - val_accuracy: 0.8942\n",
            "Epoch 360/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.9031 - val_loss: 0.3004 - val_accuracy: 0.8926\n",
            "Epoch 361/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.9025 - val_loss: 0.3002 - val_accuracy: 0.8930\n",
            "Epoch 362/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2734 - accuracy: 0.9030 - val_loss: 0.3002 - val_accuracy: 0.8928\n",
            "Epoch 363/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 0.9023 - val_loss: 0.3004 - val_accuracy: 0.8928\n",
            "Epoch 364/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2730 - accuracy: 0.9031 - val_loss: 0.3004 - val_accuracy: 0.8946\n",
            "Epoch 365/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9031 - val_loss: 0.2996 - val_accuracy: 0.8928\n",
            "Epoch 366/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2715 - accuracy: 0.9039 - val_loss: 0.2999 - val_accuracy: 0.8930\n",
            "Epoch 367/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2716 - accuracy: 0.9038 - val_loss: 0.2999 - val_accuracy: 0.8930\n",
            "Epoch 368/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2703 - accuracy: 0.9032 - val_loss: 0.3000 - val_accuracy: 0.8944\n",
            "Epoch 369/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2707 - accuracy: 0.9040 - val_loss: 0.3000 - val_accuracy: 0.8940\n",
            "Epoch 370/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9027 - val_loss: 0.2995 - val_accuracy: 0.8934\n",
            "Epoch 371/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2693 - accuracy: 0.9043 - val_loss: 0.2989 - val_accuracy: 0.8922\n",
            "Epoch 372/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2703 - accuracy: 0.9043 - val_loss: 0.2993 - val_accuracy: 0.8926\n",
            "Epoch 373/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.9042 - val_loss: 0.2998 - val_accuracy: 0.8940\n",
            "Epoch 374/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.9040 - val_loss: 0.2991 - val_accuracy: 0.8936\n",
            "Epoch 375/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.9038 - val_loss: 0.2987 - val_accuracy: 0.8938\n",
            "Epoch 376/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2691 - accuracy: 0.9036 - val_loss: 0.2985 - val_accuracy: 0.8936\n",
            "Epoch 377/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.9051 - val_loss: 0.2989 - val_accuracy: 0.8938\n",
            "Epoch 378/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.9035 - val_loss: 0.2989 - val_accuracy: 0.8930\n",
            "Epoch 379/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2678 - accuracy: 0.9045 - val_loss: 0.2990 - val_accuracy: 0.8940\n",
            "Epoch 380/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.9062 - val_loss: 0.2984 - val_accuracy: 0.8940\n",
            "Epoch 381/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2697 - accuracy: 0.9036 - val_loss: 0.2976 - val_accuracy: 0.8930\n",
            "Epoch 382/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2657 - accuracy: 0.9049 - val_loss: 0.2978 - val_accuracy: 0.8928\n",
            "Epoch 383/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9046 - val_loss: 0.2982 - val_accuracy: 0.8938\n",
            "Epoch 384/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2683 - accuracy: 0.9038 - val_loss: 0.2983 - val_accuracy: 0.8948\n",
            "Epoch 385/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.9057 - val_loss: 0.2987 - val_accuracy: 0.8944\n",
            "Epoch 386/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.9047 - val_loss: 0.2975 - val_accuracy: 0.8940\n",
            "Epoch 387/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2639 - accuracy: 0.9068 - val_loss: 0.2972 - val_accuracy: 0.8932\n",
            "Epoch 388/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2666 - accuracy: 0.9051 - val_loss: 0.2977 - val_accuracy: 0.8946\n",
            "Epoch 389/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2657 - accuracy: 0.9059 - val_loss: 0.2973 - val_accuracy: 0.8938\n",
            "Epoch 390/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.9053 - val_loss: 0.2978 - val_accuracy: 0.8942\n",
            "Epoch 391/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2650 - accuracy: 0.9062 - val_loss: 0.2973 - val_accuracy: 0.8942\n",
            "Epoch 392/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2658 - accuracy: 0.9051 - val_loss: 0.2965 - val_accuracy: 0.8946\n",
            "Epoch 393/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.9068 - val_loss: 0.2973 - val_accuracy: 0.8942\n",
            "Epoch 394/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2649 - accuracy: 0.9054 - val_loss: 0.2969 - val_accuracy: 0.8936\n",
            "Epoch 395/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2641 - accuracy: 0.9058 - val_loss: 0.2973 - val_accuracy: 0.8952\n",
            "Epoch 396/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2647 - accuracy: 0.9056 - val_loss: 0.2970 - val_accuracy: 0.8948\n",
            "Epoch 397/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2652 - accuracy: 0.9060 - val_loss: 0.2959 - val_accuracy: 0.8942\n",
            "Epoch 398/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.9064 - val_loss: 0.2958 - val_accuracy: 0.8930\n",
            "Epoch 399/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.9073 - val_loss: 0.2961 - val_accuracy: 0.8948\n",
            "Epoch 400/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2646 - accuracy: 0.9059 - val_loss: 0.2967 - val_accuracy: 0.8956\n",
            "Epoch 401/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2619 - accuracy: 0.9063 - val_loss: 0.2965 - val_accuracy: 0.8952\n",
            "Epoch 402/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2621 - accuracy: 0.9059 - val_loss: 0.2958 - val_accuracy: 0.8958\n",
            "Epoch 403/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.9065 - val_loss: 0.2955 - val_accuracy: 0.8954\n",
            "Epoch 404/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2636 - accuracy: 0.9058 - val_loss: 0.2955 - val_accuracy: 0.8946\n",
            "Epoch 405/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.9062 - val_loss: 0.2958 - val_accuracy: 0.8946\n",
            "Epoch 406/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9068 - val_loss: 0.2963 - val_accuracy: 0.8956\n",
            "Epoch 407/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2619 - accuracy: 0.9064 - val_loss: 0.2954 - val_accuracy: 0.8946\n",
            "Epoch 408/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9071 - val_loss: 0.2952 - val_accuracy: 0.8938\n",
            "Epoch 409/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9074 - val_loss: 0.2953 - val_accuracy: 0.8946\n",
            "Epoch 410/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2629 - accuracy: 0.9065 - val_loss: 0.2959 - val_accuracy: 0.8962\n",
            "Epoch 411/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2609 - accuracy: 0.9076 - val_loss: 0.2952 - val_accuracy: 0.8956\n",
            "Epoch 412/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.9078 - val_loss: 0.2954 - val_accuracy: 0.8956\n",
            "Epoch 413/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2624 - accuracy: 0.9067 - val_loss: 0.2950 - val_accuracy: 0.8956\n",
            "Epoch 414/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.9075 - val_loss: 0.2947 - val_accuracy: 0.8942\n",
            "Epoch 415/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2596 - accuracy: 0.9083 - val_loss: 0.2947 - val_accuracy: 0.8942\n",
            "Epoch 416/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2588 - accuracy: 0.9078 - val_loss: 0.2951 - val_accuracy: 0.8958\n",
            "Epoch 417/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2601 - accuracy: 0.9073 - val_loss: 0.2952 - val_accuracy: 0.8958\n",
            "Epoch 418/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2599 - accuracy: 0.9074 - val_loss: 0.2942 - val_accuracy: 0.8950\n",
            "Epoch 419/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2579 - accuracy: 0.9081 - val_loss: 0.2941 - val_accuracy: 0.8948\n",
            "Epoch 420/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2595 - accuracy: 0.9084 - val_loss: 0.2944 - val_accuracy: 0.8948\n",
            "Epoch 421/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.9076 - val_loss: 0.2945 - val_accuracy: 0.8950\n",
            "Epoch 422/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2596 - accuracy: 0.9070 - val_loss: 0.2945 - val_accuracy: 0.8962\n",
            "Epoch 423/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2581 - accuracy: 0.9085 - val_loss: 0.2942 - val_accuracy: 0.8964\n",
            "Epoch 424/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2582 - accuracy: 0.9083 - val_loss: 0.2936 - val_accuracy: 0.8948\n",
            "Epoch 425/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2572 - accuracy: 0.9087 - val_loss: 0.2937 - val_accuracy: 0.8948\n",
            "Epoch 426/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.9080 - val_loss: 0.2940 - val_accuracy: 0.8958\n",
            "Epoch 427/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2576 - accuracy: 0.9082 - val_loss: 0.2944 - val_accuracy: 0.8962\n",
            "Epoch 428/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2587 - accuracy: 0.9081 - val_loss: 0.2940 - val_accuracy: 0.8954\n",
            "Epoch 429/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.9079 - val_loss: 0.2931 - val_accuracy: 0.8954\n",
            "Epoch 430/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.9099 - val_loss: 0.2934 - val_accuracy: 0.8946\n",
            "Epoch 431/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.9096 - val_loss: 0.2937 - val_accuracy: 0.8958\n",
            "Epoch 432/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2565 - accuracy: 0.9088 - val_loss: 0.2939 - val_accuracy: 0.8968\n",
            "Epoch 433/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9087 - val_loss: 0.2935 - val_accuracy: 0.8962\n",
            "Epoch 434/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2555 - accuracy: 0.9094 - val_loss: 0.2927 - val_accuracy: 0.8964\n",
            "Epoch 435/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2563 - accuracy: 0.9099 - val_loss: 0.2926 - val_accuracy: 0.8952\n",
            "Epoch 436/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2543 - accuracy: 0.9101 - val_loss: 0.2930 - val_accuracy: 0.8950\n",
            "Epoch 437/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.9102 - val_loss: 0.2933 - val_accuracy: 0.8964\n",
            "Epoch 438/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.9084 - val_loss: 0.2932 - val_accuracy: 0.8962\n",
            "Epoch 439/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2556 - accuracy: 0.9093 - val_loss: 0.2925 - val_accuracy: 0.8964\n",
            "Epoch 440/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2536 - accuracy: 0.9093 - val_loss: 0.2921 - val_accuracy: 0.8962\n",
            "Epoch 441/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2545 - accuracy: 0.9093 - val_loss: 0.2923 - val_accuracy: 0.8948\n",
            "Epoch 442/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.9109 - val_loss: 0.2927 - val_accuracy: 0.8958\n",
            "Epoch 443/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2533 - accuracy: 0.9098 - val_loss: 0.2925 - val_accuracy: 0.8968\n",
            "Epoch 444/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2550 - accuracy: 0.9089 - val_loss: 0.2922 - val_accuracy: 0.8960\n",
            "Epoch 445/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2546 - accuracy: 0.9092 - val_loss: 0.2925 - val_accuracy: 0.8960\n",
            "Epoch 446/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.9095 - val_loss: 0.2922 - val_accuracy: 0.8952\n",
            "Epoch 447/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2523 - accuracy: 0.9113 - val_loss: 0.2928 - val_accuracy: 0.8960\n",
            "Epoch 448/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.9094 - val_loss: 0.2925 - val_accuracy: 0.8970\n",
            "Epoch 449/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2535 - accuracy: 0.9104 - val_loss: 0.2922 - val_accuracy: 0.8964\n",
            "Epoch 450/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2523 - accuracy: 0.9108 - val_loss: 0.2924 - val_accuracy: 0.8962\n",
            "Epoch 451/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9111 - val_loss: 0.2916 - val_accuracy: 0.8962\n",
            "Epoch 452/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.9096 - val_loss: 0.2915 - val_accuracy: 0.8956\n",
            "Epoch 453/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2525 - accuracy: 0.9104 - val_loss: 0.2920 - val_accuracy: 0.8966\n",
            "Epoch 454/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.9111 - val_loss: 0.2918 - val_accuracy: 0.8960\n",
            "Epoch 455/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9117 - val_loss: 0.2914 - val_accuracy: 0.8966\n",
            "Epoch 456/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.9095 - val_loss: 0.2911 - val_accuracy: 0.8956\n",
            "Epoch 457/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9119 - val_loss: 0.2913 - val_accuracy: 0.8956\n",
            "Epoch 458/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.9111 - val_loss: 0.2915 - val_accuracy: 0.8974\n",
            "Epoch 459/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2516 - accuracy: 0.9113 - val_loss: 0.2917 - val_accuracy: 0.8968\n",
            "Epoch 460/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2506 - accuracy: 0.9105 - val_loss: 0.2918 - val_accuracy: 0.8974\n",
            "Epoch 461/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2509 - accuracy: 0.9099 - val_loss: 0.2910 - val_accuracy: 0.8954\n",
            "Epoch 462/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.9113 - val_loss: 0.2914 - val_accuracy: 0.8958\n",
            "Epoch 463/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 0.9101 - val_loss: 0.2915 - val_accuracy: 0.8968\n",
            "Epoch 464/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2483 - accuracy: 0.9122 - val_loss: 0.2910 - val_accuracy: 0.8972\n",
            "Epoch 465/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2492 - accuracy: 0.9115 - val_loss: 0.2921 - val_accuracy: 0.8976\n",
            "Epoch 466/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2511 - accuracy: 0.9111 - val_loss: 0.2907 - val_accuracy: 0.8956\n",
            "Epoch 467/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2492 - accuracy: 0.9103 - val_loss: 0.2904 - val_accuracy: 0.8962\n",
            "Epoch 468/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2473 - accuracy: 0.9127 - val_loss: 0.2905 - val_accuracy: 0.8958\n",
            "Epoch 469/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.9110 - val_loss: 0.2909 - val_accuracy: 0.8970\n",
            "Epoch 470/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.9111 - val_loss: 0.2913 - val_accuracy: 0.8982\n",
            "Epoch 471/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.9109 - val_loss: 0.2911 - val_accuracy: 0.8978\n",
            "Epoch 472/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2484 - accuracy: 0.9113 - val_loss: 0.2903 - val_accuracy: 0.8966\n",
            "Epoch 473/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.9122 - val_loss: 0.2899 - val_accuracy: 0.8960\n",
            "Epoch 474/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2456 - accuracy: 0.9131 - val_loss: 0.2903 - val_accuracy: 0.8966\n",
            "Epoch 475/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2492 - accuracy: 0.9114 - val_loss: 0.2903 - val_accuracy: 0.8972\n",
            "Epoch 476/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2491 - accuracy: 0.9115 - val_loss: 0.2906 - val_accuracy: 0.8972\n",
            "Epoch 477/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2463 - accuracy: 0.9116 - val_loss: 0.2897 - val_accuracy: 0.8968\n",
            "Epoch 478/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.9131 - val_loss: 0.2898 - val_accuracy: 0.8972\n",
            "Epoch 479/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2475 - accuracy: 0.9113 - val_loss: 0.2897 - val_accuracy: 0.8964\n",
            "Epoch 480/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2474 - accuracy: 0.9117 - val_loss: 0.2898 - val_accuracy: 0.8972\n",
            "Epoch 481/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2467 - accuracy: 0.9118 - val_loss: 0.2901 - val_accuracy: 0.8980\n",
            "Epoch 482/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2463 - accuracy: 0.9121 - val_loss: 0.2898 - val_accuracy: 0.8974\n",
            "Epoch 483/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2474 - accuracy: 0.9112 - val_loss: 0.2892 - val_accuracy: 0.8966\n",
            "Epoch 484/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2461 - accuracy: 0.9127 - val_loss: 0.2896 - val_accuracy: 0.8966\n",
            "Epoch 485/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.9130 - val_loss: 0.2899 - val_accuracy: 0.8980\n",
            "Epoch 486/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2462 - accuracy: 0.9127 - val_loss: 0.2899 - val_accuracy: 0.8966\n",
            "Epoch 487/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.9124 - val_loss: 0.2895 - val_accuracy: 0.8968\n",
            "Epoch 488/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2454 - accuracy: 0.9119 - val_loss: 0.2886 - val_accuracy: 0.8966\n",
            "Epoch 489/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2431 - accuracy: 0.9129 - val_loss: 0.2890 - val_accuracy: 0.8968\n",
            "Epoch 490/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2434 - accuracy: 0.9134 - val_loss: 0.2889 - val_accuracy: 0.8964\n",
            "Epoch 491/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2470 - accuracy: 0.9131 - val_loss: 0.2894 - val_accuracy: 0.8984\n",
            "Epoch 492/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2441 - accuracy: 0.9134 - val_loss: 0.2894 - val_accuracy: 0.8978\n",
            "Epoch 493/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2433 - accuracy: 0.9143 - val_loss: 0.2886 - val_accuracy: 0.8968\n",
            "Epoch 494/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2439 - accuracy: 0.9129 - val_loss: 0.2884 - val_accuracy: 0.8974\n",
            "Epoch 495/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2445 - accuracy: 0.9131 - val_loss: 0.2889 - val_accuracy: 0.8972\n",
            "Epoch 496/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2436 - accuracy: 0.9136 - val_loss: 0.2892 - val_accuracy: 0.8972\n",
            "Epoch 497/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2442 - accuracy: 0.9135 - val_loss: 0.2888 - val_accuracy: 0.8980\n",
            "Epoch 498/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2450 - accuracy: 0.9131 - val_loss: 0.2890 - val_accuracy: 0.8980\n",
            "Epoch 499/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9138 - val_loss: 0.2881 - val_accuracy: 0.8976\n",
            "Epoch 500/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2428 - accuracy: 0.9140 - val_loss: 0.2885 - val_accuracy: 0.8966\n",
            "Epoch 501/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.9134 - val_loss: 0.2887 - val_accuracy: 0.8976\n",
            "Epoch 502/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2420 - accuracy: 0.9140 - val_loss: 0.2890 - val_accuracy: 0.8974\n",
            "Epoch 503/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2422 - accuracy: 0.9134 - val_loss: 0.2886 - val_accuracy: 0.8978\n",
            "Epoch 504/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2423 - accuracy: 0.9138 - val_loss: 0.2883 - val_accuracy: 0.8964\n",
            "Epoch 505/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2407 - accuracy: 0.9149 - val_loss: 0.2881 - val_accuracy: 0.8966\n",
            "Epoch 506/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2425 - accuracy: 0.9141 - val_loss: 0.2879 - val_accuracy: 0.8974\n",
            "Epoch 507/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2411 - accuracy: 0.9149 - val_loss: 0.2886 - val_accuracy: 0.8972\n",
            "Epoch 508/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9142 - val_loss: 0.2882 - val_accuracy: 0.8968\n",
            "Epoch 509/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2402 - accuracy: 0.9145 - val_loss: 0.2878 - val_accuracy: 0.8974\n",
            "Epoch 510/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2426 - accuracy: 0.9132 - val_loss: 0.2877 - val_accuracy: 0.8976\n",
            "Epoch 511/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2398 - accuracy: 0.9156 - val_loss: 0.2878 - val_accuracy: 0.8968\n",
            "Epoch 512/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2396 - accuracy: 0.9149 - val_loss: 0.2883 - val_accuracy: 0.8980\n",
            "Epoch 513/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9141 - val_loss: 0.2878 - val_accuracy: 0.8974\n",
            "Epoch 514/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2395 - accuracy: 0.9147 - val_loss: 0.2875 - val_accuracy: 0.8978\n",
            "Epoch 515/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2398 - accuracy: 0.9148 - val_loss: 0.2874 - val_accuracy: 0.8976\n",
            "Epoch 516/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.9136 - val_loss: 0.2872 - val_accuracy: 0.8978\n",
            "Epoch 517/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.9156 - val_loss: 0.2877 - val_accuracy: 0.8976\n",
            "Epoch 518/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2400 - accuracy: 0.9147 - val_loss: 0.2879 - val_accuracy: 0.8972\n",
            "Epoch 519/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2406 - accuracy: 0.9146 - val_loss: 0.2877 - val_accuracy: 0.8978\n",
            "Epoch 520/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2385 - accuracy: 0.9148 - val_loss: 0.2867 - val_accuracy: 0.8972\n",
            "Epoch 521/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.9152 - val_loss: 0.2867 - val_accuracy: 0.8976\n",
            "Epoch 522/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2372 - accuracy: 0.9155 - val_loss: 0.2873 - val_accuracy: 0.8976\n",
            "Epoch 523/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2400 - accuracy: 0.9153 - val_loss: 0.2875 - val_accuracy: 0.8984\n",
            "Epoch 524/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2379 - accuracy: 0.9157 - val_loss: 0.2875 - val_accuracy: 0.8978\n",
            "Epoch 525/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2361 - accuracy: 0.9159 - val_loss: 0.2865 - val_accuracy: 0.8980\n",
            "Epoch 526/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2393 - accuracy: 0.9154 - val_loss: 0.2864 - val_accuracy: 0.8976\n",
            "Epoch 527/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2380 - accuracy: 0.9165 - val_loss: 0.2870 - val_accuracy: 0.8974\n",
            "Epoch 528/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2388 - accuracy: 0.9157 - val_loss: 0.2873 - val_accuracy: 0.8984\n",
            "Epoch 529/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2366 - accuracy: 0.9166 - val_loss: 0.2871 - val_accuracy: 0.8968\n",
            "Epoch 530/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2386 - accuracy: 0.9145 - val_loss: 0.2868 - val_accuracy: 0.8974\n",
            "Epoch 531/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.9154 - val_loss: 0.2860 - val_accuracy: 0.8982\n",
            "Epoch 532/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2358 - accuracy: 0.9166 - val_loss: 0.2865 - val_accuracy: 0.8974\n",
            "Epoch 533/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9150 - val_loss: 0.2871 - val_accuracy: 0.8972\n",
            "Epoch 534/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2374 - accuracy: 0.9159 - val_loss: 0.2869 - val_accuracy: 0.8966\n",
            "Epoch 535/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9167 - val_loss: 0.2866 - val_accuracy: 0.8978\n",
            "Epoch 536/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2366 - accuracy: 0.9158 - val_loss: 0.2863 - val_accuracy: 0.8976\n",
            "Epoch 537/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2374 - accuracy: 0.9151 - val_loss: 0.2863 - val_accuracy: 0.8974\n",
            "Epoch 538/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2349 - accuracy: 0.9171 - val_loss: 0.2859 - val_accuracy: 0.8978\n",
            "Epoch 539/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2376 - accuracy: 0.9160 - val_loss: 0.2865 - val_accuracy: 0.8976\n",
            "Epoch 540/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2367 - accuracy: 0.9154 - val_loss: 0.2866 - val_accuracy: 0.8976\n",
            "Epoch 541/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2356 - accuracy: 0.9164 - val_loss: 0.2857 - val_accuracy: 0.8982\n",
            "Epoch 542/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2356 - accuracy: 0.9172 - val_loss: 0.2862 - val_accuracy: 0.8966\n",
            "Epoch 543/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2340 - accuracy: 0.9167 - val_loss: 0.2860 - val_accuracy: 0.8984\n",
            "Epoch 544/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2349 - accuracy: 0.9181 - val_loss: 0.2862 - val_accuracy: 0.8986\n",
            "Epoch 545/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2351 - accuracy: 0.9162 - val_loss: 0.2860 - val_accuracy: 0.8976\n",
            "Epoch 546/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2365 - accuracy: 0.9158 - val_loss: 0.2861 - val_accuracy: 0.8978\n",
            "Epoch 547/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2333 - accuracy: 0.9172 - val_loss: 0.2855 - val_accuracy: 0.8982\n",
            "Epoch 548/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2336 - accuracy: 0.9169 - val_loss: 0.2860 - val_accuracy: 0.8984\n",
            "Epoch 549/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9174 - val_loss: 0.2862 - val_accuracy: 0.8980\n",
            "Epoch 550/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2314 - accuracy: 0.9177 - val_loss: 0.2863 - val_accuracy: 0.8978\n",
            "Epoch 551/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2379 - accuracy: 0.9157 - val_loss: 0.2861 - val_accuracy: 0.8974\n",
            "Epoch 552/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2322 - accuracy: 0.9182 - val_loss: 0.2853 - val_accuracy: 0.8988\n",
            "Epoch 553/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2345 - accuracy: 0.9165 - val_loss: 0.2847 - val_accuracy: 0.8986\n",
            "Epoch 554/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2334 - accuracy: 0.9185 - val_loss: 0.2854 - val_accuracy: 0.8990\n",
            "Epoch 555/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2326 - accuracy: 0.9176 - val_loss: 0.2861 - val_accuracy: 0.8980\n",
            "Epoch 556/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2341 - accuracy: 0.9169 - val_loss: 0.2856 - val_accuracy: 0.8980\n",
            "Epoch 557/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2321 - accuracy: 0.9169 - val_loss: 0.2855 - val_accuracy: 0.8980\n",
            "Epoch 558/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2321 - accuracy: 0.9175 - val_loss: 0.2846 - val_accuracy: 0.8982\n",
            "Epoch 559/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2333 - accuracy: 0.9172 - val_loss: 0.2853 - val_accuracy: 0.8986\n",
            "Epoch 560/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2325 - accuracy: 0.9181 - val_loss: 0.2853 - val_accuracy: 0.8982\n",
            "Epoch 561/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2329 - accuracy: 0.9176 - val_loss: 0.2856 - val_accuracy: 0.8978\n",
            "Epoch 562/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2323 - accuracy: 0.9172 - val_loss: 0.2853 - val_accuracy: 0.8982\n",
            "Epoch 563/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2318 - accuracy: 0.9180 - val_loss: 0.2846 - val_accuracy: 0.8994\n",
            "Epoch 564/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2309 - accuracy: 0.9180 - val_loss: 0.2848 - val_accuracy: 0.8988\n",
            "Epoch 565/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2314 - accuracy: 0.9186 - val_loss: 0.2849 - val_accuracy: 0.8988\n",
            "Epoch 566/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2328 - accuracy: 0.9173 - val_loss: 0.2852 - val_accuracy: 0.8980\n",
            "Epoch 567/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2318 - accuracy: 0.9178 - val_loss: 0.2848 - val_accuracy: 0.8986\n",
            "Epoch 568/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2303 - accuracy: 0.9175 - val_loss: 0.2842 - val_accuracy: 0.8998\n",
            "Epoch 569/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2312 - accuracy: 0.9180 - val_loss: 0.2849 - val_accuracy: 0.8994\n",
            "Epoch 570/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2310 - accuracy: 0.9182 - val_loss: 0.2846 - val_accuracy: 0.8998\n",
            "Epoch 571/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2301 - accuracy: 0.9177 - val_loss: 0.2853 - val_accuracy: 0.8990\n",
            "Epoch 572/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2307 - accuracy: 0.9189 - val_loss: 0.2847 - val_accuracy: 0.8986\n",
            "Epoch 573/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2304 - accuracy: 0.9183 - val_loss: 0.2842 - val_accuracy: 0.8996\n",
            "Epoch 574/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2298 - accuracy: 0.9179 - val_loss: 0.2843 - val_accuracy: 0.8986\n",
            "Epoch 575/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9182 - val_loss: 0.2848 - val_accuracy: 0.8992\n",
            "Epoch 576/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2289 - accuracy: 0.9191 - val_loss: 0.2848 - val_accuracy: 0.8994\n",
            "Epoch 577/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2329 - accuracy: 0.9163 - val_loss: 0.2849 - val_accuracy: 0.8992\n",
            "Epoch 578/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2297 - accuracy: 0.9191 - val_loss: 0.2849 - val_accuracy: 0.8982\n",
            "Epoch 579/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2293 - accuracy: 0.9187 - val_loss: 0.2839 - val_accuracy: 0.8996\n",
            "Epoch 580/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2285 - accuracy: 0.9189 - val_loss: 0.2839 - val_accuracy: 0.8994\n",
            "Epoch 581/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2278 - accuracy: 0.9194 - val_loss: 0.2846 - val_accuracy: 0.8984\n",
            "Epoch 582/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2300 - accuracy: 0.9193 - val_loss: 0.2844 - val_accuracy: 0.8994\n",
            "Epoch 583/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2294 - accuracy: 0.9186 - val_loss: 0.2847 - val_accuracy: 0.8992\n",
            "Epoch 584/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9186 - val_loss: 0.2844 - val_accuracy: 0.8994\n",
            "Epoch 585/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2300 - accuracy: 0.9187 - val_loss: 0.2840 - val_accuracy: 0.8984\n",
            "Epoch 586/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2263 - accuracy: 0.9193 - val_loss: 0.2840 - val_accuracy: 0.8996\n",
            "Epoch 587/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2269 - accuracy: 0.9212 - val_loss: 0.2845 - val_accuracy: 0.8992\n",
            "Epoch 588/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2316 - accuracy: 0.9169 - val_loss: 0.2838 - val_accuracy: 0.8994\n",
            "Epoch 589/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2290 - accuracy: 0.9182 - val_loss: 0.2838 - val_accuracy: 0.8998\n",
            "Epoch 590/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9206 - val_loss: 0.2832 - val_accuracy: 0.8994\n",
            "Epoch 591/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2270 - accuracy: 0.9195 - val_loss: 0.2831 - val_accuracy: 0.8998\n",
            "Epoch 592/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2281 - accuracy: 0.9184 - val_loss: 0.2838 - val_accuracy: 0.9000\n",
            "Epoch 593/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2280 - accuracy: 0.9197 - val_loss: 0.2840 - val_accuracy: 0.8986\n",
            "Epoch 594/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9197 - val_loss: 0.2835 - val_accuracy: 0.8996\n",
            "Epoch 595/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2274 - accuracy: 0.9192 - val_loss: 0.2833 - val_accuracy: 0.9006\n",
            "Epoch 596/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2249 - accuracy: 0.9211 - val_loss: 0.2836 - val_accuracy: 0.8998\n",
            "Epoch 597/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2267 - accuracy: 0.9189 - val_loss: 0.2835 - val_accuracy: 0.9002\n",
            "Epoch 598/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2275 - accuracy: 0.9201 - val_loss: 0.2837 - val_accuracy: 0.8996\n",
            "Epoch 599/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2258 - accuracy: 0.9204 - val_loss: 0.2840 - val_accuracy: 0.8986\n",
            "Epoch 600/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2263 - accuracy: 0.9196 - val_loss: 0.2833 - val_accuracy: 0.9004\n",
            "Epoch 601/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.9197 - val_loss: 0.2829 - val_accuracy: 0.8996\n",
            "Epoch 602/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2251 - accuracy: 0.9211 - val_loss: 0.2835 - val_accuracy: 0.9006\n",
            "Epoch 603/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2265 - accuracy: 0.9194 - val_loss: 0.2830 - val_accuracy: 0.8998\n",
            "Epoch 604/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2276 - accuracy: 0.9187 - val_loss: 0.2837 - val_accuracy: 0.8996\n",
            "Epoch 605/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2247 - accuracy: 0.9205 - val_loss: 0.2830 - val_accuracy: 0.9004\n",
            "Epoch 606/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9199 - val_loss: 0.2834 - val_accuracy: 0.9002\n",
            "Epoch 607/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2244 - accuracy: 0.9207 - val_loss: 0.2831 - val_accuracy: 0.8994\n",
            "Epoch 608/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2243 - accuracy: 0.9202 - val_loss: 0.2833 - val_accuracy: 0.8996\n",
            "Epoch 609/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2270 - accuracy: 0.9198 - val_loss: 0.2828 - val_accuracy: 0.8996\n",
            "Epoch 610/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2241 - accuracy: 0.9205 - val_loss: 0.2831 - val_accuracy: 0.8994\n",
            "Epoch 611/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2265 - accuracy: 0.9195 - val_loss: 0.2825 - val_accuracy: 0.8994\n",
            "Epoch 612/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2227 - accuracy: 0.9213 - val_loss: 0.2825 - val_accuracy: 0.9002\n",
            "Epoch 613/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2242 - accuracy: 0.9203 - val_loss: 0.2831 - val_accuracy: 0.9008\n",
            "Epoch 614/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2250 - accuracy: 0.9207 - val_loss: 0.2823 - val_accuracy: 0.8990\n",
            "Epoch 615/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2231 - accuracy: 0.9214 - val_loss: 0.2826 - val_accuracy: 0.9002\n",
            "Epoch 616/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2224 - accuracy: 0.9212 - val_loss: 0.2828 - val_accuracy: 0.9010\n",
            "Epoch 617/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2234 - accuracy: 0.9208 - val_loss: 0.2829 - val_accuracy: 0.9002\n",
            "Epoch 618/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.9220 - val_loss: 0.2826 - val_accuracy: 0.9004\n",
            "Epoch 619/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9210 - val_loss: 0.2832 - val_accuracy: 0.9004\n",
            "Epoch 620/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2240 - accuracy: 0.9207 - val_loss: 0.2829 - val_accuracy: 0.8996\n",
            "Epoch 621/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2233 - accuracy: 0.9205 - val_loss: 0.2824 - val_accuracy: 0.9000\n",
            "Epoch 622/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9209 - val_loss: 0.2823 - val_accuracy: 0.9000\n",
            "Epoch 623/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2234 - accuracy: 0.9199 - val_loss: 0.2824 - val_accuracy: 0.9010\n",
            "Epoch 624/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2236 - accuracy: 0.9218 - val_loss: 0.2826 - val_accuracy: 0.9014\n",
            "Epoch 625/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9212 - val_loss: 0.2821 - val_accuracy: 0.9014\n",
            "Epoch 626/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2224 - accuracy: 0.9209 - val_loss: 0.2827 - val_accuracy: 0.8998\n",
            "Epoch 627/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9218 - val_loss: 0.2819 - val_accuracy: 0.9018\n",
            "Epoch 628/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9216 - val_loss: 0.2821 - val_accuracy: 0.9010\n",
            "Epoch 629/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2229 - accuracy: 0.9220 - val_loss: 0.2821 - val_accuracy: 0.9010\n",
            "Epoch 630/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9217 - val_loss: 0.2825 - val_accuracy: 0.9006\n",
            "Epoch 631/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2207 - accuracy: 0.9221 - val_loss: 0.2827 - val_accuracy: 0.9008\n",
            "Epoch 632/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9215 - val_loss: 0.2823 - val_accuracy: 0.9010\n",
            "Epoch 633/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2218 - accuracy: 0.9212 - val_loss: 0.2818 - val_accuracy: 0.9010\n",
            "Epoch 634/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2200 - accuracy: 0.9216 - val_loss: 0.2823 - val_accuracy: 0.9008\n",
            "Epoch 635/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2223 - accuracy: 0.9217 - val_loss: 0.2819 - val_accuracy: 0.9006\n",
            "Epoch 636/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2212 - accuracy: 0.9219 - val_loss: 0.2823 - val_accuracy: 0.9008\n",
            "Epoch 637/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2213 - accuracy: 0.9216 - val_loss: 0.2820 - val_accuracy: 0.9006\n",
            "Epoch 638/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2207 - accuracy: 0.9218 - val_loss: 0.2815 - val_accuracy: 0.8996\n",
            "Epoch 639/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9221 - val_loss: 0.2819 - val_accuracy: 0.9010\n",
            "Epoch 640/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2209 - accuracy: 0.9221 - val_loss: 0.2820 - val_accuracy: 0.9010\n",
            "Epoch 641/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2194 - accuracy: 0.9237 - val_loss: 0.2817 - val_accuracy: 0.9012\n",
            "Epoch 642/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9215 - val_loss: 0.2815 - val_accuracy: 0.9008\n",
            "Epoch 643/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2195 - accuracy: 0.9223 - val_loss: 0.2814 - val_accuracy: 0.9008\n",
            "Epoch 644/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2210 - accuracy: 0.9218 - val_loss: 0.2814 - val_accuracy: 0.8994\n",
            "Epoch 645/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.9240 - val_loss: 0.2814 - val_accuracy: 0.9016\n",
            "Epoch 646/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2196 - accuracy: 0.9225 - val_loss: 0.2820 - val_accuracy: 0.9004\n",
            "Epoch 647/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2213 - accuracy: 0.9214 - val_loss: 0.2814 - val_accuracy: 0.9010\n",
            "Epoch 648/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2192 - accuracy: 0.9219 - val_loss: 0.2818 - val_accuracy: 0.9010\n",
            "Epoch 649/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2180 - accuracy: 0.9235 - val_loss: 0.2807 - val_accuracy: 0.9006\n",
            "Epoch 650/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9232 - val_loss: 0.2814 - val_accuracy: 0.9010\n",
            "Epoch 651/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2199 - accuracy: 0.9225 - val_loss: 0.2815 - val_accuracy: 0.9016\n",
            "Epoch 652/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2171 - accuracy: 0.9234 - val_loss: 0.2818 - val_accuracy: 0.9002\n",
            "Epoch 653/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2187 - accuracy: 0.9225 - val_loss: 0.2816 - val_accuracy: 0.9004\n",
            "Epoch 654/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2181 - accuracy: 0.9233 - val_loss: 0.2815 - val_accuracy: 0.9012\n",
            "Epoch 655/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2174 - accuracy: 0.9240 - val_loss: 0.2813 - val_accuracy: 0.9006\n",
            "Epoch 656/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2206 - accuracy: 0.9226 - val_loss: 0.2815 - val_accuracy: 0.9020\n",
            "Epoch 657/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2177 - accuracy: 0.9224 - val_loss: 0.2817 - val_accuracy: 0.9010\n",
            "Epoch 658/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.9229 - val_loss: 0.2809 - val_accuracy: 0.9014\n",
            "Epoch 659/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2188 - accuracy: 0.9227 - val_loss: 0.2810 - val_accuracy: 0.9008\n",
            "Epoch 660/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9226 - val_loss: 0.2810 - val_accuracy: 0.8998\n",
            "Epoch 661/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2166 - accuracy: 0.9234 - val_loss: 0.2808 - val_accuracy: 0.9010\n",
            "Epoch 662/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2166 - accuracy: 0.9230 - val_loss: 0.2813 - val_accuracy: 0.9016\n",
            "Epoch 663/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2174 - accuracy: 0.9238 - val_loss: 0.2810 - val_accuracy: 0.8996\n",
            "Epoch 664/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9237 - val_loss: 0.2810 - val_accuracy: 0.9014\n",
            "Epoch 665/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2170 - accuracy: 0.9230 - val_loss: 0.2806 - val_accuracy: 0.9016\n",
            "Epoch 666/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2167 - accuracy: 0.9227 - val_loss: 0.2807 - val_accuracy: 0.9006\n",
            "Epoch 667/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2156 - accuracy: 0.9246 - val_loss: 0.2809 - val_accuracy: 0.9004\n",
            "Epoch 668/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2168 - accuracy: 0.9236 - val_loss: 0.2813 - val_accuracy: 0.9008\n",
            "Epoch 669/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.9233 - val_loss: 0.2812 - val_accuracy: 0.9002\n",
            "Epoch 670/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2163 - accuracy: 0.9233 - val_loss: 0.2807 - val_accuracy: 0.9010\n",
            "Epoch 671/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2165 - accuracy: 0.9239 - val_loss: 0.2805 - val_accuracy: 0.9008\n",
            "Epoch 672/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2156 - accuracy: 0.9239 - val_loss: 0.2807 - val_accuracy: 0.9016\n",
            "Epoch 673/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2170 - accuracy: 0.9234 - val_loss: 0.2807 - val_accuracy: 0.9006\n",
            "Epoch 674/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2151 - accuracy: 0.9239 - val_loss: 0.2807 - val_accuracy: 0.9010\n",
            "Epoch 675/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9247 - val_loss: 0.2804 - val_accuracy: 0.9008\n",
            "Epoch 676/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2129 - accuracy: 0.9244 - val_loss: 0.2801 - val_accuracy: 0.9010\n",
            "Epoch 677/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2159 - accuracy: 0.9245 - val_loss: 0.2805 - val_accuracy: 0.9000\n",
            "Epoch 678/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9233 - val_loss: 0.2810 - val_accuracy: 0.9004\n",
            "Epoch 679/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2152 - accuracy: 0.9238 - val_loss: 0.2806 - val_accuracy: 0.9016\n",
            "Epoch 680/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2156 - accuracy: 0.9234 - val_loss: 0.2803 - val_accuracy: 0.9008\n",
            "Epoch 681/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2131 - accuracy: 0.9245 - val_loss: 0.2804 - val_accuracy: 0.9008\n",
            "Epoch 682/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9247 - val_loss: 0.2802 - val_accuracy: 0.9004\n",
            "Epoch 683/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2150 - accuracy: 0.9237 - val_loss: 0.2811 - val_accuracy: 0.9018\n",
            "Epoch 684/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2166 - accuracy: 0.9234 - val_loss: 0.2807 - val_accuracy: 0.8998\n",
            "Epoch 685/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2113 - accuracy: 0.9250 - val_loss: 0.2807 - val_accuracy: 0.9008\n",
            "Epoch 686/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2148 - accuracy: 0.9240 - val_loss: 0.2800 - val_accuracy: 0.9006\n",
            "Epoch 687/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9254 - val_loss: 0.2803 - val_accuracy: 0.9012\n",
            "Epoch 688/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2143 - accuracy: 0.9249 - val_loss: 0.2801 - val_accuracy: 0.9016\n",
            "Epoch 689/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2138 - accuracy: 0.9248 - val_loss: 0.2806 - val_accuracy: 0.9008\n",
            "Epoch 690/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9248 - val_loss: 0.2808 - val_accuracy: 0.9004\n",
            "Epoch 691/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2127 - accuracy: 0.9244 - val_loss: 0.2799 - val_accuracy: 0.9010\n",
            "Epoch 692/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2153 - accuracy: 0.9242 - val_loss: 0.2799 - val_accuracy: 0.9000\n",
            "Epoch 693/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9254 - val_loss: 0.2805 - val_accuracy: 0.9020\n",
            "Epoch 694/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2134 - accuracy: 0.9248 - val_loss: 0.2801 - val_accuracy: 0.9018\n",
            "Epoch 695/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9246 - val_loss: 0.2801 - val_accuracy: 0.9004\n",
            "Epoch 696/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9244 - val_loss: 0.2803 - val_accuracy: 0.9010\n",
            "Epoch 697/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.9239 - val_loss: 0.2797 - val_accuracy: 0.9010\n",
            "Epoch 698/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2116 - accuracy: 0.9252 - val_loss: 0.2798 - val_accuracy: 0.9008\n",
            "Epoch 699/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2120 - accuracy: 0.9251 - val_loss: 0.2801 - val_accuracy: 0.9018\n",
            "Epoch 700/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2121 - accuracy: 0.9248 - val_loss: 0.2801 - val_accuracy: 0.9000\n",
            "Epoch 701/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9242 - val_loss: 0.2806 - val_accuracy: 0.9008\n",
            "Epoch 702/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2117 - accuracy: 0.9239 - val_loss: 0.2796 - val_accuracy: 0.9008\n",
            "Epoch 703/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9256 - val_loss: 0.2795 - val_accuracy: 0.9016\n",
            "Epoch 704/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2109 - accuracy: 0.9255 - val_loss: 0.2798 - val_accuracy: 0.9018\n",
            "Epoch 705/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2113 - accuracy: 0.9265 - val_loss: 0.2803 - val_accuracy: 0.9012\n",
            "Epoch 706/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2112 - accuracy: 0.9256 - val_loss: 0.2797 - val_accuracy: 0.9004\n",
            "Epoch 707/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2130 - accuracy: 0.9242 - val_loss: 0.2795 - val_accuracy: 0.9006\n",
            "Epoch 708/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2122 - accuracy: 0.9248 - val_loss: 0.2796 - val_accuracy: 0.9010\n",
            "Epoch 709/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2099 - accuracy: 0.9266 - val_loss: 0.2797 - val_accuracy: 0.9004\n",
            "Epoch 710/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2106 - accuracy: 0.9251 - val_loss: 0.2802 - val_accuracy: 0.9008\n",
            "Epoch 711/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2115 - accuracy: 0.9254 - val_loss: 0.2796 - val_accuracy: 0.9000\n",
            "Epoch 712/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2093 - accuracy: 0.9255 - val_loss: 0.2799 - val_accuracy: 0.9010\n",
            "Epoch 713/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.9251 - val_loss: 0.2794 - val_accuracy: 0.9012\n",
            "Epoch 714/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2100 - accuracy: 0.9258 - val_loss: 0.2796 - val_accuracy: 0.9014\n",
            "Epoch 715/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2107 - accuracy: 0.9260 - val_loss: 0.2792 - val_accuracy: 0.9014\n",
            "Epoch 716/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9246 - val_loss: 0.2795 - val_accuracy: 0.9002\n",
            "Epoch 717/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2094 - accuracy: 0.9258 - val_loss: 0.2792 - val_accuracy: 0.9010\n",
            "Epoch 718/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2071 - accuracy: 0.9275 - val_loss: 0.2788 - val_accuracy: 0.9014\n",
            "Epoch 719/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2111 - accuracy: 0.9251 - val_loss: 0.2795 - val_accuracy: 0.9014\n",
            "Epoch 720/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2093 - accuracy: 0.9256 - val_loss: 0.2793 - val_accuracy: 0.9004\n",
            "Epoch 721/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2099 - accuracy: 0.9265 - val_loss: 0.2794 - val_accuracy: 0.9018\n",
            "Epoch 722/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2087 - accuracy: 0.9264 - val_loss: 0.2789 - val_accuracy: 0.9020\n",
            "Epoch 723/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2086 - accuracy: 0.9258 - val_loss: 0.2795 - val_accuracy: 0.9014\n",
            "Epoch 724/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2097 - accuracy: 0.9266 - val_loss: 0.2788 - val_accuracy: 0.9006\n",
            "Epoch 725/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9267 - val_loss: 0.2793 - val_accuracy: 0.9006\n",
            "Epoch 726/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2085 - accuracy: 0.9271 - val_loss: 0.2791 - val_accuracy: 0.9018\n",
            "Epoch 727/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2094 - accuracy: 0.9266 - val_loss: 0.2794 - val_accuracy: 0.9006\n",
            "Epoch 728/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2074 - accuracy: 0.9264 - val_loss: 0.2795 - val_accuracy: 0.8998\n",
            "Epoch 729/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2079 - accuracy: 0.9271 - val_loss: 0.2787 - val_accuracy: 0.9008\n",
            "Epoch 730/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.9269 - val_loss: 0.2791 - val_accuracy: 0.9008\n",
            "Epoch 731/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2085 - accuracy: 0.9263 - val_loss: 0.2792 - val_accuracy: 0.9010\n",
            "Epoch 732/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2078 - accuracy: 0.9263 - val_loss: 0.2795 - val_accuracy: 0.9006\n",
            "Epoch 733/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2074 - accuracy: 0.9264 - val_loss: 0.2795 - val_accuracy: 0.9006\n",
            "Epoch 734/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2084 - accuracy: 0.9267 - val_loss: 0.2784 - val_accuracy: 0.9008\n",
            "Epoch 735/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2058 - accuracy: 0.9267 - val_loss: 0.2794 - val_accuracy: 0.9010\n",
            "Epoch 736/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2069 - accuracy: 0.9275 - val_loss: 0.2792 - val_accuracy: 0.9008\n",
            "Epoch 737/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2076 - accuracy: 0.9263 - val_loss: 0.2791 - val_accuracy: 0.9012\n",
            "Epoch 738/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.9259 - val_loss: 0.2786 - val_accuracy: 0.9012\n",
            "Epoch 739/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9272 - val_loss: 0.2784 - val_accuracy: 0.9012\n",
            "Epoch 740/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2078 - accuracy: 0.9267 - val_loss: 0.2786 - val_accuracy: 0.9004\n",
            "Epoch 741/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2060 - accuracy: 0.9270 - val_loss: 0.2789 - val_accuracy: 0.9004\n",
            "Epoch 742/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.9281 - val_loss: 0.2788 - val_accuracy: 0.9012\n",
            "Epoch 743/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2062 - accuracy: 0.9272 - val_loss: 0.2783 - val_accuracy: 0.9006\n",
            "Epoch 744/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.2079 - accuracy: 0.9259 - val_loss: 0.2786 - val_accuracy: 0.9016\n",
            "Epoch 745/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2068 - accuracy: 0.9269 - val_loss: 0.2785 - val_accuracy: 0.9006\n",
            "Epoch 746/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2051 - accuracy: 0.9280 - val_loss: 0.2785 - val_accuracy: 0.9008\n",
            "Epoch 747/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.9280 - val_loss: 0.2789 - val_accuracy: 0.9006\n",
            "Epoch 748/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9278 - val_loss: 0.2786 - val_accuracy: 0.9022\n",
            "Epoch 749/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9270 - val_loss: 0.2791 - val_accuracy: 0.9006\n",
            "Epoch 750/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2063 - accuracy: 0.9271 - val_loss: 0.2785 - val_accuracy: 0.9012\n",
            "Epoch 751/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2047 - accuracy: 0.9288 - val_loss: 0.2783 - val_accuracy: 0.9012\n",
            "Epoch 752/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9279 - val_loss: 0.2781 - val_accuracy: 0.9012\n",
            "Epoch 753/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9273 - val_loss: 0.2787 - val_accuracy: 0.9016\n",
            "Epoch 754/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2057 - accuracy: 0.9271 - val_loss: 0.2789 - val_accuracy: 0.9010\n",
            "Epoch 755/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2053 - accuracy: 0.9270 - val_loss: 0.2783 - val_accuracy: 0.9016\n",
            "Epoch 756/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9275 - val_loss: 0.2781 - val_accuracy: 0.9006\n",
            "Epoch 757/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.9289 - val_loss: 0.2785 - val_accuracy: 0.9010\n",
            "Epoch 758/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.9294 - val_loss: 0.2787 - val_accuracy: 0.9010\n",
            "Epoch 759/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2049 - accuracy: 0.9280 - val_loss: 0.2785 - val_accuracy: 0.9018\n",
            "Epoch 760/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.9274 - val_loss: 0.2786 - val_accuracy: 0.9010\n",
            "Epoch 761/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2047 - accuracy: 0.9279 - val_loss: 0.2779 - val_accuracy: 0.9002\n",
            "Epoch 762/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2042 - accuracy: 0.9284 - val_loss: 0.2781 - val_accuracy: 0.9012\n",
            "Epoch 763/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2031 - accuracy: 0.9283 - val_loss: 0.2782 - val_accuracy: 0.9008\n",
            "Epoch 764/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9276 - val_loss: 0.2789 - val_accuracy: 0.9008\n",
            "Epoch 765/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.9290 - val_loss: 0.2786 - val_accuracy: 0.9012\n",
            "Epoch 766/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2035 - accuracy: 0.9278 - val_loss: 0.2776 - val_accuracy: 0.9014\n",
            "Epoch 767/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2033 - accuracy: 0.9287 - val_loss: 0.2777 - val_accuracy: 0.9010\n",
            "Epoch 768/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2031 - accuracy: 0.9273 - val_loss: 0.2776 - val_accuracy: 0.9018\n",
            "Epoch 769/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2031 - accuracy: 0.9285 - val_loss: 0.2781 - val_accuracy: 0.9010\n",
            "Epoch 770/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2041 - accuracy: 0.9282 - val_loss: 0.2783 - val_accuracy: 0.9008\n",
            "Epoch 771/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2028 - accuracy: 0.9287 - val_loss: 0.2780 - val_accuracy: 0.9016\n",
            "Epoch 772/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2028 - accuracy: 0.9287 - val_loss: 0.2780 - val_accuracy: 0.9010\n",
            "Epoch 773/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2023 - accuracy: 0.9284 - val_loss: 0.2777 - val_accuracy: 0.9010\n",
            "Epoch 774/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2060 - accuracy: 0.9279 - val_loss: 0.2779 - val_accuracy: 0.9018\n",
            "Epoch 775/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9294 - val_loss: 0.2782 - val_accuracy: 0.9024\n",
            "Epoch 776/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2044 - accuracy: 0.9273 - val_loss: 0.2780 - val_accuracy: 0.9016\n",
            "Epoch 777/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2019 - accuracy: 0.9290 - val_loss: 0.2772 - val_accuracy: 0.9012\n",
            "Epoch 778/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2030 - accuracy: 0.9289 - val_loss: 0.2773 - val_accuracy: 0.9008\n",
            "Epoch 779/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2018 - accuracy: 0.9299 - val_loss: 0.2781 - val_accuracy: 0.9008\n",
            "Epoch 780/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1999 - accuracy: 0.9295 - val_loss: 0.2778 - val_accuracy: 0.9014\n",
            "Epoch 781/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2034 - accuracy: 0.9288 - val_loss: 0.2780 - val_accuracy: 0.9014\n",
            "Epoch 782/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9294 - val_loss: 0.2778 - val_accuracy: 0.9018\n",
            "Epoch 783/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2026 - accuracy: 0.9298 - val_loss: 0.2777 - val_accuracy: 0.9008\n",
            "Epoch 784/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2012 - accuracy: 0.9299 - val_loss: 0.2776 - val_accuracy: 0.9010\n",
            "Epoch 785/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9297 - val_loss: 0.2777 - val_accuracy: 0.9010\n",
            "Epoch 786/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2038 - accuracy: 0.9286 - val_loss: 0.2782 - val_accuracy: 0.9016\n",
            "Epoch 787/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2018 - accuracy: 0.9284 - val_loss: 0.2778 - val_accuracy: 0.9020\n",
            "Epoch 788/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9296 - val_loss: 0.2770 - val_accuracy: 0.9008\n",
            "Epoch 789/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2010 - accuracy: 0.9291 - val_loss: 0.2774 - val_accuracy: 0.9014\n",
            "Epoch 790/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2008 - accuracy: 0.9297 - val_loss: 0.2776 - val_accuracy: 0.9006\n",
            "Epoch 791/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2007 - accuracy: 0.9296 - val_loss: 0.2779 - val_accuracy: 0.9012\n",
            "Epoch 792/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2008 - accuracy: 0.9293 - val_loss: 0.2781 - val_accuracy: 0.9010\n",
            "Epoch 793/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9295 - val_loss: 0.2774 - val_accuracy: 0.9014\n",
            "Epoch 794/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9286 - val_loss: 0.2776 - val_accuracy: 0.9016\n",
            "Epoch 795/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2009 - accuracy: 0.9299 - val_loss: 0.2775 - val_accuracy: 0.9012\n",
            "Epoch 796/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1999 - accuracy: 0.9292 - val_loss: 0.2774 - val_accuracy: 0.9014\n",
            "Epoch 797/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1993 - accuracy: 0.9299 - val_loss: 0.2776 - val_accuracy: 0.9018\n",
            "Epoch 798/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2004 - accuracy: 0.9294 - val_loss: 0.2771 - val_accuracy: 0.9010\n",
            "Epoch 799/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1992 - accuracy: 0.9309 - val_loss: 0.2771 - val_accuracy: 0.9008\n",
            "Epoch 800/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1994 - accuracy: 0.9297 - val_loss: 0.2774 - val_accuracy: 0.9004\n",
            "Epoch 801/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2003 - accuracy: 0.9291 - val_loss: 0.2770 - val_accuracy: 0.9012\n",
            "Epoch 802/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2001 - accuracy: 0.9283 - val_loss: 0.2775 - val_accuracy: 0.9018\n",
            "Epoch 803/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2000 - accuracy: 0.9295 - val_loss: 0.2774 - val_accuracy: 0.9016\n",
            "Epoch 804/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1982 - accuracy: 0.9298 - val_loss: 0.2767 - val_accuracy: 0.9008\n",
            "Epoch 805/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1999 - accuracy: 0.9307 - val_loss: 0.2771 - val_accuracy: 0.9014\n",
            "Epoch 806/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9284 - val_loss: 0.2773 - val_accuracy: 0.9010\n",
            "Epoch 807/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1975 - accuracy: 0.9313 - val_loss: 0.2779 - val_accuracy: 0.9016\n",
            "Epoch 808/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2002 - accuracy: 0.9290 - val_loss: 0.2771 - val_accuracy: 0.9016\n",
            "Epoch 809/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1987 - accuracy: 0.9298 - val_loss: 0.2764 - val_accuracy: 0.9010\n",
            "Epoch 810/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9309 - val_loss: 0.2771 - val_accuracy: 0.9012\n",
            "Epoch 811/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9302 - val_loss: 0.2770 - val_accuracy: 0.9016\n",
            "Epoch 812/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.2000 - accuracy: 0.9297 - val_loss: 0.2771 - val_accuracy: 0.9010\n",
            "Epoch 813/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9300 - val_loss: 0.2770 - val_accuracy: 0.9012\n",
            "Epoch 814/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1979 - accuracy: 0.9299 - val_loss: 0.2766 - val_accuracy: 0.9012\n",
            "Epoch 815/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1969 - accuracy: 0.9317 - val_loss: 0.2767 - val_accuracy: 0.9012\n",
            "Epoch 816/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1972 - accuracy: 0.9309 - val_loss: 0.2768 - val_accuracy: 0.9004\n",
            "Epoch 817/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9307 - val_loss: 0.2776 - val_accuracy: 0.9012\n",
            "Epoch 818/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1968 - accuracy: 0.9305 - val_loss: 0.2775 - val_accuracy: 0.9022\n",
            "Epoch 819/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1996 - accuracy: 0.9294 - val_loss: 0.2774 - val_accuracy: 0.9008\n",
            "Epoch 820/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9312 - val_loss: 0.2766 - val_accuracy: 0.9012\n",
            "Epoch 821/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.9307 - val_loss: 0.2767 - val_accuracy: 0.9010\n",
            "Epoch 822/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9304 - val_loss: 0.2771 - val_accuracy: 0.9012\n",
            "Epoch 823/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1965 - accuracy: 0.9313 - val_loss: 0.2772 - val_accuracy: 0.9016\n",
            "Epoch 824/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.9313 - val_loss: 0.2771 - val_accuracy: 0.9014\n",
            "Epoch 825/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9304 - val_loss: 0.2761 - val_accuracy: 0.9016\n",
            "Epoch 826/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1970 - accuracy: 0.9308 - val_loss: 0.2764 - val_accuracy: 0.9008\n",
            "Epoch 827/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1972 - accuracy: 0.9310 - val_loss: 0.2764 - val_accuracy: 0.9020\n",
            "Epoch 828/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1981 - accuracy: 0.9314 - val_loss: 0.2764 - val_accuracy: 0.9014\n",
            "Epoch 829/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1963 - accuracy: 0.9308 - val_loss: 0.2768 - val_accuracy: 0.9012\n",
            "Epoch 830/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1959 - accuracy: 0.9312 - val_loss: 0.2764 - val_accuracy: 0.9014\n",
            "Epoch 831/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1962 - accuracy: 0.9306 - val_loss: 0.2765 - val_accuracy: 0.9010\n",
            "Epoch 832/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1964 - accuracy: 0.9309 - val_loss: 0.2765 - val_accuracy: 0.9010\n",
            "Epoch 833/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1950 - accuracy: 0.9317 - val_loss: 0.2768 - val_accuracy: 0.9016\n",
            "Epoch 834/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1973 - accuracy: 0.9299 - val_loss: 0.2770 - val_accuracy: 0.9016\n",
            "Epoch 835/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1939 - accuracy: 0.9323 - val_loss: 0.2766 - val_accuracy: 0.9018\n",
            "Epoch 836/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1970 - accuracy: 0.9300 - val_loss: 0.2761 - val_accuracy: 0.9010\n",
            "Epoch 837/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1948 - accuracy: 0.9314 - val_loss: 0.2763 - val_accuracy: 0.9010\n",
            "Epoch 838/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1931 - accuracy: 0.9328 - val_loss: 0.2762 - val_accuracy: 0.9012\n",
            "Epoch 839/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1960 - accuracy: 0.9304 - val_loss: 0.2765 - val_accuracy: 0.9008\n",
            "Epoch 840/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9315 - val_loss: 0.2767 - val_accuracy: 0.9012\n",
            "Epoch 841/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1958 - accuracy: 0.9309 - val_loss: 0.2763 - val_accuracy: 0.9014\n",
            "Epoch 842/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.9317 - val_loss: 0.2765 - val_accuracy: 0.9008\n",
            "Epoch 843/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9316 - val_loss: 0.2761 - val_accuracy: 0.9016\n",
            "Epoch 844/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.9314 - val_loss: 0.2763 - val_accuracy: 0.9018\n",
            "Epoch 845/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1938 - accuracy: 0.9314 - val_loss: 0.2765 - val_accuracy: 0.9012\n",
            "Epoch 846/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1963 - accuracy: 0.9313 - val_loss: 0.2762 - val_accuracy: 0.9020\n",
            "Epoch 847/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1926 - accuracy: 0.9328 - val_loss: 0.2759 - val_accuracy: 0.9006\n",
            "Epoch 848/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9312 - val_loss: 0.2764 - val_accuracy: 0.9006\n",
            "Epoch 849/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1950 - accuracy: 0.9326 - val_loss: 0.2762 - val_accuracy: 0.9014\n",
            "Epoch 850/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1948 - accuracy: 0.9310 - val_loss: 0.2764 - val_accuracy: 0.9010\n",
            "Epoch 851/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1932 - accuracy: 0.9318 - val_loss: 0.2765 - val_accuracy: 0.9018\n",
            "Epoch 852/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1930 - accuracy: 0.9323 - val_loss: 0.2758 - val_accuracy: 0.9010\n",
            "Epoch 853/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9316 - val_loss: 0.2763 - val_accuracy: 0.9012\n",
            "Epoch 854/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1936 - accuracy: 0.9326 - val_loss: 0.2762 - val_accuracy: 0.9012\n",
            "Epoch 855/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1941 - accuracy: 0.9316 - val_loss: 0.2766 - val_accuracy: 0.9012\n",
            "Epoch 856/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1936 - accuracy: 0.9319 - val_loss: 0.2765 - val_accuracy: 0.9008\n",
            "Epoch 857/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1940 - accuracy: 0.9320 - val_loss: 0.2762 - val_accuracy: 0.9018\n",
            "Epoch 858/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1936 - accuracy: 0.9319 - val_loss: 0.2763 - val_accuracy: 0.9006\n",
            "Epoch 859/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1936 - accuracy: 0.9327 - val_loss: 0.2768 - val_accuracy: 0.9016\n",
            "Epoch 860/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1935 - accuracy: 0.9319 - val_loss: 0.2766 - val_accuracy: 0.9018\n",
            "Epoch 861/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1938 - accuracy: 0.9308 - val_loss: 0.2761 - val_accuracy: 0.9014\n",
            "Epoch 862/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1929 - accuracy: 0.9311 - val_loss: 0.2761 - val_accuracy: 0.9022\n",
            "Epoch 863/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1924 - accuracy: 0.9334 - val_loss: 0.2758 - val_accuracy: 0.9008\n",
            "Epoch 864/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1942 - accuracy: 0.9319 - val_loss: 0.2760 - val_accuracy: 0.9018\n",
            "Epoch 865/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1927 - accuracy: 0.9322 - val_loss: 0.2757 - val_accuracy: 0.9020\n",
            "Epoch 866/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9325 - val_loss: 0.2759 - val_accuracy: 0.9014\n",
            "Epoch 867/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.9317 - val_loss: 0.2762 - val_accuracy: 0.9014\n",
            "Epoch 868/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.9334 - val_loss: 0.2756 - val_accuracy: 0.9014\n",
            "Epoch 869/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1914 - accuracy: 0.9335 - val_loss: 0.2756 - val_accuracy: 0.9010\n",
            "Epoch 870/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9337 - val_loss: 0.2762 - val_accuracy: 0.9022\n",
            "Epoch 871/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 0.9330 - val_loss: 0.2762 - val_accuracy: 0.9026\n",
            "Epoch 872/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1940 - accuracy: 0.9319 - val_loss: 0.2761 - val_accuracy: 0.9030\n",
            "Epoch 873/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9324 - val_loss: 0.2758 - val_accuracy: 0.9020\n",
            "Epoch 874/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1891 - accuracy: 0.9339 - val_loss: 0.2755 - val_accuracy: 0.9018\n",
            "Epoch 875/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9335 - val_loss: 0.2756 - val_accuracy: 0.9016\n",
            "Epoch 876/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.9343 - val_loss: 0.2760 - val_accuracy: 0.9022\n",
            "Epoch 877/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1924 - accuracy: 0.9327 - val_loss: 0.2764 - val_accuracy: 0.9018\n",
            "Epoch 878/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1911 - accuracy: 0.9326 - val_loss: 0.2760 - val_accuracy: 0.9022\n",
            "Epoch 879/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1908 - accuracy: 0.9332 - val_loss: 0.2760 - val_accuracy: 0.9008\n",
            "Epoch 880/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1926 - accuracy: 0.9323 - val_loss: 0.2761 - val_accuracy: 0.9018\n",
            "Epoch 881/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1896 - accuracy: 0.9335 - val_loss: 0.2760 - val_accuracy: 0.9016\n",
            "Epoch 882/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1916 - accuracy: 0.9337 - val_loss: 0.2761 - val_accuracy: 0.9014\n",
            "Epoch 883/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1906 - accuracy: 0.9327 - val_loss: 0.2767 - val_accuracy: 0.9010\n",
            "Epoch 884/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9320 - val_loss: 0.2760 - val_accuracy: 0.9002\n",
            "Epoch 885/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.9336 - val_loss: 0.2759 - val_accuracy: 0.9014\n",
            "Epoch 886/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1906 - accuracy: 0.9337 - val_loss: 0.2762 - val_accuracy: 0.9018\n",
            "Epoch 887/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1901 - accuracy: 0.9331 - val_loss: 0.2763 - val_accuracy: 0.9016\n",
            "Epoch 888/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.9324 - val_loss: 0.2767 - val_accuracy: 0.9014\n",
            "Epoch 889/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9337 - val_loss: 0.2757 - val_accuracy: 0.9016\n",
            "Epoch 890/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1899 - accuracy: 0.9340 - val_loss: 0.2758 - val_accuracy: 0.9022\n",
            "Epoch 891/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.9327 - val_loss: 0.2755 - val_accuracy: 0.9014\n",
            "Epoch 892/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1885 - accuracy: 0.9342 - val_loss: 0.2759 - val_accuracy: 0.9032\n",
            "Epoch 893/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1893 - accuracy: 0.9338 - val_loss: 0.2762 - val_accuracy: 0.9020\n",
            "Epoch 894/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.9333 - val_loss: 0.2760 - val_accuracy: 0.9026\n",
            "Epoch 895/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1906 - accuracy: 0.9331 - val_loss: 0.2758 - val_accuracy: 0.9012\n",
            "Epoch 896/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.9341 - val_loss: 0.2755 - val_accuracy: 0.9016\n",
            "Epoch 897/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1884 - accuracy: 0.9340 - val_loss: 0.2757 - val_accuracy: 0.9006\n",
            "Epoch 898/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1890 - accuracy: 0.9341 - val_loss: 0.2758 - val_accuracy: 0.9012\n",
            "Epoch 899/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1876 - accuracy: 0.9341 - val_loss: 0.2764 - val_accuracy: 0.9018\n",
            "Epoch 900/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1883 - accuracy: 0.9331 - val_loss: 0.2753 - val_accuracy: 0.9014\n",
            "Epoch 901/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1890 - accuracy: 0.9343 - val_loss: 0.2754 - val_accuracy: 0.9010\n",
            "Epoch 902/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1888 - accuracy: 0.9336 - val_loss: 0.2755 - val_accuracy: 0.9008\n",
            "Epoch 903/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1888 - accuracy: 0.9335 - val_loss: 0.2756 - val_accuracy: 0.9014\n",
            "Epoch 904/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1881 - accuracy: 0.9338 - val_loss: 0.2761 - val_accuracy: 0.9020\n",
            "Epoch 905/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1895 - accuracy: 0.9333 - val_loss: 0.2752 - val_accuracy: 0.9016\n",
            "Epoch 906/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1878 - accuracy: 0.9341 - val_loss: 0.2755 - val_accuracy: 0.9014\n",
            "Epoch 907/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1879 - accuracy: 0.9340 - val_loss: 0.2754 - val_accuracy: 0.9008\n",
            "Epoch 908/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1855 - accuracy: 0.9350 - val_loss: 0.2755 - val_accuracy: 0.9014\n",
            "Epoch 909/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.9333 - val_loss: 0.2761 - val_accuracy: 0.9022\n",
            "Epoch 910/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1878 - accuracy: 0.9337 - val_loss: 0.2753 - val_accuracy: 0.9010\n",
            "Epoch 911/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1874 - accuracy: 0.9345 - val_loss: 0.2756 - val_accuracy: 0.9014\n",
            "Epoch 912/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9339 - val_loss: 0.2753 - val_accuracy: 0.9014\n",
            "Epoch 913/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.9347 - val_loss: 0.2756 - val_accuracy: 0.9018\n",
            "Epoch 914/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1883 - accuracy: 0.9340 - val_loss: 0.2754 - val_accuracy: 0.9016\n",
            "Epoch 915/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.9349 - val_loss: 0.2757 - val_accuracy: 0.9028\n",
            "Epoch 916/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9345 - val_loss: 0.2748 - val_accuracy: 0.9012\n",
            "Epoch 917/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1873 - accuracy: 0.9348 - val_loss: 0.2754 - val_accuracy: 0.9014\n",
            "Epoch 918/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1870 - accuracy: 0.9354 - val_loss: 0.2754 - val_accuracy: 0.9014\n",
            "Epoch 919/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1895 - accuracy: 0.9341 - val_loss: 0.2759 - val_accuracy: 0.9028\n",
            "Epoch 920/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1842 - accuracy: 0.9345 - val_loss: 0.2756 - val_accuracy: 0.9016\n",
            "Epoch 921/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.9342 - val_loss: 0.2750 - val_accuracy: 0.9004\n",
            "Epoch 922/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9339 - val_loss: 0.2752 - val_accuracy: 0.9004\n",
            "Epoch 923/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1860 - accuracy: 0.9354 - val_loss: 0.2749 - val_accuracy: 0.9004\n",
            "Epoch 924/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.9340 - val_loss: 0.2750 - val_accuracy: 0.9006\n",
            "Epoch 925/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1864 - accuracy: 0.9339 - val_loss: 0.2768 - val_accuracy: 0.9024\n",
            "Epoch 926/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.9343 - val_loss: 0.2750 - val_accuracy: 0.9022\n",
            "Epoch 927/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1857 - accuracy: 0.9348 - val_loss: 0.2753 - val_accuracy: 0.9006\n",
            "Epoch 928/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9348 - val_loss: 0.2751 - val_accuracy: 0.9010\n",
            "Epoch 929/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9341 - val_loss: 0.2750 - val_accuracy: 0.9010\n",
            "Epoch 930/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1849 - accuracy: 0.9346 - val_loss: 0.2750 - val_accuracy: 0.9014\n",
            "Epoch 931/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1859 - accuracy: 0.9351 - val_loss: 0.2752 - val_accuracy: 0.9016\n",
            "Epoch 932/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1860 - accuracy: 0.9346 - val_loss: 0.2748 - val_accuracy: 0.9006\n",
            "Epoch 933/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9352 - val_loss: 0.2749 - val_accuracy: 0.9006\n",
            "Epoch 934/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1861 - accuracy: 0.9347 - val_loss: 0.2750 - val_accuracy: 0.9010\n",
            "Epoch 935/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1839 - accuracy: 0.9357 - val_loss: 0.2752 - val_accuracy: 0.9016\n",
            "Epoch 936/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1862 - accuracy: 0.9331 - val_loss: 0.2753 - val_accuracy: 0.9018\n",
            "Epoch 937/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9345 - val_loss: 0.2748 - val_accuracy: 0.9018\n",
            "Epoch 938/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1839 - accuracy: 0.9347 - val_loss: 0.2751 - val_accuracy: 0.9014\n",
            "Epoch 939/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9365 - val_loss: 0.2753 - val_accuracy: 0.9012\n",
            "Epoch 940/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9356 - val_loss: 0.2754 - val_accuracy: 0.9014\n",
            "Epoch 941/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1861 - accuracy: 0.9347 - val_loss: 0.2752 - val_accuracy: 0.9020\n",
            "Epoch 942/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1839 - accuracy: 0.9352 - val_loss: 0.2753 - val_accuracy: 0.9030\n",
            "Epoch 943/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1851 - accuracy: 0.9350 - val_loss: 0.2747 - val_accuracy: 0.9010\n",
            "Epoch 944/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1846 - accuracy: 0.9354 - val_loss: 0.2746 - val_accuracy: 0.9012\n",
            "Epoch 945/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1817 - accuracy: 0.9366 - val_loss: 0.2751 - val_accuracy: 0.9016\n",
            "Epoch 946/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1858 - accuracy: 0.9358 - val_loss: 0.2757 - val_accuracy: 0.9022\n",
            "Epoch 947/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9350 - val_loss: 0.2750 - val_accuracy: 0.9018\n",
            "Epoch 948/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1829 - accuracy: 0.9361 - val_loss: 0.2747 - val_accuracy: 0.9016\n",
            "Epoch 949/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1818 - accuracy: 0.9362 - val_loss: 0.2745 - val_accuracy: 0.9002\n",
            "Epoch 950/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.9362 - val_loss: 0.2750 - val_accuracy: 0.9014\n",
            "Epoch 951/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1845 - accuracy: 0.9356 - val_loss: 0.2753 - val_accuracy: 0.9014\n",
            "Epoch 952/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1836 - accuracy: 0.9348 - val_loss: 0.2759 - val_accuracy: 0.9014\n",
            "Epoch 953/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1821 - accuracy: 0.9371 - val_loss: 0.2752 - val_accuracy: 0.9012\n",
            "Epoch 954/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1839 - accuracy: 0.9365 - val_loss: 0.2746 - val_accuracy: 0.9012\n",
            "Epoch 955/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1829 - accuracy: 0.9358 - val_loss: 0.2747 - val_accuracy: 0.9016\n",
            "Epoch 956/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1835 - accuracy: 0.9363 - val_loss: 0.2746 - val_accuracy: 0.9018\n",
            "Epoch 957/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1832 - accuracy: 0.9361 - val_loss: 0.2753 - val_accuracy: 0.9022\n",
            "Epoch 958/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1832 - accuracy: 0.9362 - val_loss: 0.2752 - val_accuracy: 0.9028\n",
            "Epoch 959/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9363 - val_loss: 0.2747 - val_accuracy: 0.9020\n",
            "Epoch 960/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1814 - accuracy: 0.9373 - val_loss: 0.2752 - val_accuracy: 0.9008\n",
            "Epoch 961/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.9358 - val_loss: 0.2748 - val_accuracy: 0.9014\n",
            "Epoch 962/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9360 - val_loss: 0.2753 - val_accuracy: 0.9024\n",
            "Epoch 963/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1816 - accuracy: 0.9360 - val_loss: 0.2750 - val_accuracy: 0.9014\n",
            "Epoch 964/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1819 - accuracy: 0.9348 - val_loss: 0.2744 - val_accuracy: 0.9012\n",
            "Epoch 965/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1841 - accuracy: 0.9351 - val_loss: 0.2745 - val_accuracy: 0.9012\n",
            "Epoch 966/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1817 - accuracy: 0.9360 - val_loss: 0.2752 - val_accuracy: 0.9018\n",
            "Epoch 967/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9356 - val_loss: 0.2754 - val_accuracy: 0.9016\n",
            "Epoch 968/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9367 - val_loss: 0.2752 - val_accuracy: 0.9018\n",
            "Epoch 969/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1823 - accuracy: 0.9360 - val_loss: 0.2754 - val_accuracy: 0.9024\n",
            "Epoch 970/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1819 - accuracy: 0.9359 - val_loss: 0.2746 - val_accuracy: 0.9014\n",
            "Epoch 971/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9365 - val_loss: 0.2748 - val_accuracy: 0.9014\n",
            "Epoch 972/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1816 - accuracy: 0.9362 - val_loss: 0.2751 - val_accuracy: 0.9018\n",
            "Epoch 973/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1803 - accuracy: 0.9367 - val_loss: 0.2754 - val_accuracy: 0.9026\n",
            "Epoch 974/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1817 - accuracy: 0.9369 - val_loss: 0.2752 - val_accuracy: 0.9032\n",
            "Epoch 975/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1809 - accuracy: 0.9365 - val_loss: 0.2748 - val_accuracy: 0.9010\n",
            "Epoch 976/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1815 - accuracy: 0.9369 - val_loss: 0.2747 - val_accuracy: 0.9018\n",
            "Epoch 977/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1808 - accuracy: 0.9375 - val_loss: 0.2746 - val_accuracy: 0.9016\n",
            "Epoch 978/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9367 - val_loss: 0.2745 - val_accuracy: 0.9016\n",
            "Epoch 979/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9365 - val_loss: 0.2748 - val_accuracy: 0.9022\n",
            "Epoch 980/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1805 - accuracy: 0.9373 - val_loss: 0.2752 - val_accuracy: 0.9028\n",
            "Epoch 981/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1806 - accuracy: 0.9368 - val_loss: 0.2742 - val_accuracy: 0.9006\n",
            "Epoch 982/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1810 - accuracy: 0.9371 - val_loss: 0.2745 - val_accuracy: 0.9012\n",
            "Epoch 983/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9374 - val_loss: 0.2752 - val_accuracy: 0.9026\n",
            "Epoch 984/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1798 - accuracy: 0.9364 - val_loss: 0.2747 - val_accuracy: 0.9028\n",
            "Epoch 985/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9371 - val_loss: 0.2742 - val_accuracy: 0.9016\n",
            "Epoch 986/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1812 - accuracy: 0.9365 - val_loss: 0.2744 - val_accuracy: 0.9022\n",
            "Epoch 987/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9368 - val_loss: 0.2741 - val_accuracy: 0.9010\n",
            "Epoch 988/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9369 - val_loss: 0.2743 - val_accuracy: 0.9016\n",
            "Epoch 989/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1797 - accuracy: 0.9377 - val_loss: 0.2748 - val_accuracy: 0.9028\n",
            "Epoch 990/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1792 - accuracy: 0.9373 - val_loss: 0.2743 - val_accuracy: 0.9024\n",
            "Epoch 991/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9360 - val_loss: 0.2745 - val_accuracy: 0.9032\n",
            "Epoch 992/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9377 - val_loss: 0.2746 - val_accuracy: 0.9020\n",
            "Epoch 993/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1815 - accuracy: 0.9357 - val_loss: 0.2743 - val_accuracy: 0.9014\n",
            "Epoch 994/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9378 - val_loss: 0.2745 - val_accuracy: 0.9022\n",
            "Epoch 995/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1796 - accuracy: 0.9376 - val_loss: 0.2751 - val_accuracy: 0.9026\n",
            "Epoch 996/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9376 - val_loss: 0.2747 - val_accuracy: 0.9024\n",
            "Epoch 997/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 0.9371 - val_loss: 0.2748 - val_accuracy: 0.9026\n",
            "Epoch 998/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1798 - accuracy: 0.9374 - val_loss: 0.2745 - val_accuracy: 0.9008\n",
            "Epoch 999/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9374 - val_loss: 0.2752 - val_accuracy: 0.9020\n",
            "Epoch 1000/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9368 - val_loss: 0.2743 - val_accuracy: 0.9020\n",
            "Epoch 1001/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.9381 - val_loss: 0.2744 - val_accuracy: 0.9018\n",
            "Epoch 1002/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1790 - accuracy: 0.9381 - val_loss: 0.2745 - val_accuracy: 0.9018\n",
            "Epoch 1003/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9380 - val_loss: 0.2746 - val_accuracy: 0.9020\n",
            "Epoch 1004/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1801 - accuracy: 0.9372 - val_loss: 0.2751 - val_accuracy: 0.9020\n",
            "Epoch 1005/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9370 - val_loss: 0.2751 - val_accuracy: 0.9026\n",
            "Epoch 1006/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1794 - accuracy: 0.9367 - val_loss: 0.2743 - val_accuracy: 0.9022\n",
            "Epoch 1007/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1793 - accuracy: 0.9369 - val_loss: 0.2743 - val_accuracy: 0.9014\n",
            "Epoch 1008/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1782 - accuracy: 0.9373 - val_loss: 0.2746 - val_accuracy: 0.9020\n",
            "Epoch 1009/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1774 - accuracy: 0.9382 - val_loss: 0.2743 - val_accuracy: 0.9018\n",
            "Epoch 1010/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.9382 - val_loss: 0.2748 - val_accuracy: 0.9032\n",
            "Epoch 1011/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1784 - accuracy: 0.9370 - val_loss: 0.2746 - val_accuracy: 0.9024\n",
            "Epoch 1012/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9375 - val_loss: 0.2743 - val_accuracy: 0.9016\n",
            "Epoch 1013/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1773 - accuracy: 0.9381 - val_loss: 0.2748 - val_accuracy: 0.9022\n",
            "Epoch 1014/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.9376 - val_loss: 0.2745 - val_accuracy: 0.9030\n",
            "Epoch 1015/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9377 - val_loss: 0.2743 - val_accuracy: 0.9022\n",
            "Epoch 1016/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1755 - accuracy: 0.9383 - val_loss: 0.2742 - val_accuracy: 0.9022\n",
            "Epoch 1017/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1768 - accuracy: 0.9381 - val_loss: 0.2741 - val_accuracy: 0.9024\n",
            "Epoch 1018/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9389 - val_loss: 0.2736 - val_accuracy: 0.9018\n",
            "Epoch 1019/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1778 - accuracy: 0.9384 - val_loss: 0.2741 - val_accuracy: 0.9012\n",
            "Epoch 1020/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1769 - accuracy: 0.9387 - val_loss: 0.2743 - val_accuracy: 0.9020\n",
            "Epoch 1021/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9382 - val_loss: 0.2748 - val_accuracy: 0.9030\n",
            "Epoch 1022/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1772 - accuracy: 0.9373 - val_loss: 0.2747 - val_accuracy: 0.9032\n",
            "Epoch 1023/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1765 - accuracy: 0.9386 - val_loss: 0.2741 - val_accuracy: 0.9016\n",
            "Epoch 1024/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9383 - val_loss: 0.2743 - val_accuracy: 0.9018\n",
            "Epoch 1025/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9384 - val_loss: 0.2750 - val_accuracy: 0.9026\n",
            "Epoch 1026/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1781 - accuracy: 0.9371 - val_loss: 0.2744 - val_accuracy: 0.9026\n",
            "Epoch 1027/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1766 - accuracy: 0.9379 - val_loss: 0.2743 - val_accuracy: 0.9028\n",
            "Epoch 1028/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1771 - accuracy: 0.9384 - val_loss: 0.2743 - val_accuracy: 0.9028\n",
            "Epoch 1029/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1764 - accuracy: 0.9379 - val_loss: 0.2742 - val_accuracy: 0.9024\n",
            "Epoch 1030/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1749 - accuracy: 0.9393 - val_loss: 0.2742 - val_accuracy: 0.9030\n",
            "Epoch 1031/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.9373 - val_loss: 0.2745 - val_accuracy: 0.9022\n",
            "Epoch 1032/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1754 - accuracy: 0.9382 - val_loss: 0.2749 - val_accuracy: 0.9024\n",
            "Epoch 1033/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.9381 - val_loss: 0.2744 - val_accuracy: 0.9028\n",
            "Epoch 1034/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1761 - accuracy: 0.9389 - val_loss: 0.2740 - val_accuracy: 0.9024\n",
            "Epoch 1035/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9396 - val_loss: 0.2744 - val_accuracy: 0.9034\n",
            "Epoch 1036/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1744 - accuracy: 0.9389 - val_loss: 0.2741 - val_accuracy: 0.9022\n",
            "Epoch 1037/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1764 - accuracy: 0.9378 - val_loss: 0.2753 - val_accuracy: 0.9022\n",
            "Epoch 1038/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9385 - val_loss: 0.2748 - val_accuracy: 0.9028\n",
            "Epoch 1039/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1762 - accuracy: 0.9392 - val_loss: 0.2743 - val_accuracy: 0.9022\n",
            "Epoch 1040/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9386 - val_loss: 0.2741 - val_accuracy: 0.9022\n",
            "Epoch 1041/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9392 - val_loss: 0.2743 - val_accuracy: 0.9026\n",
            "Epoch 1042/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1755 - accuracy: 0.9384 - val_loss: 0.2748 - val_accuracy: 0.9026\n",
            "Epoch 1043/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1755 - accuracy: 0.9386 - val_loss: 0.2742 - val_accuracy: 0.9024\n",
            "Epoch 1044/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1765 - accuracy: 0.9381 - val_loss: 0.2743 - val_accuracy: 0.9022\n",
            "Epoch 1045/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.9387 - val_loss: 0.2735 - val_accuracy: 0.9016\n",
            "Epoch 1046/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9390 - val_loss: 0.2740 - val_accuracy: 0.9022\n",
            "Epoch 1047/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1753 - accuracy: 0.9385 - val_loss: 0.2743 - val_accuracy: 0.9024\n",
            "Epoch 1048/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9388 - val_loss: 0.2743 - val_accuracy: 0.9022\n",
            "Epoch 1049/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1757 - accuracy: 0.9388 - val_loss: 0.2739 - val_accuracy: 0.9022\n",
            "Epoch 1050/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9403 - val_loss: 0.2744 - val_accuracy: 0.9034\n",
            "Epoch 1051/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1742 - accuracy: 0.9392 - val_loss: 0.2739 - val_accuracy: 0.9020\n",
            "Epoch 1052/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9392 - val_loss: 0.2749 - val_accuracy: 0.9024\n",
            "Epoch 1053/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1770 - accuracy: 0.9374 - val_loss: 0.2748 - val_accuracy: 0.9020\n",
            "Epoch 1054/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1729 - accuracy: 0.9402 - val_loss: 0.2751 - val_accuracy: 0.9026\n",
            "Epoch 1055/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1734 - accuracy: 0.9399 - val_loss: 0.2743 - val_accuracy: 0.9032\n",
            "Epoch 1056/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1750 - accuracy: 0.9387 - val_loss: 0.2740 - val_accuracy: 0.9036\n",
            "Epoch 1057/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1710 - accuracy: 0.9408 - val_loss: 0.2745 - val_accuracy: 0.9034\n",
            "Epoch 1058/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1742 - accuracy: 0.9392 - val_loss: 0.2745 - val_accuracy: 0.9028\n",
            "Epoch 1059/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1736 - accuracy: 0.9401 - val_loss: 0.2743 - val_accuracy: 0.9022\n",
            "Epoch 1060/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1748 - accuracy: 0.9381 - val_loss: 0.2753 - val_accuracy: 0.9028\n",
            "Epoch 1061/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1725 - accuracy: 0.9392 - val_loss: 0.2743 - val_accuracy: 0.9036\n",
            "Epoch 1062/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1745 - accuracy: 0.9384 - val_loss: 0.2742 - val_accuracy: 0.9030\n",
            "Epoch 1063/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9389 - val_loss: 0.2744 - val_accuracy: 0.9032\n",
            "Epoch 1064/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1714 - accuracy: 0.9410 - val_loss: 0.2752 - val_accuracy: 0.9024\n",
            "Epoch 1065/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9394 - val_loss: 0.2747 - val_accuracy: 0.9032\n",
            "Epoch 1066/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.9396 - val_loss: 0.2744 - val_accuracy: 0.9032\n",
            "Epoch 1067/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.9407 - val_loss: 0.2744 - val_accuracy: 0.9038\n",
            "Epoch 1068/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.9400 - val_loss: 0.2738 - val_accuracy: 0.9026\n",
            "Epoch 1069/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.9389 - val_loss: 0.2743 - val_accuracy: 0.9026\n",
            "Epoch 1070/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9399 - val_loss: 0.2743 - val_accuracy: 0.9030\n",
            "Epoch 1071/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9392 - val_loss: 0.2746 - val_accuracy: 0.9032\n",
            "Epoch 1072/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9401 - val_loss: 0.2741 - val_accuracy: 0.9036\n",
            "Epoch 1073/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.9403 - val_loss: 0.2743 - val_accuracy: 0.9034\n",
            "Epoch 1074/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1728 - accuracy: 0.9396 - val_loss: 0.2745 - val_accuracy: 0.9038\n",
            "Epoch 1075/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1728 - accuracy: 0.9393 - val_loss: 0.2747 - val_accuracy: 0.9028\n",
            "Epoch 1076/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.9405 - val_loss: 0.2741 - val_accuracy: 0.9042\n",
            "Epoch 1077/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9400 - val_loss: 0.2738 - val_accuracy: 0.9028\n",
            "Epoch 1078/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1735 - accuracy: 0.9400 - val_loss: 0.2739 - val_accuracy: 0.9034\n",
            "Epoch 1079/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1711 - accuracy: 0.9400 - val_loss: 0.2741 - val_accuracy: 0.9032\n",
            "Epoch 1080/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9400 - val_loss: 0.2750 - val_accuracy: 0.9034\n",
            "Epoch 1081/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1724 - accuracy: 0.9394 - val_loss: 0.2746 - val_accuracy: 0.9040\n",
            "Epoch 1082/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.9409 - val_loss: 0.2743 - val_accuracy: 0.9028\n",
            "Epoch 1083/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1715 - accuracy: 0.9400 - val_loss: 0.2740 - val_accuracy: 0.9024\n",
            "Epoch 1084/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9405 - val_loss: 0.2744 - val_accuracy: 0.9036\n",
            "Epoch 1085/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1707 - accuracy: 0.9409 - val_loss: 0.2741 - val_accuracy: 0.9036\n",
            "Epoch 1086/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1731 - accuracy: 0.9394 - val_loss: 0.2752 - val_accuracy: 0.9026\n",
            "Epoch 1087/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9400 - val_loss: 0.2743 - val_accuracy: 0.9026\n",
            "Epoch 1088/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9408 - val_loss: 0.2741 - val_accuracy: 0.9040\n",
            "Epoch 1089/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1712 - accuracy: 0.9404 - val_loss: 0.2740 - val_accuracy: 0.9028\n",
            "Epoch 1090/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1707 - accuracy: 0.9411 - val_loss: 0.2754 - val_accuracy: 0.9022\n",
            "Epoch 1091/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1716 - accuracy: 0.9402 - val_loss: 0.2748 - val_accuracy: 0.9034\n",
            "Epoch 1092/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.9421 - val_loss: 0.2747 - val_accuracy: 0.9032\n",
            "Epoch 1093/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9400 - val_loss: 0.2746 - val_accuracy: 0.9038\n",
            "Epoch 1094/1100\n",
            "51/50 [==============================] - 0s 6ms/step - loss: 0.1711 - accuracy: 0.9399 - val_loss: 0.2734 - val_accuracy: 0.9026\n",
            "Epoch 1095/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1707 - accuracy: 0.9418 - val_loss: 0.2736 - val_accuracy: 0.9018\n",
            "Epoch 1096/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.9409 - val_loss: 0.2746 - val_accuracy: 0.9030\n",
            "Epoch 1097/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9408 - val_loss: 0.2747 - val_accuracy: 0.9042\n",
            "Epoch 1098/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1713 - accuracy: 0.9412 - val_loss: 0.2743 - val_accuracy: 0.9040\n",
            "Epoch 1099/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1694 - accuracy: 0.9402 - val_loss: 0.2740 - val_accuracy: 0.9042\n",
            "Epoch 1100/1100\n",
            "51/50 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9411 - val_loss: 0.2745 - val_accuracy: 0.9036\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nIkXFSfO0rO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "d1b644ed-1f84-4cb3-f5eb-7de416c4ec67"
      },
      "source": [
        "# adding dropout after first hidden layer + Add learning schedule with lr=1e-2\n",
        "plot_train_loss()\n",
        "plot_train_accuracy()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cfTL_5kPsl4j"
      },
      "source": [
        "### Task 1.2 Train a ConvNet from scratch\n",
        "\n",
        "*(weight ~2%)*\n",
        "\n",
        "Build a ConvNet to replace the densely connected network in Task 1.1. Report the classification accuracy on the test set. Aim to achieve higher accuracy. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQlFelM8auu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "14016130-bfa7-4760-cbfc-7713df6979d5"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-a542e1d6dcc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                                       f'train[{TRAIN_DS_SIZE + VALID_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE + TEST_DS_SIZE}]'],\n\u001b[1;32m     11\u001b[0m                                                                \u001b[0mwith_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                                as_supervised=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/registered.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"read_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m   \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mas_dataset_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mwith_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, batch_size, shuffle_files, decoders, read_config, as_supervised, in_memory)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_single_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[0;32m--> 153\u001b[0;31m                 for v in data_struct]\n\u001b[0m\u001b[1;32m    154\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       mapped = [map_nested(function, v, dict_only, map_tuple)\n\u001b[0;32m--> 153\u001b[0;31m                 for v in data_struct]\n\u001b[0m\u001b[1;32m    154\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_tuple)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0;31m# Singleton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[0;34m(self, split, shuffle_files, batch_size, decoders, read_config, as_supervised, in_memory)\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m           \u001b[0mdecoders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m           \u001b[0mread_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m       )\n\u001b[1;32m    543\u001b[0m       \u001b[0;31m# Auto-cache small datasets which are small enough to fit in memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[0;34m(self, split, decoders, read_config, shuffle_files)\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0msplit_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m           \u001b[0mread_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m           \u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       )\n\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, name, instructions, split_infos, read_config, shuffle_files)\u001b[0m\n\u001b[1;32m    288\u001b[0m       )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_read_instruction_to_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   def read_files(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m_read_instruction_to_ds\u001b[0;34m(instruction)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \"\"\"\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_instruction_to_ds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m       \u001b[0mfile_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_file_instructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m       \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_instructions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mmake_file_instructions\u001b[0;34m(name, split_infos, instruction)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0minstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;31m# Create the absolute instruction (per split)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m   \u001b[0mabsolute_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_absolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname2len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   return _make_file_instructions_from_absolutes(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36mto_absolute\u001b[0;34m(self, name2len)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \"\"\"\n\u001b[1;32m    546\u001b[0m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0;32m--> 547\u001b[0;31m             for rel_instr in self._relative_instructions]\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \"\"\"\n\u001b[1;32m    546\u001b[0m     return [_rel_to_abs_instr(rel_instr, name2len)\n\u001b[0;32m--> 547\u001b[0;31m             for rel_instr in self._relative_instructions]\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/tfrecords_reader.py\u001b[0m in \u001b[0;36m_rel_to_abs_instr\u001b[0;34m(rel_instr, name2len)\u001b[0m\n\u001b[1;32m    403\u001b[0m     msg = 'Requested slice [%s:%s] incompatible with %s examples.' % (\n\u001b[1;32m    404\u001b[0m         from_ or '', to or '', num_examples)\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfrom_\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0mfrom_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_examples\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Requested slice [60000:70000] incompatible with 60000 examples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e2Wv4ciS0N2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7a7ec0b0-7723-465b-8325-5a80edcbefb5"
      },
      "source": [
        "IMAGE_SIZE = 28\n",
        "from keras import optimizers\n",
        "\n",
        "def make_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(None, 784, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = make_model()  \n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-ca01066ba37b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-ca01066ba37b>\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m       raise ValueError('The last dimension of the inputs to `Dense` '\n\u001b[0m\u001b[1;32m   1169\u001b[0m                        'should be defined. Found `None`.')\n\u001b[1;32m   1170\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlast_dim\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The last dimension of the inputs to `Dense` should be defined. Found `None`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi7HE5zHV2Da",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3f97375-65fa-4c94-e45c-36bb0e3f5aaa"
      },
      "source": [
        "model = make_model()  \n",
        "\n",
        "history = model.fit(\n",
        "      dataset_train,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=100,\n",
        "      validation_data=dataset_valid,\n",
        "      validation_steps=50\n",
        "      )\n",
        "\n",
        "model.save('fmnist_conv.h5')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5580e2ca0c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:196 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer sequential_17 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [None, 784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qbhr44DnMbKZ"
      },
      "source": [
        "\n",
        "### Task 1.3 Build an input pipeline for data augmentation\n",
        "\n",
        "*(weight ~4%)*\n",
        "\n",
        "Build a data preprocessing pipeline to perform data augmentation. (You may use Keras ImageDataGenerator or write your own transformations.)\n",
        "\n",
        "- Report the new classification accuracy. Make sure that you use the same number of training epochs as in Task 1.2.\n",
        "\n",
        "- (Optional) Profile your input pipeline to identify the most time-consuming operation. What actions have you taken to address that slow operation? (*Hint: You may use the [TensorFlow Profiler](https://github.com/tensorflow/profiler).*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "prctXU4BswKK"
      },
      "source": [
        "### Task 1.4 Fashion-MNIST with transfer learning\n",
        "\n",
        "*(weight ~6%)*\n",
        "\n",
        "Use a pretrained model as the convolutional base to improve the classification performance. (Hint: You may use models in Keras Applications or those in the TensorFlow Hub.)\n",
        "\n",
        "- Try both with fine-tuning and without fine-tuning.\n",
        "- Report the model performance as before.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UaHLKDLas_dF"
      },
      "source": [
        "### Task 1.5 Performance comparison\n",
        "\n",
        "*(weight ~4%)*\n",
        "\n",
        "Record the test accuracy achieved at different training configurations above. Which method achieved the highest accuracy? Why did it work better for this problem?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ouK5NY-_pLDK"
      },
      "source": [
        "## Task 2 Fast training of deep networks\n",
        "\n",
        "*(weight ~16%)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LgoOE2W1pdfN"
      },
      "source": [
        "###### Task 2.1 Train a highly accurate network for CIFAR10\n",
        "\n",
        "*(weight ~6%, each subquestion worths ~2%)*\n",
        "\n",
        "In this task, you will train deep neural networks on the [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). Compared with the datasets that you have worked on so far, CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a \"harder\" problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IaD5oqj3lhuI"
      },
      "source": [
        "#### Task 2.1.1 Document the hardware used\n",
        "\n",
        "Before you start, write down your hardware specifications, including \n",
        "\n",
        "- the GPU model, the number of GPUs, and the GPU memory\n",
        "- the CPU model, the number of CPUs, and the CPU clock speed\n",
        "\n",
        "(Hint: you may find commands like `nvidia-smi`, `lscpu` or `psutil` useful.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gAJgmBF91hii"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "adN9Tq-6lyG-"
      },
      "source": [
        "#### Task 2.1.2 Train a \"shallow\" ConvNet\n",
        "\n",
        "Build a ConvNet with fewer than 10 layers. Train the network until it converges. You will use this network as a baseline for the later experiments. \n",
        "\n",
        "- Plot the training and validation history. \n",
        "- Report the testing accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9NTjVIUkmv7S"
      },
      "source": [
        "#### Task 2.1.3 Train a ResNet\n",
        "\n",
        "Train a residual neural network (ResNet) on the CIFAR10 training data and report the test accuracy and the training time.\n",
        "\n",
        "The ResNet is a popular network architecture for image classification. You may find more information about how ResNet works by reading this [paper](https://arxiv.org/abs/1512.03385).\n",
        "\n",
        "\n",
        "*(You may implement a resnet model or use an existing implementation. In either case, you should not use pretrained network weights.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AH6ZBiECzS75"
      },
      "source": [
        "### Task 2.2 Fast training of ResNet\n",
        "\n",
        "*(weight ~5%)*\n",
        "\n",
        "In this task, you will experiment with different ways to reduce the time for training your ResNet on CIFAR10. There are different ways to speed up neural network training; below are two ideas. Please select at least one idea to implement. Explain the experiment steps and report the final performance and training time.\n",
        "\n",
        "#### Option 1. Learning rate schedule\n",
        "\n",
        "Use a learning rate schedule for the training. Some popular learning rate schedules include \n",
        "\n",
        "- the Step Decay learning rate (e.g., see [here](https://github.com/kuangliu/pytorch-cifar))\n",
        "- [Cyclical learning rates](https://arxiv.org/abs/1506.01186)\n",
        "- [The exponential learning rate](https://openreview.net/forum?id=rJg8TeSFDH) \n",
        "\n",
        "Also Keras provides [some convenient functions](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules) that you can use.\n",
        "\n",
        "\n",
        "#### Option 2. Look ahead optimiser\n",
        "\n",
        "Read [this paper](https://arxiv.org/abs/1907.08610) and implement the Lookahead optimiser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C8cKfAOjpn7c"
      },
      "source": [
        "### Task 2.3 Performance comparison\n",
        "\n",
        "*(weight ~5%)*\n",
        "\n",
        "Based on the above experiments, which method or which combination of methods result in the best accuracy with the same training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjzodoRQBbYb",
        "colab_type": "text"
      },
      "source": [
        "## Task 3 Design a novel deep neural network model (Challenge Task for Targeting HD Grades)\n",
        "\n",
        "*(weight ~11%)*\n",
        "Here, you have to show your critical idea to design a new neural network model. We will evaluate your results based on the novelty of the model and performance of the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M32gNJOCBbYc",
        "colab_type": "text"
      },
      "source": [
        "### Task 3.1: The key idea to design a novel deep neural networks for CIFAR10\n",
        "\n",
        "*(weight ~5%)*\n",
        "\n",
        "In this task, you will design a novel deep neural networks on the [CIFAR10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). CIFAR10 represents a relatively larger multi-class classification problem and presents a great opportunity for you to solve a \"harder\" problem. Different from Task 2, in this task you are required to design a novel neural network and optimize the performance in classification. In your answer, you have to clearly present what the key difference between your model and the classic ones, what the benefits in your design model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9geo9oTBbYe",
        "colab_type": "text"
      },
      "source": [
        "### Task 3.2: The implementation of the novel deep neural networks for CIFAR10\n",
        "\n",
        "*(weight ~6%)*\n",
        "\n",
        "In this task, it requires you to write the codes for model implementation and report the performance. In your results, you have to demonstrate the compared performance of your new model and the state-of-the-art models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hUV0wuZ01DNA"
      },
      "source": [
        "---\n",
        "**END OF ASSIGNMENT TWO**"
      ]
    }
  ]
}